# kubernetes

## 创建 Pod 的简化流程图：

```powershell
用户执行 kubectl apply/create
         ↓
kubectl 将请求提交给 API Server
         ↓
API Server 验证 & 存储对象到 etcd
         ↓
Scheduler 监听到无 Node 的 Pod → 挑选一个 Node
         ↓
API Server 更新 Pod 的 Node 信息
         ↓
kubelet（目标 Node 上）发现新 Pod → 拉取镜像、创建容器
         ↓
Container Runtime（如 containerd）真正启动容器
         ↓
Pod Running

1、用户通过 kubectl 命令等方式向 Master 节点上的 API Server 提交创建 Pod 的请求
2、API Server 收到后进行验证，验证通过后将信息存入 etcd ，并同步到其它etcd数据库
3、etcd 通过Watch机制发现数据变化则主动通知给所有API Server，API Server再返回成功结果给用户
4、Scheduler 通过Watch端口检测到 API Server上有新的Pod需要调度，根据调度策略（如资源需求、节点亲和性、污点容忍等）选择一个合适的节点，通知 API Server 调度该Pod
5、Scheduler 将 Pod 与选定的节点进行绑定，并将绑定信息更新到 etcd 中
6、API Server 通知 kubelet 有新的 Pod 调度，kubelet 通过容器运行时来启动Pod中的容器
7、kubelet 通过 container runtime 取到 Pod 状态，并同步信息到 API Server，最终由 API Server更新信息到 etcd
```



## kubelet 在接收到要创建的 Pod 后的详细操作流程：

------

#### 🟡 1. **拉取 Pod 规范（PodSpec）**

- kubelet 通过 watch API Server，发现有分配给自己的新 Pod。
- 它获取这个 Pod 的完整定义（包括容器配置、挂载卷、环境变量、镜像信息等）。

------

#### 🟡 2. **执行 Pod 的生命周期管理**

包括以下几个子步骤：

------

#### 🟢 2.1 拉取镜像（Pull Image）

- kubelet 调用 Container Runtime（如 containerd）接口，拉取镜像；
- 如果本地已有对应镜像，就不拉；
- 如果拉镜像失败，Pod 会处于 `ImagePullBackOff` 状态。

------

#### 🟢 2.2 创建容器挂载卷（Volume Mount）

- kubelet 按照定义挂载 Volume，比如：
  - emptyDir
  - hostPath
  - PVC（PersistentVolumeClaim）
- 它会通过 CSI 插件（Container Storage Interface）调度存储（如果涉及 PVC）。

------

#### 🟢 2.3 创建并启动容器（Container Create）

- kubelet 会调用 CRI（容器运行时接口），由 containerd 负责创建和运行容器；
- 包括 init 容器（如果有）和普通应用容器；
- 容器启动后，会执行 CMD 或 ENTRYPOINT 中定义的程序。

------

#### 🟢 2.4 设置网络（通过 CNI 插件）

- kubelet 调用 CNI 插件为 Pod 设置网络：
  - 分配 Pod IP；
  - 加入网络桥接或 VXLAN；
  - 配置路由规则。
- 这一步成功之后，Pod 就可以在集群网络中通信了。

------

#### 🟢 2.5 启动探针、状态上报

- ```
  容器启动阶段：
  ┌──────────────────────────────────────────────┐
  │ 容器被启动后（容器进程创建成功）             │
  │     ↓                                        │
  │ 执行 postStart Hook（钩子）                 │
  │     ↓                                        │
  │ 执行探针前的等待（initialDelaySeconds）     │
  │     ↓                                        │
  │ 开始周期性执行探针（readiness / liveness）  │
  └──────────────────────────────────────────────┘
  
  容器终止阶段：
  ┌──────────────────────────────────────────────┐
  │ kubelet 想终止 Pod（如 delete、缩容）        │
  │     ↓                                        │
  │ 触发 preStop Hook（钩子）                    │
  │     ↓                                        │
  │ 发送 SIGTERM 给容器                          │
  │     ↓                                        │
  │ 等待容器优雅退出（宽限期内）                 │
  │     ↓                                        │
  │ 容器仍未退出 → 发 SIGKILL 强制杀死           │
  └──────────────────────────────────────────────┘
  ```

  

- | 钩子名称    | 触发时机                | 用途                               |
  | ----------- | ----------------------- | ---------------------------------- |
  | `postStart` | **容器启动后** 立即触发 | 做启动后的初始化操作               |
  | `preStop`   | **容器终止前** 触发     | 做优雅退出（如通知、清理、延迟等） |

- | 探针类型               | 作用                                            | 触发结果                               |
  | ---------------------- | ----------------------------------------------- | -------------------------------------- |
  | `livenessProbe`        | 判断容器是否 **活着**（是否需要重启）           | 探测失败 → 重启容器                    |
  | `readinessProbe`       | 判断容器是否 **准备好接收请求**                 | 探测失败 → Pod 不加入 Service 负载均衡 |
  | `startupProbe`（可选） | 判断容器 **是否已完成启动**（适合启动慢的应用） | 启动成功后才执行前两个探针             |

- 你通过 `kubectl get pods` 或 `describe` 能看到当前状态和事件日志。



## 讲一下pod的探针

##### startup Probe（启动探测）

用于检测容器内的服务是否已经启动

容器完成首次启动探测后，在后续启动期间，会频繁进行启动探测，直到探测成功或者超过设定的超时时间

如果检测失败，默认会删除Pod中的容器并重新创建，但Pod的ID名称不变，如果继续失败， 重复此过程

##### liveness Probe（存活探测）

用于判断容器内的服务是否正在运行

如果检测失败，默认会删除Pod中的容器并重新创建，但Pod的ID名称不变，如果继续失败， 重复此过程

##### readiness Probe（就绪探测）

用于确定容器是否能正常提供服务

如果监测失败，会被service从上游可用端点移除，哪怕符合service的标签选择器，只有当就绪探测成功时，Pod 才会被认为是就绪状态，才会被添加到 Service 的负载均衡池中，从而接收外部流量

##### 实现探针的三种监测方式

##### Exec

在容器内执行指定的命令，如果命令的退出状态码为 0，则认为探测成功；如果是非 0 值，则认为探测失败

##### TcpSocket

Kubernetes 尝试与容器内指定的端口建立 TCP 连接，如果连接成功，则认为探测成功；如果连接失败，则认为探测失败

##### HTTPGet

ubernetes 向容器内指定的 HTTP 或 HTTPS 端点发送 GET 请求，如果响应的状态码在 200 到 400 之间（不包括 400），则认为探测成功；否则，认为探测失败



## 就绪探针的频率

### **1️⃣ 就绪探针频率是啥意思？**

> **频率 = 探针检查的间隔时间 (多久执行一次探测)**

Kubernetes 通过

```
periodSeconds
```

参数来控制「就绪探针」多久检查一次容器可用性

------

### **2️⃣ 相关参数 (面试一定要讲清)**

| 参数                    | 说明                              | 默认值         |
| ----------------------- | --------------------------------- | -------------- |
| **initialDelaySeconds** | 第一次探针执行前等待时间          | 0秒 (立刻执行) |
| **periodSeconds**       | 探针执行间隔 (频率)               | 10秒           |
| **failureThreshold**    | 失败多少次算失败                  | 3次            |
| **successThreshold**    | 成功多少次算恢复 (Readiness 专用) | 1次            |
| **timeoutSeconds**      | 每次探测最大等待时间              | 1秒            |



> **就绪探针频率 = periodSeconds (默认10秒一次)**

------

### **3️⃣ 面试标准答法**

> Kubernetes Readiness Probe 默认每10秒执行一次，通过 periodSeconds 参数可调整频率
>  initialDelaySeconds 控制首次执行延迟
>  failureThreshold 和 successThreshold 控制探测失败与恢复的判定
>  合理设置这些参数可以平衡探测灵敏度与系统负载
>  实际运维中，通常 periodSeconds 设置为 5–15 秒，根据应用特点灵活调整

------

### **4️⃣ YAML 示例 (标准写法)**

```
readinessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  failureThreshold: 3
  successThreshold: 1
  timeoutSeconds: 2
```

→ 解释
 ✅ **5秒**后第一次探测
 ✅ 每**5秒**探测一次
 ✅ 失败**3次**视为「不就绪」 (Service 不转发流量)
 ✅ 成功**1次**恢复

------

### **5️⃣ 实际建议 (加分讲解)**

| 应用类型                  | 推荐 periodSeconds | 备注                   |
| ------------------------- | ------------------ | ---------------------- |
| Web 服务 (Nginx/Java Web) | 5–10秒             | 典型场景               |
| 数据库 (MySQL/Redis)      | 10–30秒            | 频率不宜过高，防止压力 |
| 启动慢 (大应用)           | 15–30秒            | 配合 startupProbe      |



✅ **探针频率要适配应用特点**
 太快 → 增加系统负担
 太慢 → 故障检测延迟

------

### **6️⃣ 面试标准背诵版**

> Readiness Probe 默认每10秒探测一次，通过 periodSeconds 参数调整频率
>  我通常为 Web 应用设置5–10秒，数据库服务15–30秒
>  通过合理配置探针频率与失败阈值，平衡检测灵敏度与系统负载，确保服务可靠性
>  我实际项目中曾为 Nginx Ingress Pod 配置5秒探针频率，保障故障快速摘除



## hpa是干什么的，如何实现

实现pod的自动扩缩容

根据应用程序的负载情况自动调整 Pod 的副本数量，其核心作用在于确保应用既能应对高并发流量，又能在低负载时避免资源浪费，提高资源利用率，增强应用的弹性和可用性

设置最小副本数为2，最大副本数为6，现在要调整副本数为8，要有什么操作

### HPA 工作原理图：

```
pgsql复制编辑             +-------------------------+
             |   Metrics Server        |
             |   （提供监控数据）       |
             +-----------+-------------+
                         |
                         ▼
     +------------------------+
     |    HPA 控制器          |
     |    （定时检测指标）     |
     +-----------+------------+
                 |
                 ▼
    +--------------------------+
    |    Deployment / Pod      |
    |    自动调整副本数量      |
    +--------------------------+
```

------

### ✅ HPA 常用参数解释：

| 参数                       | 说明                                 |
| -------------------------- | ------------------------------------ |
| `minReplicas`              | 最少副本数（不能少于这个数）         |
| `maxReplicas`              | 最大副本数（不能超过这个数）         |
| `metrics`                  | 触发扩缩容的指标（如 CPU/内存）      |
| `targetAverageUtilization` | 目标利用率，比如 50%                 |
| `scaleTargetRef`           | 目标资源，如 Deployment、StatefulSet |

## **Kubernetes HPA (Horizontal Pod Autoscaler) 自动伸缩的理解和操作**


 ✅ **考察点**
 ✅ **标准答案**
 ✅ **命令示例**
 ✅ **面试加分讲解**
 让你回答得完整有逻辑。

------

### **1️⃣ 面试官考察点**

> 你是否理解 HPA 的 minReplicas / maxReplicas 限制，以及
>  实际手动扩容 (scale) / 调整 HPA 参数 时需要注意哪些地方

------

### **2️⃣ 面试标准答法**

> 当前 HPA 已设置 minReplicas=2，maxReplicas=6
>  如果我们想把副本数扩容到 8，大于现有 maxReplicas=6，
>  需要先「修改 HPA 的 maxReplicas 参数」为 ≥ 8，
>  然后才可以让系统自动扩容到 8，或者直接手动 scale 副本数到 8

------

### **3️⃣ 标准操作步骤 + 命令**

#### **步骤1：查看当前 HPA 资源**

```
kubectl get hpa
kubectl describe hpa <hpa-name>
```

#### **步骤2：修改 HPA 最大副本数 (maxReplicas)**

> 方法A (直接 patch)

```
kubectl patch hpa <hpa-name> -p '{"spec": {"maxReplicas": 8}}'
```

> 方法B (直接 edit)

```
kubectl edit hpa <hpa-name>
# 修改 maxReplicas: 8 然后保存退出
```

#### **步骤3：确认修改成功**

```
kubectl get hpa
```

#### **步骤4：扩容副本数到 8**

> 如果等自动扩容，HPA 会根据指标自动调整
>  如果要立刻强制 scale，也可以直接：

```
kubectl scale deployment <deployment-name> --replicas=8
```

------

### **4️⃣ 面试加分讲解**

✅ **为什么不能直接 scale 到 8？**

> 因为 HPA 会自动把 replicas 限制在 maxReplicas 范围内
>  如果 maxReplicas=6，你直接 scale 到 8，系统会把它缩回到 ≤6
>  所以必须先调高 HPA 的 maxReplicas

✅ **HPA 会和手动 scale 冲突吗？**

> 有冲突
>  手动 scale 会立即调整副本数
>  但 HPA controller 还是会持续控制副本数，使其符合指标和 min/max 约束
>  所以手动 scale 只是暂时生效，最终还是 HPA 决定副本数

✅ **实战建议 (加分)**

> 如果需求变成「未来副本数经常需要 >6」
>  应该同时评估资源利用率指标 (比如 CPU target utilization)，合理调整 HPA 策略，避免频繁手动 scale
>  同时结合 `kubectl autoscale` 可以一次性设置 deployment + HPA 参数

------

### **5️⃣ 面试标准背诵版**

> 要扩容副本数到 8，首先需要调整 HPA 的 maxReplicas 参数为 8
>  否则系统会自动把副本数限制在 6 以内
>  我会先通过 kubectl patch 或 edit 修改 maxReplicas，再确认 HPA 状态，然后执行 scale 命令或等 HPA 自动扩容
>  同时我会评估资源利用率与实际需求，合理规划 HPA 策略，确保服务弹性与稳定性



## `Pending` 状态的常见原因

#### 资源不足

**原因**

- **CPU / 内存 不足**：集群没有足够的资源满足 Pod 需求。
- **节点压力过大**：节点资源耗尽，无法调度新的 Pod。



#### PVC 未绑定

**原因**

- **PVC 没有成功绑定到 PV**。
- **PV 不满足 PVC 需求**（如 `storage` 或 `accessMode` 不匹配）。
- **存储类（StorageClass）问题**。



#### 节点不可用

**原因**

- **节点 `NotReady`**，可能因网络问题、磁盘空间不足或 Kubelet 崩溃。
- **Taint（污点）** 阻止 Pod 调度。



#### 调度失败（调度策略问题）

**原因**

- **NodeSelector / Affinity 限制**，Pod 只能调度到特定节点，但这些节点不可用。
- **Toleration 和 Taint 不匹配**，导致 Pod 不能调度到污点节点。



#### 网络问题

**原因**

- **CoreDNS 崩溃**，导致 Pod 无法解析存储服务器或其他服务。
- **NFS / Ceph 存储访问失败**，导致 PVC 绑定失败。



#### 镜像拉取失败

**原因**

- **镜像不存在** 或 **拼写错误**。
- **私有镜像仓库未配置凭证**。
- **网络问题**，导致无法从 Docker Hub / 阿里云拉取镜像。



####  ServiceAccount 权限不足

**原因**

- **Pod 需要访问 API 但 ServiceAccount 没有足够权限**。
- **RBAC 配置错误**。



## 生产中k8s遇到的问题

在实际生产环境中，Kubernetes 集群常见的问题非常多，涉及集群稳定性、资源调度、存储网络、安全性、CI/CD 集成等多个层面。根据企业运维和 SRE 实践经验，我帮你梳理一份**生产环境 Kubernetes 典型问题清单**，方便你了解和排查：

------

### 1️⃣ 资源管理与调度问题

| 问题                   | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| Pod 无法调度 (Pending) | 资源不足 (CPU/内存)、节点污点 (Taints)、亲和性/反亲和性约束导致无法调度 |
| 资源利用不均衡         | 节点资源分配不均，导致部分节点压力过大或资源浪费             |
| OOMKilled              | Pod 运行内存超限，被 kubelet 杀死 (需要合理设置 `requests/limits`) |
| CPU 限制导致性能抖动   | 设置 CPU limits 过低，导致 CPU throttling，影响应用性能      |



------

### 2️⃣ 网络与服务发现问题

| 问题                        | 说明                                                         |
| --------------------------- | ------------------------------------------------------------ |
| Pod 之间无法通信            | CNI 插件故障 (如 Calico/Flannel 配置问题)、iptables 规则异常 |
| Service 访问不通            | Service 配置错误、Endpoint 丢失、CoreDNS 故障                |
| LoadBalancer / Ingress 失效 | 外部负载均衡器未配置或 Ingress Controller 异常               |
| DNS 解析失败                | CoreDNS Pod 异常、ConfigMap 配置错误、节点 DNS 转发问题      |



------

### 3️⃣ 存储与数据持久化问题

| 问题           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| PVC 挂载失败   | StorageClass 配置错误、PV/PVC 状态不一致、存储后端 (如 NFS/CSI) 故障 |
| 持久卷性能瓶颈 | NFS/iSCSI 存储延迟高，影响数据库或应用性能                   |
| 存储回收失败   | PVC 删除后 PV 处于 Released，无法自动回收，需手动清理        |



------

### 4️⃣ 集群组件与控制平面问题

| 问题                 | 说明                                                       |
| -------------------- | ---------------------------------------------------------- |
| etcd 读写慢或崩溃    | etcd 磁盘 IOPS 不足、存储空间不足、集群扩容不当            |
| API Server 压力大    | 频繁 CRD 变更、大量短生命周期 Pod、Prometheus 监控请求过多 |
| kubelet 宕机或不健康 | kubelet 崩溃、node unreachable、cgroup 配置问题            |
| 控制平面证书过期     | kubeadm 证书未续期，API Server / etcd 无法通信             |



------

### 5️⃣ 安全性与权限管理问题

| 问题              | 说明                                                         |
| ----------------- | ------------------------------------------------------------ |
| RBAC 权限配置错误 | ServiceAccount 权限不足，Pod 无法访问 API                    |
| Secret 泄露风险   | Secret 以明文形式挂载，缺少加密与审计                        |
| Pod 安全性不足    | 容器以 root 运行，未启用 PodSecurityPolicy / Pod Security Standards |
| 节点暴露风险      | 节点 SSH 暴露、kubelet API 暴露 (未关闭匿名访问)             |



------

### 6️⃣ 运维管理与升级问题

| 问题             | 说明                                                     |
| ---------------- | -------------------------------------------------------- |
| 集群版本不一致   | Control plane 和 Node kubelet 版本差异大，API 不兼容风险 |
| 滚动升级中断服务 | Deployment 滚动更新未设置合理探针和 maxUnavailable       |
| 镜像仓库不可用   | Harbor / DockerHub 镜像拉取失败，Pod 创建卡住            |
| 节点意外宕机     | 节点维护不当，Pod 没有合理的 Anti-Affinity 约束          |



------

### 7️⃣ 监控与日志问题

| 问题           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| 监控指标丢失   | Prometheus TSDB 压力大、ServiceMonitor 配置错误              |
| 日志丢失       | Pod 异常重启，stdout/stderr 日志未持久化或未采集 (EFK/ELK 配置不完整) |
| 链路追踪不完整 | SkyWalking / Jaeger 未正确注入 sidecar，trace 丢失           |



------

### 8️⃣ CI/CD 与自动化运维问题

| 问题                          | 说明                                                   |
| ----------------------------- | ------------------------------------------------------ |
| CI/CD 交付不稳定              | GitLab Runner / ArgoCD 部署管道失败，K8s RBAC 未配置好 |
| 自动扩缩容 (HPA) 无效         | Metrics-server 配置异常，导致 HPA 无法获取指标         |
| ConfigMap / Secret 更新未生效 | 应用未正确 reload 配置，导致配置变更后服务无感知       |



------

### 9️⃣ 典型高可用与灾备问题

| 问题            | 说明                                               |
| --------------- | -------------------------------------------------- |
| 单点故障 (SPoF) | etcd 单节点、API Server 单副本部署导致高可用性不足 |
| 数据丢失        | etcd 备份缺失，存储卷未做快照与备份                |
| 跨区域部署挑战  | 跨地域网络延迟高，K8s 多集群联邦部署复杂度大       |



------

### 生产环境总结 🛠️

| 领域         | 推荐实践                                           |
| ------------ | -------------------------------------------------- |
| **资源管理** | 合理设置 requests/limits，启用 VPA/HPA             |
| **网络安全** | CNI 插件选型谨慎、Service Mesh 增强可观测性        |
| **存储策略** | StatefulSet + CSI 动态存储、定期备份               |
| **监控告警** | Prometheus + Grafana + AlertManager 全链路监控     |
| **CI/CD**    | GitOps (ArgoCD) + 自动化测试、蓝绿/金丝雀发布      |
| **安全治理** | OPA Gatekeeper / Kyverno 统一策略管理、Secret 加密 |



------

如果你告诉我你想重点了解 **哪一类问题的解决方案**（比如资源调度、网络问题还是安全管理），我可以进一步帮你整理 **排查步骤** 和 **最佳实践**。



## 什么是资源配额，什么是资源限额

### ✅ 一、什么是 **资源限额（Resource Limits）**

资源限额是针对 **单个 Pod 或容器** 的 **资源限制设置**，防止一个应用吃光节点资源。

#### 📌 包括两个参数：

| 参数       | 说明         | 作用                           |
| ---------- | ------------ | ------------------------------ |
| `requests` | 最低保障资源 | Pod 调度时会用它判断能不能部署 |
| `limits`   | 最大资源限制 | 容器实际运行时的资源上限       |



#### 📌 示例（限制 CPU 和内存）：

```
resources:
  requests:
    cpu: "100m"      # 最少需要 0.1 核
    memory: "256Mi"  # 最少需要 256Mi 内存
  limits:
    cpu: "500m"      # 最多能用 0.5 核
    memory: "512Mi"  # 最多能用 512Mi 内存
```

> 💡 说明：
>
> - 如果容器超过 limits 的内存，会被 **杀掉（OOMKilled）**
> - 超过 CPU limits，则会被 **限制执行速度**

------

### ✅ 二、什么是 **资源配额（Resource Quota）**

资源配额是针对 **整个命名空间（namespace）** 的 **资源总量限制**，用于多租户或团队资源控制。

#### 📌 用于控制整个团队在命名空间里：

- 能创建多少个 Pod？
- 总共最多用多少 CPU 和内存？
- 最多能申请多少 PVC 存储卷？
- 最多能建多少 Service？

#### 📌 示例：

```
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu: "4"
    requests.memory: "8Gi"
    limits.cpu: "8"
    limits.memory: "16Gi"
```

> 💡 意思是：
>
> - 命名空间 `dev` 只能最多创建 10 个 Pod
> - 总共最多请求 4 核 CPU，最大使用 8 核
> - 总共最多使用 16Gi 内存（limits）

------

#### ✅ 总结区别：

| 对比点   | 资源限额（Resource Limit）  | 资源配额（Resource Quota）    |
| -------- | --------------------------- | ----------------------------- |
| 控制范围 | 控制单个容器 / Pod          | 控制整个命名空间资源总量      |
| 设置位置 | 在 Pod / Deployment YAML 里 | 单独写 ResourceQuota 资源     |
| 控制对象 | requests / limits           | pods、cpu、memory、storage 等 |
| 作用场景 | 防止单个应用占用太多资源    | 限制团队或项目的总资源使用    |



## 滚动更新和灰度发布

##### 灰度 (金丝雀) 发布

是一种逐步向用户发布，能够平滑过渡的一种发布方式，会先将新版本部署到一小部分用户上进行测试，这部分用户就像是 "金丝雀" 一样，用于提前检测新内容可能存在的问题，在确认没有问题后，再逐步将其推广到更多的用户或服务器，直到完全取代旧版本

因此，灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现并调整问题

1. **流量分片**：通过流量控制（如 Nginx Ingress、Service Mesh）将部分流量导向新版本。
2. **实时监控**：在小范围验证期间，监控新版本的性能、错误率等指标。
3. **快速回滚**：如果发现问题，可快速将流量切回旧版本

##### 滚动发布

是一种逐步升级替换旧版本软件的方式，是指每次只升级一个或多个服务实例，升级完成后加入生产环境，不断执行这个过程，直到集 群中的全部旧版本升级新版本，确保服务在更新过程中始终可用，其核心目标是实现无缝更新，减少对用户的影响

缺点：中间不会进行测试与观察用户的反馈，只能升级完进行回退

Kubernetes 的 Deployment 资源提供了滚动更新的能力。通过修改 Deployment 的镜像版本或配置，Kubernetes 会自动以滚动的方式更新 Pod。用户可以在 Deployment 配置中设置更新策略，如`maxUnavailable`和`maxSurge`，分别控制更新过程中不可用的 Pod 最大数量和超出期望副本数的最大 Pod 数量。



## k8s外部流量怎么访问本地pod的

Nodeport方式：  通过node节点的ip和暴露端口，提供外部访问 

Loadbalance模式：适用于云产品厂商进行暴露访问。

Ingress模式：通过提供域名，代理分流不同域名进行各自访问

ExternalIP：不过不属于service的解决方案



我们用的是ingress nginx Controller，部署 Ingress 控制器，创建 Ingress 资源

配置 DNS：将域名 `example.com` 解析到 Ingress Controller 的 IP 地址，之后通过该域名即可访问 Pod



## 污点这个标签起什么作用，怎么使用



在 Kubernetes 中，**污点（Taints）** 是一种机制，用于让节点拒绝调度不符合条件的 Pod。配合 **容忍（Tolerations）** 使用，能实现更灵活的 **Pod 调度控制**。

------

### ✅ 一句话解释：

> 污点（Taint）用来“驱逐”Pod，容忍（Toleration）用来“豁免”Pod。
>  污点标记节点不欢迎哪些 Pod，只有带容忍的 Pod 才能调度进去。

------

### ✅ 使用场景举例

- 指定某些节点只能运行系统级 Pod（如 kube-proxy）
- 给 GPU 节点打污点，只有 AI 训练类 Pod 才能调度上去
- 节点维护时打污点，避免新 Pod 被调度进去

------

### ✅ 污点的结构

```
<key>=<value>:<effect>
```

| 字段   | 含义               |
| ------ | ------------------ |
| key    | 污点键             |
| value  | 污点值             |
| effect | 污点效果（见下表） |



------

#### ✅ effect（效果）取值：

| Effect 值          | 含义                                |
| ------------------ | ----------------------------------- |
| `NoSchedule`       | 不调度到该节点，除非 Pod 有对应容忍 |
| `PreferNoSchedule` | 尽量不调度（软性规则）              |
| `NoExecute`        | 不仅不调度，还驱逐已有不容忍的 Pod  |



------

### ✅ 给节点打污点

```
kubectl taint nodes node1 key=value:NoSchedule
```

例如：

```
kubectl taint nodes node1 env=prod:NoSchedule
```

表示：不允许调度普通 Pod 到 node1，除非 Pod 有容忍 `env=prod`

------

### ✅ 编写 Pod 容忍（tolerations）

```
apiVersion: v1
kind: Pod
metadata:
  name: toleration-pod
spec:
  tolerations:
  - key: "env"
    operator: "Equal"
    value: "prod"
    effect: "NoSchedule"
  containers:
  - name: busybox
    image: busybox
    command: [ "sleep", "3600" ]
```

这个 Pod 会被允许调度到打了 `env=prod:NoSchedule` 污点的节点。

------

### ✅ 查看和删除污点

#### 查看某节点的污点：

```
kubectl describe node node1
```

#### 删除污点：

```
kubectl taint nodes node1 env=prod:NoSchedule-
```

注意末尾有个 **`-`**，代表移除。

------

#### ✅ 总结：

| 关键词     | 作用                                 |
| ---------- | ------------------------------------ |
| Taint      | 限制某些节点不接受不符合要求的 Pod   |
| Toleration | Pod 主动声明“我能容忍这个节点的污点” |

这套机制能精准控制 Pod 在什么节点运行，防止资源误用。



## k8s数据持久化是怎么做的，velero，应用就是pvpvc？

###  hostPath (本地存储卷)

可以将宿主机上的目录挂载到 Pod 中作为数据的存储目录

缺点：无法实现数据漫游，因为`hostPath` 的数据存储在本地磁盘，Pod 重启或调度到其他节点时，无法自动访问原节点的数据

### openEBS

定义存储类

定义PVC持久卷

定义pod并挂载持久卷

在部署应用时，通过在 Pod 的配置中指定使用 Jiva 存储卷的 PVC，应用就能使用 Jiva 提供的持久化存储



## pod的控制器和作用

| 工作负载类型    | 主要功能                                             | 使用场景                            |
| --------------- | ---------------------------------------------------- | ----------------------------------- |
| **Pod**         | Kubernetes 中最小的调度单位，管理一个或多个容器。    | 单一应用或共享资源的容器。          |
| **ReplicaSet**  | 确保指定数量的 Pod 副本运行，维护 Pod 副本数。       | 确保应用高可用性，自动扩容和容错。  |
| **Deployment**  | 管理无状态应用的副本，支持滚动更新和回滚。           | 无状态应用，如 Web 服务、API 服务。 |
| **StatefulSet** | 管理有状态应用，提供持久化存储、稳定身份和顺序部署。 | 数据库、分布式存储、消息队列等。    |
| **DaemonSet**   | 确保每个节点上运行一个 Pod，适用于节点级别的任务。   | 集群级别代理，如日志收集、监控等。  |
| **Job**         | 用于一次性任务，确保任务成功完成并终止。             | 批处理任务，如数据迁移、备份等。    |
| **CronJob**     | 定期执行任务，类似 Linux 中的 cron。                 | 定时任务，如定期备份、日志清理等。  |

##### **1. ReplicaSet**

**ReplicaSet** 是用于确保指定数量的 Pod 副本在集群中运行的控制器。如果 Pod 发生故障或被删除，ReplicaSet 会自动创建新的 Pod 来恢复到期望的副本数。

- **ReplicaSet 的特点**：
  - 主要功能是 **保证 Pod 副本数**，确保始终有指定数量的 Pod 在运行。
  - 是 **Deployment** 的基础组件，通常不会单独使用，而是通过 **Deployment** 来管理。
- **使用场景**：
  - 确保高可用性，避免单点故障，ReplicaSet 自动扩缩容来维护集群的稳定性。

##### **2. Deployment**

**Deployment** 是 Kubernetes 中最常用的工作负载类型之一，它基于 ReplicaSet，负责管理 **Pod 的副本**，并提供 **无中断部署**、**回滚**、**版本管理**等功能。

- Deployment 的特点：
  - 支持 **滚动更新**，可以将新版本的应用逐步替换旧版本，而不影响应用的可用性。
  - 支持 **回滚**，如果新版本出现问题，可以迅速回滚到上一个稳定版本。
  - 管理 **Pod 的副本数**，通过 ReplicaSet 确保 Pods 的数量满足需求。
- 使用场景：
  - 适用于 **无状态应用**，如 Web 服务、API 服务等，确保应用的 **可扩展性** 和 **高可用性**。

##### **3. StatefulSet**

**StatefulSet** 是为有状态应用（如数据库、分布式缓存等）设计的工作负载类型，能够管理 **Pod 的稳定标识**、**有序部署和滚动更新**。

- **StatefulSet 的特点**：
  - 提供 **持久化存储**：每个 Pod 可以有一个独立的持久化存储卷，Pod 被销毁后，数据不会丢失。
  - 保证 **Pod 的顺序部署和滚动更新**，例如，Pod 会按顺序启动和终止。
  - 每个 Pod 会有一个 **稳定的网络标识**（DNS 名称），方便有状态应用使用。
- **使用场景**：
  - 适用于需要 **稳定身份和持久存储** 的应用，如 **数据库、消息队列、分布式存储**。

##### **4. DaemonSet**

**DaemonSet** 确保 **每个 Node** 上运行一个 Pod 副本。这在需要确保集群中的每个 Node 都运行某些特定任务时非常有用。

- **DaemonSet 的特点**：
  - 每个节点都会运行一个 Pod，可以确保集群中每个节点都能够处理特定的任务。
  - 适用于 **日志收集**、**监控代理**、**网络代理** 等场景。
  - 如果新节点加入集群，DaemonSet 会自动在新节点上启动一个 Pod。
- **使用场景**：
  - 部署 **集群级别的代理** 或 **监控工具**，如 **Fluentd**、**Prometheus Node Exporter** 等。

##### **5. Job**

**Job** 是用于批处理作业的工作负载。Job 确保指定数量的 Pod 完成某个任务，并在任务完成后终止。

- **Job 的特点**：
  - 确保任务的 **执行成功**，如果 Pod 执行失败，Job 会重新创建 Pod 来重新执行任务。
  - 支持并发执行多个 Pod，以加快任务完成。
  - 适用于一次性任务，如数据迁移、批量处理等。
- **使用场景**：
  - 适用于 **批处理任务**，如定时任务、数据备份、数据导入等。

##### **6. CronJob**

**CronJob** 是 Job 的扩展，支持 **定时任务**。CronJob 会按照指定的时间表定期执行任务。

- **CronJob 的特点**：
  - 类似于 Linux 中的 cron，可以设置定时任务，按指定时间运行 Job。
  - 支持定期执行 **批处理任务**，如每天、每小时、每月执行某些操作。
- **使用场景**：
  - 定期执行 **数据库备份**、**日志清理**、**定时任务** 等。



## 有状态和无状态的区别

##### 有状态

指不会在请求之间保存任何状态信息，每个请求都独立处理，不考虑之前的请求或状态

它的执行情况和结果与前面的请求和之后的请求没有直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况

##### 无状态

指在处理请求时，系统会存储客户端的历史信息或状态数据，并有可能会在客户端下一次的请求中使用这些数据，基于这些信息进行处理





## kubernetes组件

##### Master

**API Server**：整个集群的API网关，以API形式对外提供服务

声明式API：允许用户声明系统的期望结果，具体 "如何做" 由Kubernetes负责

**Scheduler**：调度器，负责将新创建的 Pod 分配到合适的节点上运行

**Controller Manager**：控制器，负责除调度之外的编排决策，每种类型的决策都由相应的控制器实现

**etcd**：集群状态数据存储系统，仅会同API Server交互

##### Worker

**容器运行时：**容器运行的环境，一般用docker

**Kubelet**：每个Worker节点上的代理，主要接收执行Master节点发来的指令，管理由Scheduler绑定至当前节点上的Pod对象的容器

**Kube Proxy（可选）**：运行于每个Worker节点上，负责实现 Service 的网络代理和负载均衡功能，确保集群内的 Pod 和外部客户端能够通过 Service 访问后端 Pod

可选原因：网络插件cilium和calico可以具备service网络功能，所以可以代替掉proxy



## kubernetes网络

**三个网络功能**

- 节点网络

  集群节点间的通信网络，并负责打通与集群外部端点间的通信

  节点网络的IP地址配置在集群节点主机的物理接口上

  网络及各节点地址需要于Kubernetes部署前完成配置，非由Kubernetes管理

  因而，需要由**管理员或借助于主机虚拟化管理程序实现**

- Pod网络

  为集群上的Pod对象提供的网络

  Pod网络 IP地址配置在Pod的虚拟网络接口上

  每个pod 从此网络动态获取地址,且每次重启pod后IP地址可能会变化

  虚拟网络，需要经**由CNI网络插件实现**，例如Flannel、Calico、Cilium等

  **使用某此CNI插件也可以支持和节点网络使用相同的网络**

- Service网络

  主要用于解决 pod 使用动态地址问题

  在部署Kubernetes集群时指定，各Service对象使用的地址将从该网络中分配

  Service网络的IP地址并不配置在任何物理接口,而是存在于每个节点内核中其相关的iptables或ipvs规则中

  **由Kubernetes集群自行管理**

```
1 主机网络，网络运维管理
2 容器网络，CNI 组件提供 flannel ,calico,cilium 
3 service 网络 kube-proxy
```



## Flannel和Calico的分别的使用场景

##### Flannel 的使用场景

- 中小规模集群

  Flannel 的 VXLAN 或 Host-GW 模式适合节点数量较少的集群（通常几十到几百节点）。

  覆盖网络带来的开销在中小规模集群中可以接受。

  部署简单，配置少，适合快速搭建开发测试环境。

  不需要复杂的网络策略时，Flannel 是一个轻量级的选择。

##### 示例

- 一个由 50 个节点组成的 Kubernetes 集群，用于运行微服务开发环境。
- 集群中不需要复杂的网络策略，只需要基本的 Pod 间通信。

##### Calico的使用场景

适合大规模生产集群

Calico 的原生路由（BGP）模式适合大规模集群（数千节点），性能更高。

支持大规模网络拓扑，且延迟更低。

## Flannel工作模式

```powershell
使用“虚拟网桥和veth设备”的方式为Pod创建虚拟网络接口，通过可配置的“后端”定义Pod间的通信网络，支持基于VXLAN和UDP的Overlay网络，以及基于三层路由的Underlay网络
	虚拟网桥cni0
	隧道接口通常为flannel.1
在IP地址分配方面，它将预留的一个专用网络(默认为10.244.0.0/16)切分成多个子网后作为每个节点的podCIDR，而后由节点以IPAM插件host-local进行地址分配，并将子网分配信息保存于etcd之中

flanneld
	Flannel在每个主机上运行一个名为fanneld的二进制代理程序
	该程序负责从预留的网络中按照指定或默认的掩码长度为当前节点申请分配一个子网，并将网络配置、已分配的子网和辅助数据(例如主机的公网IP等)存储于Kubernetes API或etcd之中
Flannel使用称为后端(backend)的容器网络机制转发跨节点的Pod报文，它目前支持的主流backend如下
	vxlan
		使用Linux内核中的vxlan模块封装隧道报文，以叠加网络模型支持跨节点的Pod间互联互通
		额外支持直接路由(Direct Routing)模式，该模式下位于同二层网络内的节点之上的Pod间通信可通过路由模式直接发送，而跨网络的节点之上的Pod间通信仍要使用VXLAN隧道协议转发
		vxlan后端模式中，fanneld监听于8472/UDP发送封装的数据包;
	host-gw
		类似于VXLAN中的直接路由模式，但不支持跨网络的节点，因此这种方式强制要求各节点本身必须在同一个二层网络中，不太适用于较大的网络规模
		有着较好的转发性能，且易于设定，推荐对报文转发性能要求较高的场景使用
		
VXLAN 隧道模式
	对节点网络几乎没有限制
	存在开销
	
host-gw 路由模式
	要求所有网路必须位于同一网络平面
	没有网络开销，性能好
	
混合网络
	同一网络平面上的使用host-gw，跨网络通信的，使用VXLAN
```



## Calico工作模式

```powershell
ProjectCalico

三层的虚拟网络方案
	它把每个节点都当作虚拟路由器(vRouter)，把个节点上的Pod都当作是“节点路由器”后的一个终端设备并为其分配一个IP地址
	各节点路由器通过BGP(Border Gateway Protocol)协议学习生成路由规则从而实现不同节点上Pod间的互联互通

Calico在每一个计算节点利用Linux内核实现了一高效的vRouter(虚拟路由器)进行报文转发，而每个vRouter通过BGP协议负责把自身所属的节点上行的Pod资源的IP地址信息基于节点的agent程序网络内传播(Felix)直接由vRouter生成路由规则问整个Calico

网络模式
	纯隧道：
		ipip
		vxlan
	纯三层：
		bgp
	混合模式
		bgp
        + ipip
		bgp + vxlan
```



## Kubernetes提供了三个特定功能的接口

kubernetes通过调用这几个接口，来完成相应的功能。

- 容器运行时接口CRI: Container Runtime Interface

  CRI 首次发布于2016年12月的Kubernetes 1.5 版本。

  在此版本之前，Kubernetes 直接与 Docker 通信，没有标准化的接口。

  从 Kubernetes 1.5 开始，CRI 成为 Kubernetes 与容器运行时交互的标准接口，使得 Kubernetes 可以与各种容器运行时进行通信，从而增加了灵活性和可移植性。

  kubernetes 对于容器的解决方案，只是预留了容器接口，只要符合CRI标准的解决方案都可以使用

- 容器网络接口CNI: Container Network Interface

  kubernetes 对于网络的解决方案，只是预留了网络接口，只要符合CNI标准的解决方案都可以使用

- 容器存储接口CSI: Container Storage Interface

  kubernetes 对于存储的解决方案，只是预留了存储接口，只要符合CSI标准的解决方案都可以使用此接口非必须

## **Pod** **状态**

`phase` 可能的值：

| 取值                | 描述                                                         |
| :------------------ | :----------------------------------------------------------- |
| `Pending`（悬决）   | Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间。 |
| `Running`（运行中） | Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。 |
| `Succeeded`（成功） | Pod 中的所有容器都已成功结束，并且不会再重启。               |
| `Failed`（失败）    | Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止，且未被设置为自动重启。 |
| `Unknown`（未知）   | 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。 |

#### Pod 的启动流程状态

| 流程状态        | 描述                              |
| --------------- | --------------------------------- |
| PodScheduled    | Pod被调度到某一个节点             |
| Ready           | 准备就绪，Pod可以处理请求         |
| initialized     | Pod中所有初始init容器启动完毕     |
| Unschedulable   | 由于资源等限制，导致pod无法被调度 |
| ContainersReady | Pod中所有的容器都启动完毕了       |

|            **状态**            |                           **描述**                           |
| :----------------------------: | :----------------------------------------------------------: |
|          **Pending**           | API Server 已经创建该 Pod，但是 Pod 因为某些原因无法调度到合适的节点运行。 |
|          **Running**           | Pod 内所有的容器已创建，且至少有一个容器处于运行状态，正在启动或重启状态。 |
|          **Waiting**           |                       Pod 等待启动中。                       |
|        **Terminating**         |   Pod 正在删除，若超过终止宽限期仍无法删除，可以强制删除。   |
|         **Succeeded**          |            所有容器均成功执行退出，且不会再重启。            |
|           **Ready**            |                Pod 已经准备好，可以提供服务。                |
|           **Failed**           |     Pod 内所有容器都已退出，其中至少有一个容器退出失败。     |
|          **Unknown**           |   由于某种原因 kubelet 无法获取 Pod 的状态，比如网络不通。   |
|      **CrashLoopBackOff**      | Pod 回避算法：第 1 次 0 秒立刻重启，第二次 10 秒后重启，第三次 20 秒后重启，第 6 次 160 秒后重启，第 7 次 300 秒后重启，如仍然重启失败，则为 CrashLoopBackOff 状态。 |
|           **Error**            | 因为集群配置、安全限制、资源等原因导致 Pod 启动过程中发生了错误。 |
|          **Evicted**           |      集群节点系统内存或硬盘资源不足导致 Pod 出现异常。       |
|         **Completed**          | 表示 Pod 已经执行完成，比如：一次性的 Job 或周期性的 CronJob 中的 Pod 执行完成后，会显示此状态。 |
|        **Unscheduled**         |    Pod 不能调度到节点，一般可能是因为没有合适的节点主机。    |
|        **PodScheduled**        |           Pod 正在被调度过程，但此状态的时间很短。           |
|        **Initialized**         |                Pod 中所有初始化容器启动完毕。                |
|      **ImagePullBackOff**      |                   Pod 对应的镜像拉取失败。                   |
|      **InvalidImageName**      |               镜像名称无效，导致镜像无法下载。               |
|     **ImageInspectError**      |              镜像检查错误，通常因为镜像不完整。              |
|     **ErrImageNeverPull**      |     拉取镜像因策略禁止错误，镜像仓库权限拒绝或私有导致。     |
|    **RegistryUnavailable**     |     镜像仓库服务不可用，比如：网络原因或仓库服务器宕机。     |
|        **ErrImagePull**        | 镜像拉取错误，可能是镜像地址错误，因为超时或拉取被强行终止。 |
|     **NetworkPluginReady**     |    网络插件异常，会导致新建容器出错，但旧的容器不受影响。    |
|          **NodeLost**          |                    Pod 所在节点无法联系。                    |
| **CreateContainerConfigError** |                      创建容器配置错误。                      |

|           **状态**           |                           **描述**                           |
| :--------------------------: | :----------------------------------------------------------: |
|   **CreateContainerError**   |                     创建容器时发生错误。                     |
|    **RunContainerError**     | 运行容器时发生错误，例如容器中没有 PID 为 1 的前台进程等原因。 |
| **ContainersNotInitialized** |                     容器没有初始化完成。                     |
|    **ContainersNotReady**    |                       容器没有准备好。                       |
|    **ContainerCreating**     |                     容器正在创建过程中。                     |
|     **PodInitializing**      |                      容器正在初始化中。                      |
|   **DockerDaemonNotReady**   |                   节点的 Docker 服务异常。                   |



## Service 和 kube-proxy 关联关系

- Service作为一个独立的API资源对象，它会在在API Service服务中定义出来的
- 在创建任何存在标签选择器的Service时，都会被自动创建一个同名的Endpoints资源，Endpoints对象会使用Label Selector自动发现后端端点，并各端点的IP配置为可用地址列表的元素
- Service Controller 触发每个节点上的kube-proxy，由kube-proxy实时的转换为本地节点上面的ipvs/iptables规则。
- 默认情况下，内核中的ipvs或iptables规则，仅仅是负责本地节点用户空间pod客户端发出请求时的拦截或者转发规则
- 如果Pod客户端向Service发出请求,客户端向内核发出请求，根据ipvs或iptables规则，匹配目标service
- 如果service匹配，会返回当前service随对应的后端endpoint有哪些
- iptables或ipvs会根据情况挑选一个合适的endpoint地址
  - 如果endpoint是本机上的，则会转发给本机的endpoint
  - 如果endpoint是其他主机上的，则转发给其他主机上的endpoint

## Service 类型

|                 类型                 |                        核心功能                         |                           访问方式                           |                        依赖条件/限制                         |          示例场景          |
| :----------------------------------: | :-----------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------------------: |
|      **ClusterIP** （默认类型）      |  为集群内部（节点、Pod）提供访问，外部网络无法直接访问  |       `客户端 → ClusterIP:ServicePort → PodIP:PodPort`       |                          无特殊依赖                          | 内部微服务通信（如数据库） |
|  **NodePort** （ClusterIP 增强版）   | 通过节点 IP 和固定端口（30000~32767）暴露服务到外部网络 | `外部客户端 → NodeIP:NodePort` `→ ClusterIP:ServicePort → PodIP:PodPort` |    需节点开放端口 （所有 `kube-proxy` 节点启用相同端口）     |    开发测试环境临时访问    |
| **LoadBalancer** （NodePort 增强版） |        基于云厂商负载均衡器（LBaaS）对外提供服务        | `外部客户端 → 云厂商LB → NodeIP:NodePort` `→ ClusterIP:ServicePort → PodIP:PodPort` | 依赖云平台 LBaaS 支持 （无云服务时降级为 `NodePort`，`EXTERNAL-IP` 显示 `Pending`） |  生产环境高可用 Web 服务   |
|           **ExternalName**           |   通过 DNS CNAME 将外部服务（如云数据库）引入集群内部   | `集群内客户端 → Service名称 → CNAME → 外部服务域名（如 mysql.wang.org）` | 依赖 CoreDNS 解析 （无 ClusterIP/NodePort，不创建 Endpoints） | 访问外部托管服务（如 RDS） |

## Headless Service

```
有头服务
myweb.demo.svc.cluster.local
client ——》 myweb.demo.svc.cluster.local ——》 coredns ——》 10.101.159.213 ——》 svc （endpoints） ——》 pod

无头服务
client ——》 myweb.demo.svc.cluster.local ——》 svc （endpoints） ——》 pod
```

```yaml
#方式
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
 ...
  spec:
    clusterIP: "None"
```



## 数据存储

### 1️⃣ 临时存储（Pod 生命周期内有效）

- **emptyDir**：Pod 启动时创建，Pod 删除即清除，适合临时缓存场景
   **项目例子**：在 Prometheus + ELK 项目中，Logstash 的中间处理缓存可以用 emptyDir 暂存批量日志

------

### 2️⃣ 持久存储（Pod 生命周期外有效）

#### **（1）PersistentVolume（PV） + PersistentVolumeClaim（PVC）**

- **通过 PVC 管理持久卷**，支持 Pod 弹性扩缩容与重建后数据不丢
   **项目例子**：
   MinIO 集群项目中，MinIO Bucket 数据和元数据持久化，我们使用本地磁盘 + PVC 保障分布式存储可靠性

#### **（2）StorageClass（动态存储供应器）**

- 动态按需创建 PV，简化管理
- 我们项目主要用 **NFS StorageClass** 和 **本地分布式存储（MinIO + 本地盘）**

------

### 3️⃣ 访问模式（AccessModes）

| 模式    | 说明       | 生产用例                         |
| ------- | ---------- | -------------------------------- |
| **RWO** | 单节点读写 | MySQL PVC、Prometheus TSDB       |
| **RWX** | 多节点读写 | NFS 共享静态资源、MinIO 共享数据 |
| **ROX** | 多节点只读 | 共享配置文件                     |



------

### 4️⃣ 存储策略（ReclaimPolicy）

- **Retain**：PVC 删除后数据保留（生产常用，防止误删）
- **Delete**：PVC 删除时自动清理底层存储
   **项目例子**：
   MinIO 集群备份方案中，我们配置 Retain 确保 Bucket 数据不会随 PVC 误删

------

### 5️⃣ 生产最佳实践（我项目中用过）

- Prometheus 监控数据 → **Ceph RBD / 云盘 / Local PV + PVC**
- Nginx 静态资源 → **NFS StorageClass + RWX PVC**
- MinIO 对象存储 → **Local PV + PVC + 多副本备份 (mc mirror)**
- 配合 **Velero 快照备份 PVC**，防止数据丢失（可提及，证明你懂备份）

------

### 一句话总结（强烈建议面试时背下来）

> 生产环境中，我们通过 PVC + StorageClass 动态管理持久存储，合理选择访问模式和回收策略，结合 Ceph/NFS/MinIO/云盘等后端，保障业务数据持久性、可用性与弹性扩展。

------

### 如果面试官追问「你实际项目里怎么选存储的？」

你可以补充我帮你整理的**项目总结版**：

> 我们 Prometheus + ELK 监控项目和 MinIO 存储集群项目中，综合考虑了存储性能、可用性与成本：
>
> - 监控数据 → **本地磁盘 + PVC**，写多读少，追求高 IOPS
> - 静态资源 → **NFS + RWX PVC**，多副本读写一致性强
> - 对象存储 → **MinIO + Local PV 分布式集群**，配合 **mc mirror** 备份，保障数据安全





## PVC扩容

> **1. 明确 StorageClass 是否支持扩容（AllowVolumeExpansion）**
>
> > 在生产环境 PVC 扩容前，我首先会确认当前 StorageClass 是否启用了 `allowVolumeExpansion: true`，因为只有开启了这个参数的存储类型才支持在线扩容 PVC。
>
> ```
> kubectl get sc <storageclass-name> -o yaml | grep allowVolumeExpansion
> ```
>
> **2. 检查 PVC 绑定的 PV / 存储后端是否支持扩容**
>
> > 其次要确认底层存储（比如 Ceph、NFS、云盘等）是否支持扩容，比如 Ceph RBD、AWS EBS、阿里云云盘默认支持，但 NFS 不一定支持自动扩容。
>
> **3. 执行 PVC 扩容操作**
>
> > 如果确认支持，可以直接 `kubectl edit pvc <pvc-name>` 修改 `spec.resources.requests.storage`，把容量调大：
>
> ```
> spec:
>   resources:
>     requests:
>       storage: 100Gi
> ```
>
> 或者
>
> ```
> kubectl patch pvc <pvc-name> -p '{"spec": {"resources": {"requests": {"storage": "100Gi"}}}}'
> ```
>
> **4. 检查 Pod 使用方式**
>
> > 需要确认 PVC 是否以 `ReadWriteOnce` 方式挂载在单个 Pod，并且文件系统是否支持在线扩容（ext4/xfs 基本支持）。
> >  如果底层存储支持在线扩容，Pod 一般无需重启，文件系统会自动检测新空间。
> >  如果不支持（比如某些老旧 NFS），可能需要重新挂载或重建 Pod。
>
> **5. 在线扩容 or 离线扩容**
>
> > - 对支持在线扩容的存储（比如 Ceph RBD、云盘），PVC 扩容完基本不影响业务。
> > - 如果不支持在线扩容，提前和应用沟通维护窗口，优雅下线后扩容并重建 Pod。
>
> **6. 验证 PVC 扩容是否生效**
>
> ```
> kubectl get pvc <pvc-name>
> kubectl describe pvc <pvc-name>
> ```
>
> **7. 监控和告警**
>
> > 最佳实践是结合 Prometheus 监控 PVC 使用率，比如持久卷用量超过 80% 预警，提前规划扩容，避免业务影响。
>
> ------
>
> ### 示例一句话总结（适合面试最后补充）
>
> > 生产中 PVC 扩容我会优先确认 StorageClass 和存储后端支持，执行安全扩容操作，视存储类型决定是否在线完成，同时配合监控及时发现容量瓶颈。

### NFS PVC 扩容——标准面试回答

**1. 确认 NFS 后端存储是否已扩容**

> 由于 NFS 是通过挂载共享目录方式提供存储，PVC 扩容本质上依赖 NFS 服务器端的目录底层磁盘空间是否足够。
>  所以扩容第一步是联系存储管理员或我们自己扩容 NFS 服务器磁盘，比如通过 LVM 扩容挂载路径。

**2. StorageClass 和 PVC 配置确认**

> 虽然 NFS 类型 StorageClass 通常不启用 `allowVolumeExpansion`，但其实对 NFS PVC 来说，Kubernetes 层的 PVC 大小只是一个逻辑配额，真正存储空间取决于 NFS 服务器。

**3. PVC 端扩容操作**

> 如果我们为了与集群资源配额保持一致，仍然会在 PVC 层同步调整 `requests.storage`：

```
kubectl edit pvc <pvc-name>
```

把容量数值调大，比如 100Gi。
 （实际上 NFS 后端空间足够大时，PVC 逻辑大小和真实可用空间关系不大）

**4. 应用 Pod 层面影响**

> 对于 NFS 卷，因为是通过网络挂载，扩容底层存储后一般不需要重启 Pod，也不需要扩展文件系统，Pod 可以直接感知新的空间。
>  但保险起见，我们会 `df -h` 查看挂载目录是否看到新空间。

**5. 验证和监控**

> - 在 NFS 服务器端 `df -h` 验证磁盘是否扩容成功
> - 在 Pod 内部 `df -h /mnt/<nfs>` 验证挂载路径是否空间变化
> - 结合 Prometheus + cAdvisor 监控 PVC 使用率，提前预警

------

### NFS PVC 扩容 一句话总结（面试加分）

> NFS PVC 扩容本质是扩容 NFS 后端磁盘，PVC 层同步调整 requests.storage 逻辑配额，扩容过程中通常不影响业务，Pod 无需重启，但需要监控空间用量避免资源耗尽。

------

### **如果面试官继续追问**

（我帮你准备了“高级回答”）

> **面试官问**：「NFS 动态卷的情况下 StorageClass 支持扩容吗？」
>  **你可以答**：
>  通常社区版 nfs-subdir-external-provisioner（NFS 动态卷）默认 StorageClass 没有启用 `allowVolumeExpansion`，不过我们可以手动编辑 StorageClass 加上 `allowVolumeExpansion: true`，这样 PVC 资源对象可以扩容，但底层还是依赖 NFS 服务器目录空间是否足够。



## configMap

ConfigMap 是一种 API 对象，用来将非机密性的数据保存到键值对中。使用时， [Pod](https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/) 可以将其用作环境变量、命令行参数或者存储卷中的配置文件。

ConfigMap 将你的环境配置信息和[容器镜像](https://kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-image)解耦，便于应用配置的修改。

**注意: Configmap 属于名称空间级别,只能被同一个名称空间的Pod引用**

## Secret

Secret volume是通过tmpfs（内存文件系统）实现的，所以这种类型的volume不是永久存储的。

每个Secret的数据不能超过1MB，支持通过资源限额控制每个名称空间的Secret的数量

注意: Secret 属于名称空间级别，只能被同一个名称空间的Pod引用

|     **类型**      |               **核心功能**                |                        **常见子类型**                        |
| :---------------: | :---------------------------------------: | :----------------------------------------------------------: |
|     `generic`     |   存储通用base64编码数据（密码/公钥等）   | `Opaque` `kubernetes.io/service-account-token` `kubernetes.io/basic-auth` `kubernetes.io/ssh-auth` `bootstrap.kubernetes.io/rbd` |
|       `tls`       |        专用于存储TLS/SSL证书和私钥        |                     `kubernetes.io/tls`                      |
| `docker-registry` | 用于kubelet从私有镜像仓库拉取镜像时的认证 |  `kubernetes.io/dockercfg` `kubernetes.io/dockerconfigjson`  |

Secret资源在Pod中引用的方式有三种

- 环境变量

  引用Secret对象上特定的key，以valueFrom赋值给Pod上指定的环境变量

  在Pod上使用envFrom一次性导入Secret对象上的所有key-value，key(也可以统一附加特定前缀）即为环境变量名,value自动成为相应的变量值

  注意：容器很可能会将环境变量打印到日志中,基于安全考虑不建议以环境变量方式引用Secret中的敏感数据

- secret卷

  在Pod上将Secret对象引用为存储卷，而后整体由容器mount至某个目录下,其中key名称转为文件名，value的值转为相应的文件内容

  在Pod上定义Secret卷时，也可以仅引用其中的指定的部分key，而后由容器mount至目录下

- 拉取镜像

  在Pod 上使用 imagePullSecrets 拉取私有仓库镜像使用

  Pod引用Secret的方式：pods.spec.imagePullSecrets



## **Ingress-nginx Controller 工作机制**

> Ingress-nginx Controller 是 Kubernetes 中用于管理 HTTP/HTTPS 流量入口的反向代理组件，它基于 Nginx 实现，负责接收外部请求并将流量按规则转发到集群内 Service / Pod。

------

### 1️⃣ **核心组件**

| 组件                                 | 作用                                       |
| ------------------------------------ | ------------------------------------------ |
| **Ingress Controller（Deployment）** | 监听 K8s Ingress 资源，动态生成 Nginx 配置 |
| **Nginx Pod（Controller 内部）**     | 实际执行反向代理和负载均衡                 |
| **Ingress 资源（Ingress YAML）**     | 用户定义域名、路径转发规则                 |
| **ConfigMap / Annotations**          | 自定义 Nginx 行为和转发细节                |



------

### 2️⃣ **工作流程（核心面试重点！）**

#### **① 部署 Controller**

> 我们通过 Helm / YAML 安装 **Ingress-nginx Controller**，它作为 Deployment 运行，通常暴露为 **LoadBalancer / NodePort / MetalLB** IP

```
kubectl apply -f ingress-nginx.yaml
```

------

#### **② 监听 Ingress 资源**

> Controller 自动 watch 所有命名空间的 **Ingress 资源对象**，例如：

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
spec:
  rules:
  - host: www.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp
            port:
              number: 80
```

------

#### **③ 动态生成 Nginx 配置**

> Controller 把 Ingress 规则「翻译」为 Nginx 配置文件，写入 Nginx Pod 内部 `/etc/nginx/nginx.conf`，典型反向代理配置：

```
server {
  server_name www.example.com;
  location / {
    proxy_pass http://myapp-service;
  }
}
```

------

#### **④ Nginx 监听流量 + 负载均衡**

> 外部用户访问 `http(s)://www.example.com` → 流量进入 Nginx → 根据 Ingress 规则转发到 Service → Pod

- 支持 **L7 路由**（域名 / 路径）
- 支持 **SSL 终结**（证书管理）
- 支持 **负载均衡**（Nginx upstream）

------

#### **⑤ 实时热更新**

> Ingress Controller 自动监控 Ingress 资源变化，**热更新 Nginx 配置**，不重启实现流量切换
>  **比如滚动更新、蓝绿发布、灰度发布都依赖这个能力**

------

### 3️⃣ **高级功能（加分项）**

- **HTTPS / TLS 终结** → 自动申请/管理证书（结合 cert-manager）
- **Rewrite / Redirect / Path rewrite** → 灵活路由规则
- **Rate limiting / 访问控制 / 认证** → 配合 Annotation / ConfigMap 实现
- **自定义负载均衡算法 / 健康检查** → Nginx 层能力
- **Prometheus Metrics 暴露** → 监控 Ingress 性能状态

------

### 4️⃣ **生产项目实战答法（结合你简历项目）**

> 在我们汽车维修平台和 Prometheus 监控项目中，我们通过 Ingress-nginx Controller 统一管理 HTTP 入口：
>
> - 通过 **MetalLB + LoadBalancer Service** 暴露 Ingress IP
> - 配置 Ingress 资源实现**多域名 / 多路径转发**
> - 结合 **cert-manager** 自动申请 Let’s Encrypt 证书，实现 HTTPS 终结
> - 结合 Annotation 配置 Nginx **连接超时 / 限流 / IP 访问控制**
> - 通过 Prometheus 监控 Ingress 请求量和响应延迟，保障服务稳定性

------

### 5️⃣ **一句话总结（面试必背）**

> Ingress-nginx Controller 通过监听 K8s Ingress 资源，动态生成 Nginx 配置，实现 HTTP/HTTPS 入口的统一路由转发与流量管理，支持负载均衡、SSL 终结与高级路由功能，是生产环境主流流量入口方案。

------

### 6️⃣ **如果面试官追问「和 Service 有什么关系？」**

你答：

> Ingress 本质是「七层反向代理 + 路由规则」，背后通过 **Service** 发现 Pod
>  Ingress → Nginx → **Service (ClusterIP)** → Pod
>  两者配合，Ingress 管理入口规则，Service 负责后端服务发现和负载均衡



## **OpenEBS 与 PV / PVC 关系与原理总结**

> **OpenEBS** 是一款开源的**云原生存储引擎**，专为 Kubernetes 环境设计，提供 **容器化、本地化、可扩展的持久化存储服务**
>  它遵循 Kubernetes 标准 PV / PVC 接口，支持动态供给（dynamic provision），帮助应用轻松获取持久卷

------

### 1️⃣ **Kubernetes PV / PVC 基本概念（先铺垫）**

| 概念                            | 说明                                                    |
| ------------------------------- | ------------------------------------------------------- |
| **PersistentVolume (PV)**       | 由管理员预配置或 StorageClass 动态创建的物理存储资源    |
| **PersistentVolumeClaim (PVC)** | 应用申请存储卷（容量 + 访问模式），K8s 匹配对应 PV 绑定 |
| **StorageClass**                | 定义存储类型、供给器（Provisioner）、参数、回收策略     |



> OpenEBS 本质上是提供「动态 Provisioner + 后端存储引擎」，自动创建 PV 供 PVC 使用

------

### 2️⃣ **OpenEBS 生产部署架构与组件**

| 组件                      | 作用                                                         |
| ------------------------- | ------------------------------------------------------------ |
| **OpenEBS Control Plane** | OpenEBS Operator + Provisioner + NDM（Node Disk Manager）管理集群存储 |
| **OpenEBS Data Plane**    | 存储引擎（Jiva / cStor / Mayastor / LocalPV 等），真正提供数据存储与卷管理 |
| **StorageClass**          | 绑定对应 OpenEBS 引擎（Provisioner），动态供给 PV            |



------

### 3️⃣ **OpenEBS 工作原理（核心面试重点）**

> 应用 Pod → PVC（申请存储） → StorageClass（绑定 OpenEBS Provisioner） → 动态创建 PV（OpenEBS 负责） → Pod 绑定使用

#### **流程图（逻辑清晰）**

```scss
App Pod
   │
 PVC (storageClassName=openebs-jiva)
   │
 StorageClass (provisioner=openebs.io/provisioner-iscsi)
   │
OpenEBS Provisioner → 动态创建 PV → OpenEBS Storage Engine (Jiva/cStor)
```

------

### 4️⃣ **OpenEBS 支持的存储引擎（生产重点）**

| 引擎                            | 特点                                     | 生产适用场景             |
| ------------------------------- | ---------------------------------------- | ------------------------ |
| **Jiva**                        | 容器内 iSCSI 存储引擎，轻量级，快速部署  | 中小型应用，开发测试环境 |
| **cStor**                       | 基于 ZFS，强一致性，支持快照、备份、RAID | 高可用生产环境，数据库   |
| **Mayastor**                    | 高性能 NVMe 驱动，适合 SSD/裸机          | 高性能应用，数据库/AI    |
| **LocalPV (hostpath / device)** | 直接挂载节点磁盘，性能极高               | 日志、大数据、本地数据库 |



------

### 5️⃣ **OpenEBS StorageClass 示例（Agent 配置模板）**

#### **1. Jiva StorageClass**

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-jiva-default
provisioner: openebs.io/provisioner-iscsi
parameters:
  openebs.io/storage-pool: default
  replicaCount: "3"
reclaimPolicy: Delete
allowVolumeExpansion: true
```

#### **2. LocalPV (Device) StorageClass**

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-device
provisioner: openebs.io/local
parameters:
  storageType: device
  blockDeviceTag: "fast-disk"
reclaimPolicy: Delete
allowVolumeExpansion: false
```

------

### 6️⃣ **生产项目实战答法（你可以这么说）**

> 在我们 Prometheus 监控和 MinIO 对象存储项目中，为提升集群内存储性能与弹性，我们部署了 OpenEBS 作为 K8s 本地持久化存储方案：
>
> - 使用 **OpenEBS LocalPV (Device)**，结合 SSD 磁盘，为 Prometheus TSDB 和 MinIO Bucket 提供高性能持久卷
> - 通过 StorageClass 绑定 OpenEBS Provisioner，PVC 自动申请对应本地卷
> - 结合 OpenEBS NDM 管理节点磁盘，动态识别与分配
> - 配置 **Retain 回收策略**，防止 PVC 删除误删数据
> - 搭配 **Velero** 定期快照备份 PVC 数据，保障数据安全性

------

### 7️⃣ **一句话总结（面试必背）**

> OpenEBS 作为云原生存储方案，通过自研存储引擎与 Kubernetes StorageClass 集成，实现 PV 动态供给与本地高性能存储，帮助应用无缝获取持久卷，支持灵活扩展与高可用。

------

### 8️⃣ **高级加分项**

> - OpenEBS 支持 **CSI 标准接口**，与 K8s 完美集成
> - 支持 **快照 / 克隆 / 备份 / 恢复**，增强数据安全性
> - OpenEBS 可与 **Prometheus 集成监控存储性能指标**
> - OpenEBS LocalPV 适合 AI / 大数据 / 日志类应用，极致性能



## **Kubernetes 访问控制体系**

> Kubernetes 访问控制体系主要从「认证（Who）→ 鉴权（Can do what）→ 准入控制（How）」三层保障集群安全
>  核心理念就是 **「谁能做什么」**

------

### **1️⃣ 认证（Authentication） —「你是谁？」**

> 认证负责确认请求来源「身份」
>  支持多种认证方式，生产常用：

| 认证方式                               | 说明                           | 典型用途                              |
| -------------------------------------- | ------------------------------ | ------------------------------------- |
| **证书认证（Client Certificate）**     | kube-apiserver 校验证书+CN字段 | kubelet / kube-proxy / 管理员账号     |
| **Token 认证（ServiceAccount Token）** | Pod 内通过 JWT Token 调用 API  | Pod 访问 K8s API                      |
| **Static Token 文件**                  | 预置静态 token 列表            | 临时测试                              |
| **OIDC 认证（OpenID Connect）**        | 集成企业统一身份认证（SSO）    | 企业用户SSO认证（结合 Keycloak/LDAP） |
| **Webhook Token 认证**                 | 外部认证服务                   | 自定义复杂认证流程                    |



------

### **2️⃣ 鉴权（Authorization） —「你能做什么？」**

> 鉴权决定认证通过的用户**能否执行具体操作**

#### **主流鉴权机制（生产必背）**

| 鉴权机制                                   | 说明                           | 典型用途                 |
| ------------------------------------------ | ------------------------------ | ------------------------ |
| **RBAC（Role-Based Access Control）**      | 基于角色+资源粒度授权          | 生产默认标准，细粒度授权 |
| **ABAC（Attribute-Based Access Control）** | 基于用户属性配置 JSON 授权策略 | 老版本 / 特殊场景        |
| **Webhook Authorization**                  | 外部服务鉴权                   | 接入企业 IAM 系统        |



------

#### **RBAC 四大资源对象**

| 资源                   | 作用                                 |
| ---------------------- | ------------------------------------ |
| **Role**               | 命名空间内角色权限                   |
| **ClusterRole**        | 集群范围角色权限                     |
| **RoleBinding**        | 绑定 Role 到用户/组/SA（命名空间级） |
| **ClusterRoleBinding** | 绑定 ClusterRole（集群级）           |



✅ **生产经验**

> 通常用 ClusterRole + RoleBinding 细化授权
>  比如：
>  开发 → 只能管理 dev-namespace
>  运维 → 全集群只读
>  CI/CD → 只允许部署 Deployment / Service

------

### **3️⃣ 准入控制（Admission Control） —「请求是否被允许？」**

> 准入控制在认证/鉴权通过后，决定请求是否符合集群安全策略
>  典型场景：强制性校验、自动修改对象

#### **常用 Admission Controllers（生产必备）**

| 控制器                                      | 作用                          | 典型用途                    |
| ------------------------------------------- | ----------------------------- | --------------------------- |
| **NamespaceLifecycle**                      | 管控 NS 生命周期              | 禁止删除 kube-system        |
| **ResourceQuota**                           | 强制资源配额                  | 限制 NS 资源消耗            |
| **LimitRanger**                             | 设置 Pod 默认 requests/limits | 防止资源争用                |
| **PodSecurityPolicy（弃用） / PodSecurity** | 限制容器安全上下文            | 禁止特权容器                |
| **ValidatingWebhook**                       | 外部服务校验请求              | CI/CD 代码检查              |
| **MutatingWebhook**                         | 外部服务自动修改请求          | 自动加 Label / 注入 Sidecar |



------

### **4️⃣ 其它配套安全机制（加分项）**

✅ **ServiceAccount（SA）**
 Pod 内访问 API Server 的身份凭证，搭配 RBAC 授权
 ✅ **NetworkPolicy**
 控制 Pod 级网络访问
 ✅ **Secrets 加密 / etcd 加密**
 保障敏感数据安全
 ✅ **Audit Logs**
 记录访问日志，追溯安全事件

------

#### **项目实战答法（结合你简历项目）**

> 在我们 Prometheus + SkyWalking 监控与 OA 系统容器化项目中，我们采用：
>
> - RBAC 细粒度授权：开发组只能管理 dev 命名空间，CI/CD 账号只允许部署 Pod 资源
> - AdmissionWebhook：结合 OPA Gatekeeper 强制检查 Deployment 资源必须配置 requests/limits
> - ServiceAccount + RBAC：Prometheus 组件限定只读集群指标权限
> - NetworkPolicy：SkyWalking OAP 只允许 UI / Agent 访问，防止暴露

------

### **一句话总结（面试必背）**

> Kubernetes 访问控制体系通过认证确认身份，RBAC 鉴权分配权限，Admission 控制请求合法性，配合 SA、NetworkPolicy、Audit 等机制，全面保障集群资源安全与访问可控。

------

### **如果面试官追问「RBAC 和 NetworkPolicy 区别？」**

你答：

> RBAC 控制「用户/服务账户访问 API 资源权限」
>  NetworkPolicy 控制「Pod 级网络流量访问权限」
>  **RBAC 控 API，NetworkPolicy 控网络**，两者互补

------

✅ 这套答法**结构清楚 + 实战落地 + 细节扎实**
 ✅ 结合你简历 Prometheus + SkyWalking 项目直接扣得住



## **Kubernetes 生产 RBAC 授权 YAML 模板**

### **场景1：开发组只管理 dev-namespace Deployment / Service 资源**

#### **1️⃣ 角色（Role）**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: dev
  name: dev-namespace-developer
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "create", "update", "delete"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "create", "update", "delete"]
```

#### **2️⃣ 角色绑定（RoleBinding）**

```
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: bind-dev-developer
  namespace: dev
subjects:
- kind: User
  name: devuser1
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: dev-namespace-developer
  apiGroup: rbac.authorization.k8s.io
```

------

### **场景2：CI/CD 服务账号集群范围只管理 Deployment / Service**

#### **1️⃣ 集群角色（ClusterRole）**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cicd-deployer
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "create", "update", "delete"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "create", "update", "delete"]
```

#### **2️⃣ 集群角色绑定（ClusterRoleBinding）**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: bind-cicd-sa
subjects:
- kind: ServiceAccount
  name: cicd-sa
  namespace: kube-system
roleRef:
  kind: ClusterRole
  name: cicd-deployer
  apiGroup: rbac.authorization.k8s.io
```

------

### **面试标准答法（直接背！）**

> 在生产环境中，我们常用 RBAC 授权两类典型场景：
>
> - **开发组命名空间级权限**：Role + RoleBinding，只允许管理 dev namespace 的 Deployment / Service
> - **CI/CD 跨命名空间发布权限**：ClusterRole + ClusterRoleBinding，授予 ServiceAccount 跨命名空间部署应用权限
>    我们通过细粒度 verbs 控制 CRUD 权限，原则「最小权限（Least Privilege）」保障安全

------

### **加分答法：生产 RBAC 授权设计原则**

✅ **原则1：最小权限**
 — 只授予必要资源 / 操作权限

✅ **原则2：职责分离**
 — 开发只管业务资源，不能改集群资源
 — 运维管核心资源（node/pv/crd）

✅ **原则3：显式授权**
 — 不用 wildcard `*`，明确列出资源和 verbs

✅ **原则4：命名规范**
 — Role 名称: **namespace-角色描述**
 — ClusterRole 名称: **功能-角色描述**

✅ **原则5：审计和定期回收**
 — 定期审计 RoleBinding/ClusterRoleBinding
 — 回收不再使用账号权限

------

### **一句话总结（面试必背）**

> 生产 RBAC 授权我们通过 Role / ClusterRole 精细控制资源权限，结合 RoleBinding / ClusterRoleBinding 绑定用户或 ServiceAccount，遵循最小权限、职责分离与定期审计原则，保障集群安全与权限可控。

------

✅ 这套答法「YAML 模板 + 设计理念 + 生产原则」
 ✅ **面试官听完会知道你真的做过权限管理**
 ✅ 完美对应你简历 CI/CD + Prometheus + SkyWalking 项目





| 默认 ClusterRole  |       绑定的 ClusterRoleBinding        |                       描述（核心权限）                       |
| :---------------: | :------------------------------------: | :----------------------------------------------------------: |
| **cluster-admin** |          `system:masters` 组           | **最高权限**： - 通过 `ClusterRoleBinding` 授权时：可操作集群及所有命名空间的任何资源。 - 通过 `RoleBinding` 授权时：可操作绑定命名空间的所有资源（包括 `Namespace` 自身）。 |
|     **admin**     | 无默认绑定（需手动关联 `RoleBinding`） | **命名空间管理员权限**： - 读写命名空间内大多数资源（如 Pod、Deployment）。 - 可创建子 `Role` 和 `RoleBinding`。 - **限制**：不能操作 `ResourceQuota` 和 `Namespace` 本身。 |
|     **edit**      |               无默认绑定               | **编辑权限**： - 读写命名空间内大多数对象（包括 `Secret`）。 - **限制**：不可查看或修改 `Role` 和 `RoleBinding`。 |
|     **view**      |               无默认绑定               | **只读权限**： - 可查看命名空间内大多数对象。 - **限制**：不可访问 `Role`、`RoleBinding` 和 `Secret`。 |

1. **ClusterRole 与 RoleBinding 的关系**

   - `ClusterRole` 是集群级别的角色模板，通过 `ClusterRoleBinding` 或 `RoleBinding` 绑定到用户/组。
   - 区别：
     - `ClusterRoleBinding`：权限作用于整个集群（如 `cluster-admin`）。
     - `RoleBinding`：权限仅作用于单个命名空间（如 `admin`、`edit`、`view`）。

2. **权限递进逻辑**

   ```
   view（只读） → edit（读写，不含RBAC） → admin（读写+RBAC管理） → cluster-admin（全集群控制）
   ```

3. **实际应用场景**

   - **`cluster-admin`**：集群运维人员（需谨慎分配）。
   - **`admin`**：命名空间负责人（如开发团队Leader）。
   - **`edit`**：普通开发者（需修改资源但无需管理权限）。
   - **`view`**：监控或审计人员（仅需查看资源状态）。



## **Kubernetes Operator 原理**

> **Operator** 是一种 Kubernetes 扩展机制，用于封装和自动化复杂有状态应用（Stateful Application）的运维逻辑
>  它基于 **控制器模式**，通过自定义资源对象（CRD + Controller），实现应用的**生命周期管理**（部署 / 扩缩容 / 升级 / 备份 / 故障恢复）

------

### **1️⃣ Operator 核心组成**

| 组件                                | 作用                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| **CRD（CustomResourceDefinition）** | 自定义资源类型，扩展 Kubernetes API，定义「我想管理的新对象」 |
| **Custom Resource（CR）**           | 自定义资源对象，用户实例化 CRD，比如 "MySQLCluster"          |
| **Controller（控制器）**            | 业务逻辑引擎，监听 CR 变化，执行期望状态 → 实际状态同步      |
| **Reconcile Loop（调谐循环）**      | Operator Controller 定期执行「观察 - 对比 - 调谐」循环，保证资源状态一致性 |



------

### **2️⃣ Operator 工作原理（核心面试重点！）**

#### **① CRD 扩展 API 资源**

> Operator 通过 CRD 注册新资源，比如

```
yaml复制编辑apiVersion: mysql.example.com/v1
kind: MySQLCluster
```

> 这让 `kubectl get mysqlclusters` 成为合法 API

------

#### **② 用户创建 Custom Resource**

```
yaml复制编辑apiVersion: mysql.example.com/v1
kind: MySQLCluster
metadata:
  name: my-db
spec:
  replicas: 3
  version: 8.0
```

> **CR = 应用期望状态（Desired State）声明**

------

#### **③ Controller 监听 CR 变化**

> Operator Controller 监听 `MySQLCluster` 对象变更事件（新增/修改/删除）

------

#### **④ Reconcile Loop 执行调谐**

> Controller 对比
>  ✅ **期望状态（CR）** vs ✅ **实际状态（集群资源现状）**
>  发现不一致 → 生成 / 更新 / 删除资源（Pod / Service / PVC 等）

- 例子：用户改了 replicas=5
   → Controller 自动 scale StatefulSet 到 5 副本

------

#### **⑤ 持续自动化运维**

> Controller 持续调谐，自动化执行
>  **部署 / 扩容 / 升级 / 备份 / 恢复 / 故障转移**

------

### **3️⃣ Operator 适合场景**

✅ 有状态应用（Stateful Apps）
 如 MySQL、Redis、Kafka、Elasticsearch
 ✅ 运维复杂度高、需要自动化
 如 备份 / 主从同步 / 故障恢复

------

### **4️⃣ 生产实战答法（结合你 MinIO Operator 经验）**

> 在我们 MinIO 集群项目中，我们使用 **MinIO Operator** 管理 MinIO 分布式对象存储
>
> - 定义 **Tenant Custom Resource**，声明 MinIO 集群副本数、存储配置
> - Operator Controller 自动生成 StatefulSet + PVC + Service 资源，完成集群部署
> - 通过更新 CR，实现集群**弹性扩缩容 / 自动修复 / 升级版本**
> - 结合 Operator 自带 **Console UI** 管理多租户 Bucket 权限与存储策略，实现 MinIO 集群生命周期自动化管理

------

### **5️⃣ Operator vs Helm 区别（面试官爱追问）**

| Helm                | Operator            |
| ------------------- | ------------------- |
| 一次性部署          | 持续调谐管理        |
| 模板化资源清单      | 编排应用运维逻辑    |
| 不感知状态变化      | 自动处理应用变更    |
| 适合无状态/简单应用 | 适合有状态/复杂应用 |



> **一句话** → Helm 负责「安装」，Operator 负责「自动化运维全生命周期」

------

### **6️⃣ 一句话总结（面试必背）**

> Operator 通过 CRD 扩展 API，Controller 持续监听并自动调谐资源状态，实现有状态应用的自动化部署、扩缩容与故障恢复，是生产级 Kubernetes 应用运维的重要手段。



## **Helm 原理与机制**

> **Helm** 被称为「Kubernetes 的包管理器」，作用类似于 Linux 的 apt / yum
>  主要用来**模板化定义、安装、管理 Kubernetes 应用资源**
>  **一句话** → Helm = K8s 应用的「一键安装 + 升级 + 回滚 + 版本管理」工具

------

### **1️⃣ 核心概念（面试必背）**

| 概念            | 作用                                | 生产用途          |
| --------------- | ----------------------------------- | ----------------- |
| **Chart**       | 应用打包单元（模板 + values +说明） | 应用发布包        |
| **Release**     | 已安装实例（Chart + 配置）          | 部署的具体应用    |
| **Repository**  | Chart 存储仓库                      | 共享 / 分发 Chart |
| **Values.yaml** | Chart 配置文件（变量值）            | 灵活定制部署参数  |



------

### **2️⃣ Helm 工作原理（核心面试重点！）**

#### **① Chart 模板化定义应用资源**

```
yaml复制编辑# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.app.name }}
spec:
  replicas: {{ .Values.app.replicas }}
```

> Chart 中资源清单（Deployment / Service / PVC …）使用 Go 模板 + Values 变量
>  **灵活参数化**

------

#### **② 安装 Chart → 生成 Release**

```
bash


复制编辑
helm install myapp ./mychart -f values-prod.yaml
```

> Helm 渲染模板 + 应用配置 → 生成 YAML → 调用 kube-apiserver → 创建 K8s 资源
>  生成的应用实例叫 **Release**
>  **Release = Chart + values + 状态**

------

#### **③ 管理 Release 生命周期**

| 操作      | 说明                     |
| --------- | ------------------------ |
| upgrade   | 升级 Release 配置 / 版本 |
| rollback  | 回滚 Release 到历史版本  |
| list      | 查看当前集群 Release     |
| uninstall | 卸载 Release             |
| history   | 查看 Release 变更历史    |



> Helm 会记录 Release 元数据（默认存在 Secret / ConfigMap），支持版本化管理

------

#### **④ Chart 分发与复用**

> Chart 可以上传到 Helm 仓库（本地 / 远程 Harbor / ChartMuseum）
>  方便团队 / 企业分发与复用

```
bash复制编辑helm repo add stable https://charts.bitnami.com/bitnami
helm search repo nginx
```

------

### **3️⃣ Helm 适合场景**

✅ 快速部署复杂应用（Prometheus / MySQL / MinIO / Ingress-nginx）
 ✅ CI/CD 集成一键部署
 ✅ 多环境部署（dev / prod / test），通过 values.yaml 切换参数
 ✅ 版本管理、回滚能力强

------

### **4️⃣ 项目实战答法（结合你 Prometheus + MinIO 项目）**

> 在我们 Prometheus 监控与 MinIO 集群项目中，我们通过 Helm 管理应用部署：
>
> - 使用 **Prometheus Community Helm Chart** 快速部署 Prometheus + Alertmanager + Grafana
> - 通过 **values.yaml** 定制存储卷路径、Alertmanager 飞书告警、Prometheus scrape job
> - 结合 **Helm upgrade** 实现 Prometheus 版本平滑升级与滚动更新
> - 使用 **MinIO Operator Helm Chart** 部署 MinIO Operator 与 Console
> - 结合 GitLab CI/CD 集成 Helm Release 管理，实现自动化部署与回滚

------

### **5️⃣ Helm vs Operator 区别（面试官爱追问）**

| Helm                | Operator            |
| ------------------- | ------------------- |
| 模板化一次性安装    | 持续调谐管理        |
| 适合无状态/简单应用 | 适合有状态/复杂应用 |
| 不感知应用运行状态  | 实时感知应用状态    |
| CI/CD 友好，快      | 自动化运维强        |



> **一句话** → Helm 适合快速部署，Operator 适合复杂运维

------

### **6️⃣ 一句话总结（面试必背）**

> Helm 通过模板化 Chart 管理 Kubernetes 应用资源，实现一键部署、升级、回滚与版本化管理，是生产环境中常用的应用发布与交付工具。



## 亲和性

### 1️⃣**什么是亲和性 (Affinity)?**

> **Affinity（亲和性）= Pod 调度策略，控制 Pod 调度到哪些 Node 或与哪些 Pod 组合部署**
>  它补充了 nodeSelector，更灵活地表达 Pod 需要「亲近」谁、「远离」谁

------

### **2️⃣ 亲和性分类 (面试重点)**

| 亲和性类型                           | 作用                                      | 触发对象  |
| ------------------------------------ | ----------------------------------------- | --------- |
| **Node Affinity** (节点亲和性)       | 控制 Pod 调度到哪些 Node                  | Node 标签 |
| **Pod Affinity** (Pod 亲和性)        | 控制 Pod 亲近哪些 Pod (和哪些 Pod 在一起) | Pod 标签  |
| **Pod Anti-Affinity** (Pod 反亲和性) | 控制 Pod 远离哪些 Pod (和哪些 Pod 分散)   | Pod 标签  |



✅ **Node Affinity** = Pod 想去哪个 Node (基于 Node 标签)
 ✅ **Pod Affinity/Anti-Affinity** = Pod 想靠近/远离哪些其他 Pod (基于 Pod 标签)

------

### **3️⃣ 亲和性表达式 (面试要讲清)**

| 表达式                                              | 说明                              |
| --------------------------------------------------- | --------------------------------- |
| **requiredDuringSchedulingIgnoredDuringExecution**  | 强制约束 (必须满足，否则不调度)   |
| **preferredDuringSchedulingIgnoredDuringExecution** | 软性偏好 (尽量满足，尽量但不强制) |



------

### **4️⃣ 面试标准答法**

> Kubernetes 亲和性分为 Node Affinity、Pod Affinity 和 Pod Anti-Affinity
>  Node Affinity 控制 Pod 调度到满足 Node 标签条件的节点
>  Pod Affinity 让 Pod 靠近具备特定标签的其他 Pod，适合有数据局部性或通信需求的场景
>  Pod Anti-Affinity 让 Pod 分散部署，提升高可用性
>  亲和性支持「强制 (required)」与「偏好 (preferred)」两种模式，
>  我实际项目中合理利用亲和性优化了服务分布和稳定性

------

### **5️⃣ YAML 示例 (标准写法)**

#### **Node Affinity 示例 (强制)**

```
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: disktype
          operator: In
          values:
          - ssd
```

→ **调度到 Node 上标签 disktype=ssd 的节点**

------

#### **Pod Affinity 示例 (偏好)**

```
affinity:
  podAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - web
        topologyKey: kubernetes.io/hostname
```

→ **尽量和标签 app=web 的 Pod 调度到同一 Node (主机)**

------

#### **Pod Anti-Affinity 示例 (强制)**

```
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - frontend
      topologyKey: kubernetes.io/hostname
```

→ **强制与标签 app=frontend 的 Pod 分散到不同 Node**

------

### **6️⃣ 实际建议 (加分点)**

| 场景               | 推荐亲和性配置           |
| ------------------ | ------------------------ |
| Web+缓存紧密通信   | Pod Affinity (偏好)      |
| 高可用服务分散部署 | Pod Anti-Affinity (强制) |
| GPU 计算任务调度   | Node Affinity (强制)     |
| SSD 存储任务调度   | Node Affinity (强制)     |



✅ **topologyKey**
 常用 `kubernetes.io/hostname` (节点级别)
 也支持 **zone** / **rack** 级别 (实现跨机架/跨区域分布)

------

### **7️⃣ 面试标准背诵版**

> Kubernetes Affinity 分为 Node Affinity、Pod Affinity、Pod Anti-Affinity
>  Node Affinity 控制 Pod 调度到指定标签的节点
>  Pod Affinity 让 Pod 靠近指定 Pod
>  Pod Anti-Affinity 让 Pod 远离指定 Pod，适合做高可用性分布
>  亲和性支持 required 强制和 preferred 软性偏好
>  我实际项目中使用 Pod Anti-Affinity 实现多副本分布到不同节点，保障服务稳定性
>  也通过 Node Affinity 让存储任务优先调度到 SSD 节点，提升性能



## 重启Pod

很好，「**重启 Pod**」也是 Kubernetes 运维面试必考基础题，
 我直接帮你整理清楚：
 ✅ **Pod 为什么要重启**
 ✅ **重启方式分类 (面试要答完整)**
 ✅ **命令示例 (面试要讲得会操作)**
 ✅ **加分项 (项目实战)**

------

### **1️⃣ 为什么要重启 Pod？(面试一定要讲原因)**

| 场景         | 说明                                  |
| ------------ | ------------------------------------- |
| 应用配置变更 | 镜像、环境变量、ConfigMap/Secret 更新 |
| 代码更新     | 新版本镜像发布                        |
| 故障恢复     | 容器异常 (Crash)、探针检测失败        |
| 资源压力     | 内存泄露、性能瓶颈                    |
| 计划运维     | 滚动升级、节点维护                    |



------

### **2️⃣ Pod 重启方式分类 (面试标准答法)**

| 方式                    | 说明                   | 运维命令             |
| ----------------------- | ---------------------- | -------------------- |
| **主动重启 (运维手动)** | 明确操作重启 Pod       | `kubectl delete pod` |
| **被动重启 (K8s自动)**  | K8s 监测失败后重启容器 | 探针失败、OOM        |



------

### **3️⃣ 面试标准答法**

> Pod 重启分为主动重启与被动重启
>  主动重启主要通过 `kubectl delete pod`，控制器会自动拉起新 Pod
>  被动重启则由 K8s 自愈机制触发，比如探针失败、OOMKilled 等
>  合理重启 Pod 能实现配置生效、故障恢复与应用升级
>  我实际项目中常用于发布新版本与修复故障

------

### **4️⃣ 重点命令与操作 (面试要讲得操作熟)**

#### ✅ **主动重启 Pod (最常用)**

```
kubectl delete pod POD_NAME
```

控制器 (Deployment / StatefulSet) 会立刻自动重建 Pod
 ✅ **IP 地址变了**
 ✅ **PVC (持久卷) 复用不变**

------

#### ✅ **重启 Deployment (整体滚动重启)**

```
kubectl rollout restart deployment DEPLOY_NAME
```

✔️ **滚动重启所有 Pod** (优雅、生产推荐)

------

#### ✅ **重启 StatefulSet**

```
kubectl rollout restart statefulset STS_NAME
```

✔️ **有序重启 StatefulSet Pod**

------

#### ✅ **模拟 Pod 容器崩溃 (演示 K8s 自动重启)**

```
kubectl exec POD_NAME -- kill 1
```

容器主进程被杀死 → K8s 立刻重启容器 (因为 RestartPolicy=Always)

------

### **5️⃣ 加分项 (项目实战)**

| 场景           | 实际操作                                                |
| -------------- | ------------------------------------------------------- |
| 发布新版本镜像 | `kubectl set image deployment/nginx nginx=nginx:1.25.5` |
| ConfigMap 变更 | `kubectl rollout restart deployment app`                |
| Node 故障迁移  | 节点驱逐 Pod，自动重启到新节点                          |
| 内存泄露恢复   | `kubectl delete pod` 重启释放资源                       |



------

### **6️⃣ 面试标准背诵版**

> Kubernetes Pod 重启分主动与被动
>  主动通过 kubectl delete pod / rollout restart 等命令
>  被动由 K8s 探针失败、OOMKilled 自动重启
>  我项目中常通过 rollout restart 发布新版本和配置变更
>  也利用 delete pod 快速修复单 Pod 故障
>  合理重启保障应用持续可用与平滑发布



## kubernetes的发布 变更 故障处理

在 Kubernetes 环境中，发布、变更和故障处理是常见的运维任务。为了确保系统稳定性、快速发布和高可用性，通常会采用一系列的最佳实践和工具。我将为你梳理出**Kubernetes的发布、变更和故障处理**的详细策略和操作步骤。

### 1️⃣ **发布策略**

在 Kubernetes 中，发布策略主要通过 `Deployment`、`StatefulSet` 和 `DaemonSet` 进行管理。发布过程需要确保应用更新的平滑过渡和系统稳定。

#### 1.1 **滚动更新 (Rolling Update)**

- **定义**：滚动更新是 Kubernetes 默认的发布方式，逐个替换旧版本的 Pod，确保系统始终保持一定数量的 Pod 在运行。
- **优点**：无需停机，逐步更新避免大规模故障。

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my-app:v2
```

- **如何配置滚动更新：**
  - `maxSurge`：更新时可以超出的 Pod 数量（如超出 1 个）。
  - `maxUnavailable`：更新时可以不可用的最大 Pod 数量（如不可用 1 个）。

```
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
```

#### 1.2 **蓝绿发布 (Blue-Green Deployment)**

- **定义**：蓝绿发布通过创建两个环境（蓝色和绿色环境），在更新应用时，将流量从旧环境切换到新环境。
- **优点**：快速回滚到稳定版本，避免滚动更新中的风险。
- **工具**：可以通过 Kubernetes 的 `Service` 来实现蓝绿发布。

#### 1.3 **金丝雀发布 (Canary Deployment)**

- **定义**：通过逐步将流量从旧版本切换到新版本，通常只将一小部分流量引导到新版本中，逐步扩大直到新版本完全替代旧版本。
- **优点**：控制风险，快速定位问题。

```
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
```

------

### 2️⃣ **变更管理**

在 Kubernetes 中，变更管理通常通过 GitOps、CI/CD 和 Kubernetes 控制台来实现。

#### 2.1 **GitOps 管理**

- **定义**：GitOps 是通过 Git 来管理 Kubernetes 配置文件，确保环境与 Git 仓库中的定义保持一致。
- **工具**：常见的 GitOps 工具有 **ArgoCD**、**Flux**。
- **优点**：自动化、可追溯，减少手动干预。
- **流程**：开发人员将 Kubernetes 配置文件提交到 Git 仓库，GitOps 工具自动同步并应用这些配置。

#### 2.2 **CI/CD 管道**

- **定义**：持续集成 (CI) 和持续交付 (CD) 管道通过自动化构建、测试和发布 Kubernetes 资源来确保应用的快速交付。
- **常用工具**：**Jenkins**、**GitLab CI**、**ArgoCD**、**Tekton**。

#### 2.3 **Kubernetes ConfigMap 和 Secret 管理**

- **定义**：将配置信息和敏感数据（如密码、证书等）管理在 `ConfigMap` 和 `Secret` 中，确保变更的可控性。
- **优点**：支持动态更新、便于管理。

```
kubectl create configmap my-config --from-file=config/
kubectl create secret generic my-secret --from-literal=password=secret
```

#### 2.4 **版本管理和回滚**

- **如何管理**：使用 Kubernetes 的版本控制，跟踪发布历史，并进行回滚。

```
kubectl rollout history deployment my-app
kubectl rollout undo deployment my-app
```

------

### 3️⃣ **故障处理**

在 Kubernetes 集群中，故障处理的核心是自动化恢复、告警和快速定位问题。

#### 3.1 **Pod 重启策略**

- **定义**：Pod 的重启策略可设置为 `Always`、`OnFailure`、`Never`。
  - `Always`：无论容器是否退出，都始终重启。
  - `OnFailure`：仅当容器异常退出时才重启。
  - `Never`：容器退出后不重启。
- **如何设置**：

```
spec:
  restartPolicy: Always
```

#### 3.2 **Pod 健康检查 (Liveness & Readiness Probes)**

- **Liveness Probe**：检查 Pod 是否处于健康状态，若不健康，Kubernetes 会重新启动该 Pod。
- **Readiness Probe**：检查 Pod 是否准备好接收流量，若未就绪，Kubernetes 会停止向该 Pod 转发流量。

```
spec:
  containers:
  - name: my-app
    image: my-app:v2
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /readiness
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
```

#### 3.3 **Pod 优雅关闭 (Graceful Shutdown)**

- **定义**：确保 Pod 被终止时，完成所有处理（如清理资源、关闭连接等）。
- **如何设置**：`terminationGracePeriodSeconds` 配置优雅关闭时间。

```
spec:
  terminationGracePeriodSeconds: 30
```

#### 3.4 **集群资源监控与告警**

- **监控工具**：使用 **Prometheus** 和 **Grafana** 进行资源监控。
- **告警工具**：配置 **Alertmanager**、**Slack**、**PagerDuty** 等进行告警。

#### 3.5 **故障排查步骤**

1. **检查 Pod 状态**：使用 `kubectl get pod` 和 `kubectl describe pod` 检查 Pod 状态。
2. **查看日志**：使用 `kubectl logs <pod-name>` 查看容器日志，分析错误信息。
3. **检查事件**：使用 `kubectl get events` 查看集群事件，识别问题。
4. **集群状态**：使用 `kubectl get nodes` 检查节点状态，确保节点健康。

------

### 📋 **面试答题模板**

> 在 Kubernetes 中，我们通过多种发布策略确保应用高可用性，如滚动更新、蓝绿发布、金丝雀发布等。
>  发布时，使用 `Deployment` 或 `StatefulSet` 进行管理，确保无缝更新。在发布过程中，我们会通过滚动更新策略来避免停机并确保服务持续可用。
>  变更管理方面，我倾向于使用 GitOps 和 CI/CD 自动化流程来管理应用的发布和配置变更，确保环境一致性和高效交付。
>  对于故障处理，我会依赖 Kubernetes 的健康检查、资源监控（Prometheus、Grafana）以及告警机制（Alertmanager），确保能够及时发现并修复故障。
>  故障处理时，我们会通过查看日志、事件和集群状态来定位问题，并在必要时进行 Pod 重新部署或回滚。



## etcd选举机制

ETCD 是 Kubernetes 的核心组件之一，用于存储集群的所有配置数据和状态信息。为了保证数据的一致性和高可用性，etcd 使用了 **Raft 共识算法** 来进行**选举**和数据复制。下面我们详细解释 etcd 的选举机制和其在高可用中的作用。

------

### 🔧 一、etcd 的基本结构

- etcd 是一个分布式的 key-value 存储系统。
- 每个 etcd 集群节点称为 **member**。
- 所有节点中有一个被选为 **Leader（领导者）**，其他为 **Follower（跟随者）**。
- 所有的写操作必须经过 Leader 处理，然后同步给 Follower。

------

### 🧠 二、选举机制（基于 Raft 算法）

#### 1. 状态角色

etcd 中的每个节点基于 Raft 算法，有以下三种状态：

- **Follower**：初始状态，接收 Leader 的指令。
- **Candidate**：如果长时间未接收到 Leader 的心跳，会发起选举。
- **Leader**：负责处理客户端请求并将日志同步到所有 Follower。

#### 2. 选举流程

当 Follower 超过一定时间（称为 **选举超时 election timeout**，如 150-300ms）没有接收到 Leader 的心跳，它就会转变为 Candidate 并发起选举。

**流程如下：**

1. 候选者自增任期号（term）并投自己一票。
2. 向其他节点发送 **RequestVote RPC** 请求。
3. 接收到超过半数节点的投票（即 N/2 + 1）后，成为新的 Leader。
4. 成为 Leader 后开始发送心跳（AppendEntries RPC）维持领导地位。
5. 如果某个 Candidate 发现有其他节点 term 更大，会退回 Follower 状态。

**示例：3 节点 etcd 集群**

- 节点 A、B、C
- 假设 A 成为 Candidate，并获得 B 和 C 的投票（共 2 票）
- A 成为 Leader
- A 开始负责所有写请求，并同步到 B 和 C

------

### 💡 三、etcd 的高可用性要求

#### 1. **奇数节点部署**

- 推荐部署奇数个节点（如 3、5、7），以确保有法定多数（quorum）。
- 比如 3 个节点的集群中，2 个节点在线就能选出 Leader。

#### 2. **没有多数 quorum 就无法工作**

- 如果一个 5 节点集群宕掉 3 个，只剩 2 个节点，则无法选出 Leader，集群不可写入（读操作默认也被限制）。

------

### 🛠️ 四、写入流程简要说明（基于 Leader）

1. 客户端向 etcd 发起写请求（PUT、DELETE）。
2. 请求到达 Leader，Leader 将请求以日志条目形式写入本地日志。
3. Leader 将该日志条目发送给所有 Follower。
4. 超过半数的节点（包括自己）响应成功后，Leader 将该日志提交，并应用到状态机。
5. Leader 返回客户端成功响应。

------

### 🚨 五、故障恢复与自动选举

- 如果 Leader 宕机，其它 Follower 会自动在 `election timeout` 过后发起新一轮选举。
- 新 Leader 会从上一任 Leader 的日志继续同步。

------

### ✅ 六、面试回答参考模板

> etcd 使用了 Raft 分布式共识算法来确保集群中的数据一致性和高可用性。集群中的节点角色分为 Leader 和 Follower，所有写操作都必须由 Leader 执行并同步到多数 Follower 节点。
>
> 在发生故障（如 Leader 节点宕机）时，其他 Follower 会在 election timeout 后发起选举，争取成为新的 Leader，只要多数节点（如3节点中2个）存活，就可以选出新 Leader，从而保障 etcd 和整个 Kubernetes 控制平面的正常工作。



## raft协议

Raft 协议是一个 **分布式一致性算法**，被 etcd、Consul、TiKV 等广泛使用。它的设计目标是**易于理解**，并且能提供类似 Paxos 的强一致性。在 Kubernetes 中，etcd 通过 Raft 协议实现 Leader 选举和数据复制，确保集群状态一致性。

------

### 🌟 一、Raft 协议的核心目标

Raft 解决的问题：

> **如何让多个服务器（节点）在面对网络分区或节点故障时，仍能达成一致决策并保持数据一致？**

------

### 🧠 二、Raft 的核心概念

Raft 把一致性算法分为三个关键组成部分：

| 模块            | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| **Leader 选举** | 确保集群中有唯一的 Leader 节点来接收客户端请求               |
| **日志复制**    | Leader 将客户端请求写入日志，并复制给其他 Follower           |
| **日志一致性**  | 通过任期（term）和索引（index）等机制，确保所有节点日志保持一致 |



------

### 🔄 三、Raft 的三种角色

| 角色          | 说明                                       |
| ------------- | ------------------------------------------ |
| **Leader**    | 负责处理所有客户端请求，管理日志复制与提交 |
| **Follower**  | 被动响应 Leader 或 Candidate 请求          |
| **Candidate** | 发起选举，试图成为 Leader                  |



------

### 📶 四、Leader 选举过程

1. **初始所有节点是 Follower**。
2. 若 Follower 在一定时间内未收到 Leader 的心跳，变成 Candidate。
3. Candidate 发起选举（term+1），请求其他节点投票。
4. 若获得多数（n/2+1）票，成为 Leader。
5. 成为 Leader 后，定期发送心跳（AppendEntries RPC）保持权威。

------

### 🗃️ 五、日志复制机制

1. 客户端向 Leader 提交写请求。
2. Leader 将请求以 **日志条目（log entry）** 的形式写入本地。
3. Leader 向所有 Follower 发送日志条目（AppendEntries RPC）。
4. 若 **多数节点** 写入成功，Leader 提交日志，并更新状态。
5. 日志提交成功后，Leader 回复客户端。

------

### 🔄 六、日志一致性机制

- 每条日志都有 `term` 和 `index`。
- Follower 接收 AppendEntries 时，会检查日志前项是否匹配（前项不一致就拒绝）。
- 若日志有冲突，Leader 强制替换 Follower 的日志，保持一致。

------

### 🧨 七、网络分区与故障恢复

- 如果 Leader 宕机，其余节点将在 election timeout 后重新选举。
- 保证只有一个 Leader 存在。
- 新 Leader 会带着最新日志，强制同步落后节点，确保一致。

------

### ✅ 八、Raft 的特性总结

| 特性       | 描述                                           |
| ---------- | ---------------------------------------------- |
| 强一致性   | 多节点在网络不可靠时依然保持数据一致           |
| 自动恢复   | 节点故障或网络中断后能自动选主并恢复           |
| 顺序提交   | 所有日志提交顺序一致，状态机应用结果一致       |
| 容错性强   | 可以容忍少数节点宕机（例如3节点可容忍1个宕机） |
| 简单易理解 | 相比 Paxos 更直观，便于实现和调试              |



------

### 📋 面试回答模板（Raft）

> Raft 协议是一种强一致性的共识算法，被广泛应用于分布式系统中。它将一致性流程划分为三个核心部分：Leader 选举、日志复制和日志一致性。在 etcd 中，通过 Raft 协议选出一个 Leader 节点来处理所有写入请求。
>  所有写入操作先由 Leader 写入日志，然后同步给多数 Follower，待大多数节点确认后再提交到状态机。这样能保证集群中即使有节点宕机，系统也能保持一致性。Raft 相比 Paxos 更容易实现和理解，适合应用在工程实践中。



## 限制两个名称空间A，B可以相互访问，其他的名称空间全部都拒绝访问

你想要实现的目标是：

> **仅允许 Kubernetes 中的 A 和 B 两个命名空间之间互相通信，其他命名空间与它们互相都禁止访问。**

这个需求涉及到的是 **网络层访问控制**，Kubernetes 中控制命名空间之间通信的常用方式是 **NetworkPolicy（网络策略）**。

------

### ✅ 实现思路

1. 前提是：**集群使用了支持 NetworkPolicy 的 CNI 插件**（如 Calico、Cilium、Weave Net 等）。
2. 为命名空间 **A 和 B** 配置 **互相允许通信的规则**。
3. 默认拒绝所有来自其他命名空间的访问。

------

### ✅ 步骤详解

#### 第一步：为 A 和 B 添加标签（便于网络策略匹配）

```
kubectl label ns A ns=ns-a
kubectl label ns B ns=ns-b
```

------

#### 第二步：在 A 命名空间中创建网络策略，只允许 B 通信

```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-namespace-b
  namespace: A
spec:
  podSelector: {}  # 作用于 A 命名空间的所有 Pod
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          ns: ns-b  # 允许来自 B 的命名空间
  policyTypes:
  - Ingress
```

------

#### 第三步：在 B 命名空间中创建网络策略，只允许 A 通信

```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-namespace-a
  namespace: B
spec:
  podSelector: {}
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          ns: ns-a
  policyTypes:
  - Ingress
```

------

#### 第四步：默认拒绝其它命名空间通信

网络策略的特点是：

> **一旦一个命名空间下的 Pod 被任何 NetworkPolicy 选中后，未明确允许的流量将默认被拒绝。**

因此，上面的配置已经达成目标：

- **A 只接受来自 B 的访问**
- **B 只接受来自 A 的访问**
- **其他命名空间都不能访问 A 和 B**
- **A 和 B 也不能访问其他命名空间（因为没有允许出去的 egress）**

------

#### ✅（可选）加强策略：禁止 A/B 访问其他命名空间（出站）

为了更严格控制，也可以加上出站（egress）限制，例如：

```
# namespace A: 只允许访问 namespace B
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-egress-to-namespace-b
  namespace: A
spec:
  podSelector: {}
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          ns: ns-b
  policyTypes:
  - Egress
```

B 同样做类似配置，防止 B 随意访问其他命名空间。

------

### ✅ 总结

| 目标                     | 配置方式                                              |
| ------------------------ | ----------------------------------------------------- |
| A、B 之间互通            | NetworkPolicy + namespaceSelector                     |
| 禁止其他命名空间访问 A/B | 不为其配置 allow 网络策略                             |
| A/B 禁止访问其它命名空间 | 添加 `egress` 限制                                    |
| 要求插件支持             | 需使用支持 NetworkPolicy 的 CNI，如 Calico、Cilium 等 |





# skywalking

## **SkyWalking 生产部署架构图（标准版）**

```postgresql
                        +-----------------+
                        | SkyWalking UI   | <--- Web界面 (链路拓扑/Trace/告警)
                        +-----------------+
                                 |
                                 v
+--------------------------------------------------------------+
|                        SkyWalking OAP Server                 |
|                                                              |
| +----------------+    +------------------+   +-------------+ |
| | Receiver (gRPC)|    | Trace Aggregator |   | Metrics     | |
| | / HTTP         | -> | Trace Analysis   |   | Analysis    | |
| +----------------+    +------------------+   +-------------+ |
|         |                                |           |        |
|         |                                |           v        |
|         |                                |    +--------------+|
|         |                                |    | Alarm Module ||
|         |                                |    +--------------+|
|         |                                |                    |
|         v                                v                    |
|   +-----------------+      +---------------------+           |
|   | Storage Layer   |----> | ElasticSearch/BanyanDB/MySQL |  |
|   +-----------------+      +---------------------+           |
+--------------------------------------------------------------+
                                 ^
                                 |
                        Agent 批量上报 (gRPC / HTTP)
                                 ^
                                 |
+----------------------+      +----------------------+      +----------------------+
| Java App (Service A) |      | Java App (Service B) |      | Java App (Service C) |
|  SkyWalking Agent    |      |  SkyWalking Agent    |      |  SkyWalking Agent    |
+----------------------+      +----------------------+      +----------------------+
```

**架构说明：**

✅ **Agent**
 — 部署在每个微服务中（无侵入）
 — 采集 Trace / Metrics / Logs
 — 通过 gRPC/HTTP 上报 OAP

✅ **OAP Server**
 — 接收并聚合 Trace 数据
 — 计算服务指标 / 分析调用链
 — 存储数据到 ElasticSearch / BanyanDB
 — 触发告警并暴露 UI 查询接口

✅ **UI**
 — 展示拓扑图、调用链、性能指标
 — 提供 Trace 检索、慢接口分析
 — 集成告警视图

✅ **存储层**
 — ElasticSearch 常用，支撑 Trace 快速检索
 — BanyanDB（SkyWalking 原生时序数据库），更适合海量指标

✅ **告警集成**
 — 飞书、钉钉、Prometheus AlertManager

------

## **SkyWalking Agent 生产配置模板（Java）**

#### **agent.config**

```properties
# 1. SkyWalking OAP Server 地址
collector.backend_service=skywalking-oap:11800

# 2. 应用标识（服务名/实例名）
agent.service_name=oa-system-service
agent.instance_name=${HOSTNAME}

# 3. 采样率 (默认100%采样，生产建议降采样)
# 全量采样
sampling.n_per_3_secs=-1  
# 每3秒采集10个
# sampling.n_per_3_secs=10

# 4. 日志/链路 关联上下文传播
plugin.toolkit.log.transmit_formatted=true

# 5. 高级设置（可选）
# buffer 大小，防止丢数据
agent.buffer_size=5000

# 6. 日志级别（可调试）
logging.level=INFO
```

------

#### **JVM 启动参数**

```bash
-javaagent:/data/skywalking-agent/skywalking-agent.jar
-Dskywalking.agent.service_name=oa-system-service
```

------

### **生产优化建议（面试加分项）**

✅ **采样率控制**
 — 低QPS服务可以全量采样
 — 高QPS服务配置「每秒 N 条采样」+ 重要接口白名单采样

✅ **多OAP Server 高可用**

```
collector.backend_service=oap1:11800,oap2:11800
```

✅ **数据保留周期控制**
 — ElasticSearch ILM / BanyanDB TTL 设定，控制存储空间

✅ **链路日志整合**
 — Agent 配置日志传输 + Logstash 关联 TraceID，Trace / Metrics / Log 三合一

✅ **告警配置**
 — OAP 侧配置告警规则（响应时间 / 错误率 / 调用量），结合 飞书/Prometheus 推送

------

### **一句话总结（面试必背）**

> SkyWalking 生产部署通过 Agent → OAP Server → 存储层（ES）+ UI 构建全链路可观测平台，结合高可用架构、合理采样、数据保留与告警策略，保障大规模微服务集群的链路追踪与性能分析。



------

## **SkyWalking OAP 高可用部署 YAML 模板（生产级）**

> **部署目标**
>  SkyWalking OAP Server 多实例（2副本起步），负载均衡 + 高可用，结合 ElasticSearch 存储
>  （适合 K8s 集群 / 私有云 / 物理机）

### **1️⃣ SkyWalking OAP Deployment + Service**

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skywalking-oap
  namespace: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: skywalking-oap
  template:
    metadata:
      labels:
        app: skywalking-oap
    spec:
      containers:
      - name: oap
        image: apache/skywalking-oap-server:9.5.0
        ports:
        - containerPort: 11800  # gRPC
        - containerPort: 12800  # HTTP
        env:
        - name: SW_STORAGE
          value: elasticsearch
        - name: SW_STORAGE_ES_CLUSTER_NODES
          value: elasticsearch:9200
        - name: JAVA_OPTS
          value: "-Xms2G -Xmx2G"

---
apiVersion: v1
kind: Service
metadata:
  name: skywalking-oap
  namespace: observability
spec:
  selector:
    app: skywalking-oap
  ports:
  - name: grpc
    port: 11800
    targetPort: 11800
  - name: http
    port: 12800
    targetPort: 12800
  type: ClusterIP
```

------

### **2️⃣ SkyWalking UI Deployment + Service**

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skywalking-ui
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: skywalking-ui
  template:
    metadata:
      labels:
        app: skywalking-ui
    spec:
      containers:
      - name: ui
        image: apache/skywalking-ui:9.5.0
        ports:
        - containerPort: 8080
        env:
        - name: SW_OAP_ADDRESS
          value: http://skywalking-oap:12800

---
apiVersion: v1
kind: Service
metadata:
  name: skywalking-ui
  namespace: observability
spec:
  selector:
    app: skywalking-ui
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
```

------

### **3️⃣ Java Agent 配置多 OAP Server 高可用**

```
collector.backend_service=skywalking-oap:11800
```

> SkyWalking Agent 自动做「负载均衡 + 断点续传」
>  无需人工切换，OAP 副本扩容后自动均衡

------

## **Elasticsearch ILM（索引生命周期管理）策略模板**

> **目的**
>  控制 SkyWalking 数据在 ElasticSearch 中的存储周期，防止磁盘爆满，提高查询性能
>  （SkyWalking Trace/Metric 索引量大，必须配 ILM）

**ILM 策略示例：保留 7天**

```
PUT _ilm/policy/skywalking_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "3d"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

------

**索引模板绑定 ILM 策略**

```
PUT _template/skywalking_template
{
  "index_patterns": ["sw_*"],
  "settings": {
    "index.lifecycle.name": "skywalking_policy",
    "index.lifecycle.rollover_alias": "skywalking_alias",
    "number_of_shards": 3,
    "number_of_replicas": 1
  }
}
```

------

### **生产实践总结（面试加分句）**

> 我们生产中 SkyWalking 采用 OAP Server 多副本部署实现高可用，结合 ElasticSearch ILM 策略控制 Trace 数据 7天滚动删除，保障平台稳定性与存储资源可控，同时结合 Prometheus 监控 OAP / ES 集群健康状态，实现可观测平台的稳定运行。



------

## **SkyWalking + Prometheus Exporter 监控配置**

> **目的**
>  把 SkyWalking OAP Server 运行状态与核心指标暴露给 Prometheus，统一纳入企业监控体系，结合 Grafana 可视化 + 告警
>  （比如 OAP Server QPS、Trace 处理量、GC情况等）

### **1️⃣ OAP Server 开启 Prometheus Metrics 端点**

SkyWalking OAP 默认支持 Prometheus metrics，只要打开 **telemetry** 配置

```
# skywalking-oap config/application.yml
telemetry:
  prometheus:
    host: 0.0.0.0
    port: 1234
```

> 这会在 OAP Server 开启 **http://oap:1234/metrics** 端点
>  Prometheus 通过 HTTP 拉取指标

------

### **2️⃣ Prometheus 添加 scrape 配置**

```
# prometheus.yml
scrape_configs:
  - job_name: 'skywalking-oap'
    metrics_path: /metrics
    static_configs:
      - targets: ['skywalking-oap:1234']
```

------

### **3️⃣ 典型监控指标**

| 指标                            | 含义                    |
| ------------------------------- | ----------------------- |
| skywalking_oap_trace_count      | 每秒处理 Trace 数量     |
| skywalking_oap_instance_gauge   | OAP Server 实例数       |
| skywalking_oap_analysis_latency | Trace 分析延迟          |
| jvm_memory_used_bytes           | OAP Server JVM 内存使用 |
| jvm_gc_pause_seconds            | OAP Server GC 停顿时长  |



------

### **4️⃣ Grafana Dashboard**

- 监控 OAP Server 性能：CPU、内存、GC、Trace 处理量
- 监控 Trace 上报量变化，预警数据堆积

> 生产建议**OAP Server CPU < 70% / Trace 分析延迟 < 500ms**

------



## **SkyWalking OAP 飞书告警配置（内置告警体系）**

> **目的**
>  SkyWalking OAP 内置告警模块，支持把服务指标/链路异常等告警自动推送飞书、钉钉、Webhook

------

### **1️⃣ 配置飞书 Webhook**

- 飞书群 → 添加机器人 → 获取 Webhook URL

```
https://open.feishu.cn/open-apis/bot/v2/hook/xxxxxxx
```

------

### **2️⃣ SkyWalking OAP 告警配置**

#### **alarm-settings.yml**

```
rules:
  - name: service_resp_time_rule
    metrics-name: service_resp_time
    op: ">"
    threshold: 500
    period: 10
    count: 3
    silence-period: 5
    message: "服务响应时间超500ms，请排查: {{service}}"

# 说明: 
# - 目标指标: service_resp_time
# - 条件: 连续3个周期大于500ms，触发告警
```

------

#### **webhook.yml**

```
webhooks:
  - url: "https://open.feishu.cn/open-apis/bot/v2/hook/xxxxxxx"
    headers:
      Content-Type: application/json
```

------

### **3️⃣ 告警触发效果（飞书消息示例）**

```makefile
[SkyWalking 告警]
服务: oa-system-service
问题: 服务响应时间超500ms，请排查: oa-system-service
时间: 2025-05-10 14:33:12
```

------

### **4️⃣ 生产经验建议（面试加分项）**

✅ 告警维度
 — 服务响应时间 / QPS / Trace 失败率 / Trace 栈异常关键字

✅ 告警合并
 — 同一服务告警聚合，防止飞书消息爆炸

✅ 告警闭环
 — 告警触发 → 飞书通知 → 链接 SkyWalking UI Trace 详情 → 快速定位

------

### **一句话总结（面试必背）**

> 我们生产通过 SkyWalking OAP Prometheus Exporter 接入 Prometheus 统一监控，结合 Grafana Dashboard 展示 Trace 处理与 OAP 资源状态，同时启用 SkyWalking 内置告警推送飞书，实现链路异常与性能瓶颈的实时预警与快速定位，保障可观测平台高可用性。

------

✅ 这套答法「部署 + 监控 + 告警 + 运维闭环」完整
 ✅ 直接把面试官带入你项目环境，**可信度爆表**



## **SkyWalking 生产典型告警规则清单（面试背诵版）**

| 告警名称               | 监控指标                    | 触发条件          | 生产意义                  |
| ---------------------- | --------------------------- | ----------------- | ------------------------- |
| **服务响应慢**         | service_resp_time           | > 500ms 持续 3次  | 发现慢接口、性能瓶颈      |
| **QPS 异常下降**       | service_cpm                 | < 10 持续 3次     | 服务崩溃 / 请求流量异常   |
| **异常率过高**         | service_sla                 | < 95% 持续 3次    | 接口错误率过高，故障苗头  |
| **数据库慢查询**       | database_access_resp_time   | > 200ms 持续 3次  | SQL 性能瓶颈 / 死锁风险   |
| **外部依赖异常**       | endpoint_relation_resp_time | > 300ms 持续 3次  | 下游服务 / 三方接口慢     |
| **OAP Server GC 频繁** | jvm_gc_time                 | > 1000ms 持续 3次 | SkyWalking 后端内存压力大 |
| **Trace 丢失率高**     | trace_error_rate            | > 5% 持续 3次     | 链路采集异常 / Agent 问题 |
| **服务实例崩溃**       | instance_last_ping          | 断连 > 60s        | 应用实例宕机 / Pod Crash  |
| **服务调用超时**       | service_relation_resp_time  | > 300ms 持续 3次  | 微服务间调用链路异常      |



------

### **面试答法模版（直接背）**

> 我们生产中常用 SkyWalking 典型告警规则包括：
>
> - 服务响应慢：service_resp_time > 500ms，定位接口性能瓶颈
> - QPS 异常下降：service_cpm < 10，快速发现服务崩溃
> - 异常率过高：service_sla < 95%，提示接口错误率升高
> - 数据库慢查询：database_access_resp_time > 200ms，发现 SQL 性能问题
> - 外部依赖异常：endpoint_relation_resp_time > 300ms，监测三方接口稳定性
> - OAP Server GC 频繁，保障监控平台自身稳定性

> 告警触发后，我们通过飞书通知并跳转 SkyWalking UI 追踪链路详情，实现问题快速定位与闭环处理。

------

### **加分点：告警策略设计原则**

✅ 指标阈值合理（避免误报 / 漏报）
 ✅ 连续多周期确认（去抖动）
 ✅ 告警分级（一般 / 严重 / 紧急）
 ✅ 关联 Trace ID，快速定位异常链路
 ✅ 告警静默（silence-period）防止重复告警

------

### **一句话总结（面试必背）**

> 我们生产常用 SkyWalking 告警包括服务响应慢、QPS 异常下降、异常率过高、数据库慢查询和服务崩溃，结合合理阈值和飞书告警机制，保障业务链路性能与稳定性。



# MySQL

## 主从复制的三个核心线程

| 线程类型               | 作用                             | 运行位置 |
| ---------------------- | -------------------------------- | -------- |
| **Binlog Dump Thread** | 把主库 binlog 传给从库           | 主库     |
| **I/O Thread**         | 从主库读取 binlog 并写到中继日志 | 从库     |
| **SQL Thread**         | 读取中继日志，执行 SQL 更新      | 从库     |

**两个日志**

| 日志名称                  | 作用                                 | 所在位置 |
| ------------------------- | ------------------------------------ | -------- |
| **Binlog**（二进制日志）  | 主库记录所有数据更改操作（用于复制） | 主库     |
| **Relay Log**（中继日志） | 从库接收主库 binlog 后存储下来的副本 | 从库     |

```
[主库]
  应用执行写操作（INSERT/UPDATE/DELETE）
        ↓
  记录变更到 Binlog（二进制日志）
        ↓
  Binlog Dump Thread 把日志发送给从库
        ↓

[从库]
  I/O Thread 连接主库，接收 Binlog → 写入中继日志（relay-log）
        ↓
  SQL Thread 读取中继日志，执行相同的 SQL
        ↓
  从库数据更新完成，与主库保持同步

```



## mysql主从再从新增加一个从库



在 MySQL 主从架构中，**新增一个从库**（从现有主库或从库复制数据）是运维中非常常见的操作，特别是在读写分离场景下。下面是标准的操作流程，适合面试或实战使用。

------

### ✅ 场景：已有结构如下

```
MySQL 主库：      192.168.10.10 （master）
MySQL 从库1：     192.168.10.11 （slave1）

➡ 现在要新增：MySQL 从库2：192.168.10.12（slave2）
```

------

### ✅ 一、新增从库的操作流程

#### 步骤 1：**在主库或已有从库上查看当前 binlog 信息**

```
-- 登录主库或任意一个已有从库（一般选主库）
SHOW MASTER STATUS;
```

输出示例：

```
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000123 |   456789 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
```

记下 `File` 和 `Position` 值（假设是：`mysql-bin.000123` 和 `456789`）。

------

#### 步骤 2：**将数据从主库或现有从库同步到新的从库**

方式有三种（推荐顺序）：

##### ✅ 推荐 A：使用已有从库的快照（如 slave1）

```
mysqldump -uroot -p --all-databases --master-data=2 > full_backup.sql
scp full_backup.sql root@192.168.10.12:/tmp/
```

在新从库（slave2）中恢复：

```
mysql -uroot -p < /tmp/full_backup.sql
```

> `--master-data=2` 表示在 dump 文件中包含 binlog 的位置，供后续 CHANGE MASTER 使用。

------

#### 步骤 3：**配置 slave2 复制主库**

登录 slave2 执行：

```
STOP SLAVE;

CHANGE MASTER TO
  MASTER_HOST='192.168.10.10',
  MASTER_PORT=3306,
  MASTER_USER='replication_user',
  MASTER_PASSWORD='replication_pass',
  MASTER_LOG_FILE='mysql-bin.000123',
  MASTER_LOG_POS=456789;

START SLAVE;

SHOW SLAVE STATUS\G
```

> 请将 `replication_user/replication_pass` 替换为你的主库上的复制用户。

------

### ✅ 二、主库上确认复制用户权限（如未配置）

在主库上创建复制账号（仅需一次）：

```
CREATE USER 'replication_user'@'%' IDENTIFIED BY 'replication_pass';
GRANT REPLICATION SLAVE ON *.* TO 'replication_user'@'%';
FLUSH PRIVILEGES;
```

------

### ✅ 三、检查是否成功同步

在新从库上查看状态：

```
SHOW SLAVE STATUS\G
```

确认以下两个字段为 `Yes`：

- `Slave_IO_Running: Yes`
- `Slave_SQL_Running: Yes`

表示复制正常。

------

### ✅ 四、注意事项

| 项        | 建议                                                  |
| --------- | ----------------------------------------------------- |
| 防火墙    | 确保主库 `3306` 端口对从库开放                        |
| 延迟监控  | 关注 `Seconds_Behind_Master`，监控复制延迟            |
| GTID 模式 | 若启用了 GTID，则需使用 `MASTER_AUTO_POSITION=1` 配置 |



------

### ✅ 五、面试总结答法（标准回答）

> 在生产中新增从库时，我们一般从已有主库或从库导出快照，通过 mysqldump 或物理备份同步数据，然后使用 `CHANGE MASTER TO` 配置复制关系
>  最后通过 `SHOW SLAVE STATUS` 确认同步是否成功。我们通常也会在主库上创建只读复制用户以保证权限安全，并配置告警系统监控同步状态。



## mysql主从复制原理

MySQL 主从复制是数据库常见的高可用与读写分离架构，**面试时常问：MySQL 主从复制是怎么实现的？**下面是详细的原理解析，适合你在面试中系统讲解。

------

### ✅ 一、主从复制的核心机制（标准三步走）

MySQL 的主从复制采用 **异步复制机制**（支持半同步、全同步），核心原理为 **三步复制流程**：

```
客户端 → 主库（写操作） → binlog → 从库（读取 binlog） → 执行 SQL
```

------

### ✅ 二、主从复制的三大阶段

| 阶段                         | 描述                                                        |
| ---------------------------- | ----------------------------------------------------------- |
| ① 写入 binlog（主库）        | 主库将数据变更记录写入 binlog 日志文件                      |
| ② 传输 binlog（I/O 线程）    | 从库 I/O 线程连接主库，拉取 binlog 内容并写入本地 relay log |
| ③ 应用 relay log（SQL 线程） | 从库 SQL 线程解析 relay log 并按顺序重放执行，达到数据一致  |



------

### ✅ 三、复制线程结构图（主从端）

```
[主库]
  |
  |-- binlog 记录 SQL 写入操作
  |
[从库]
  |-- I/O 线程：连接主库并获取 binlog，写入 relay log
  |-- SQL 线程：解析 relay log 并执行 SQL，完成数据同步
```

------

### ✅ 四、复制方式（常被问）

| 模式             | 描述                                                         |
| ---------------- | ------------------------------------------------------------ |
| 异步复制（默认） | 主库提交事务后即返回客户端，从库异步复制，**快但可能延迟或数据丢失** |
| 半同步复制       | 主库至少等待一个从库确认 binlog 写入，再返回客户端           |
| 全同步复制       | 主库等待 **所有从库** 写入 binlog 后才返回，**最安全但性能最差**（极少用） |



------

### ✅ 五、数据一致性说明

- 异步复制可能会有延迟（`Seconds_Behind_Master > 0`）
- 需依靠 GTID 或 binlog 位置确保复制完整性
- 为防止数据不一致，**从库禁止写操作**（一般只读）

------

### ✅ 六、复制常用配置参数

主库 `my.cnf`：

```
server-id=1
log-bin=mysql-bin
binlog_format=row
```

从库 `my.cnf`：

```
server-id=2
read_only=1
relay_log=relay-bin
```

------

### ✅ 七、面试标准答法总结（背诵模板）

> MySQL 主从复制基于 binlog 日志实现。主库将数据变更写入 binlog，从库通过 I/O 线程拉取 binlog 写入本地 relay log，再由 SQL 线程解析并执行，实现数据同步
>  默认是异步复制，我们可以配置为半同步以提高可靠性。复制过程中的延迟和一致性需要监控 `Seconds_Behind_Master` 等指标，通常通过设置 GTID 和监控告警机制来保障复制准确性。



## MHA结合主从原理

MySQL MHA（Master High Availability）是 MySQL 主从架构中用于**自动故障切换（Failover）和主库高可用**的成熟方案。它适用于基于 **主从复制架构（非 MGR、非 Galera）** 的场景，是面试中常被问到的高可用方案之一。

------

### ✅ 一、MHA 的基本组成

MHA 包含两个角色：

| 组件            | 作用                                                |
| --------------- | --------------------------------------------------- |
| **MHA Manager** | 整个架构的管理者，部署在独立节点，负责监控、切换    |
| **MHA Node**    | 部署在每个 MySQL 主从节点上，支持日志拉取与恢复操作 |



------

### ✅ 二、MHA 支持的主从复制架构

```
        +----------------+
        |     MHA       |
        |   Manager     |
        +-------+--------+
                |
        +-------+-------+
        |     Master     |  ⇦ 正常运行中
        +-------+--------+
                |
        +-------+-------+
        |   Slave1       |
        |   Slave2       |  ⇦ 主从复制架构
        +---------------+
```

------

### ✅ 三、主从 + MHA 高可用的工作原理

当主库宕机时，MHA 会执行以下步骤：

#### 🟡 1. 检测故障（秒级）

- MHA Manager 持续检测主库是否存活
- 一旦发现无法连接（如端口失败、复制失败），认为主库故障

#### 🟠 2. 自动 failover

- 选取复制最完整的从库（`Seconds_Behind_Master 最小`）为新主库
- 将其他从库指向新主库，**重建复制关系**
- 从原主库中拉取未传递 binlog（如还能访问）补齐数据

#### 🔵 3. 切换完成通知

- 更新应用访问地址（如 VIP 或 DNS）
- 发送邮件或记录日志通知切换完成

------

### ✅ 四、核心优势

| 优点              | 描述                                    |
| ----------------- | --------------------------------------- |
| 自动主备切换      | 无需人工介入，几秒内完成主库替换        |
| 日志补全能力      | 能从宕机主库中拉取 binlog，避免数据丢失 |
| 支持读写分离      | 结合 MySQL 主从使用，支持高并发读写场景 |
| 配合 VIP 或 Proxy | 可实现对外统一服务 IP，切换透明         |



------

### ✅ 五、Failover 过程详解图

```
1️⃣ 正常状态
  Master
     |
  Slaves (复制)

2️⃣ 主库故障
  MHA 监测失败

3️⃣ 从库提升为新主库
  最完整的 Slave ⇨ New Master

4️⃣ 重新建立复制
  其余 Slave 指向 New Master

5️⃣ 可选：从原 Master 拉 binlog 恢复缺失数据
```

------

### ✅ 六、MHA 常见配置与使用

主配置文件（`app1.cnf`）示例：

```
[server default]
user=repl
password=repl_pass
manager_workdir=/data/mha
remote_workdir=/data/mha
ssh_user=root

[server1]
hostname=192.168.1.10
port=3306

[server2]
hostname=192.168.1.11
port=3306

[server3]
hostname=192.168.1.12
port=3306
```

------

### ✅ 七、面试总结背诵答法（精简实用）

> 我们在主从架构上使用 MHA 来实现主库高可用。MHA Manager 会监控主库健康状态，一旦主库故障，会自动选择同步最完整的从库提升为新主库
>  然后将其余从库指向新主库，同时尽可能从原主库拉取 binlog 保证数据一致。MHA 的自动化程度高、可靠性强，是 MySQL 高可用方案中非常常见的一种。

------

### ✅ 八、MHA 和其他高可用方案对比（可用于面试补充）

| 高可用方案     | 特点                                                     |
| -------------- | -------------------------------------------------------- |
| MHA            | 传统主从复制基础上实现高可用，部署灵活，支持 binlog 补全 |
| Orchestrator   | 更现代化，支持拓扑发现、手动与自动切换，Web UI           |
| MySQL MGR      | 官方组复制，强一致，但对网络与硬件要求较高               |
| Keepalived+VIP | 简单高效的主从漂移方案，可配合 MHA/Orchestrator 使用     |



## 主从数据不一致解决办法

MySQL 主从复制过程中出现**数据不一致**是生产环境中的一个常见问题，面试中经常会被问到：

> 如果你发现主从数据不一致，你是怎么排查和解决的？

下面给出详尽回答思路，包含排查方法 + 解决方案，适合面试时完整表达。

------

### ✅ 一、主从数据不一致的常见原因

| 原因                | 描述                                                      |
| ------------------- | --------------------------------------------------------- |
| ❌ 从库配置允许写入  | 从库被误写入数据（`read_only=0`）                         |
| ❌ 非确定性函数复制  | 如 `UUID()`, `NOW()`, `RAND()` 等在不同节点执行结果不一致 |
| ❌ 网络抖动/中断     | 主从间 binlog 丢失或未能完整同步                          |
| ❌ SQL 语句非幂等    | 如 `INSERT ... ON DUPLICATE KEY` 导致主从执行结果不同     |
| ❌ 不同存储引擎/参数 | 主从数据库参数不一致，如字符集、排序规则等                |



------

### ✅ 二、排查步骤（实际可操作）

#### 🔍 1. 查看从库复制状态

```
SHOW SLAVE STATUS\G
```

重点关注字段：

- `Seconds_Behind_Master`
- `Last_SQL_Error`
- `Last_IO_Error`
- `Exec_Master_Log_Pos` / `Read_Master_Log_Pos`

是否有错误信息，如 `Duplicate entry`, `Table doesn't exist` 等。

------

#### 🔍 2. 对比主从数据一致性（以下工具推荐背诵）

| 工具                        | 用途                      |
| --------------------------- | ------------------------- |
| `pt-table-checksum`         | 主从数据对比（推荐）      |
| `mysqldump` + diff          | 导出表结构和数据后比对    |
| `SELECT COUNT(*) / CRC32()` | 小表可手动对比行数或 hash |



示例：pt-table-checksum

```
pt-table-checksum --user=root --password=xxx --host=master_ip
```

------

### ✅ 三、解决办法（按类型分类）

#### 🧯 方案一：从库被误写，修复方案

- 设置从库只读：

  ```
  SET GLOBAL read_only=1;
  SET GLOBAL super_read_only=1;
  ```

- 使用 `pt-table-sync` 工具同步主库数据：

  ```
  pt-table-sync --execute --sync-to-master --user=root --password=xxx --host=slave_ip
  ```

------

#### 🧯 方案二：复制中断/报错，跳过修复

临时解决，**慎用**（可能跳过有用数据）：

```
STOP SLAVE;
SET GLOBAL sql_slave_skip_counter = 1;
START SLAVE;
```

------

#### 🧯 方案三：主从差异大，重新搭建从库

适用于数据不一致较严重场景：

```
# 1. 主库锁表（可选）
FLUSH TABLES WITH READ LOCK;

# 2. 备份主库数据
mysqldump -uroot -p --all-databases --master-data=2 > full.sql

# 3. 导入到新从库

# 4. 配置复制参数
CHANGE MASTER TO ...;
START SLAVE;
```

------

### ✅ 四、如何预防数据不一致（可做总结）

| 预防措施                                | 说明                                   |
| --------------------------------------- | -------------------------------------- |
| ✅ 开启 `read_only` 和 `super_read_only` | 避免从库被误写                         |
| ✅ 使用 GTID 模式复制                    | 避免 binlog 丢失                       |
| ✅ 采用 `ROW` 格式 binlog                | 行级日志更安全，防止语义偏差           |
| ✅ 开启复制监控                          | 监控 `Seconds_Behind_Master`、复制错误 |
| ✅ 禁用非确定性函数                      | 尽量避免 `NOW()`、`RAND()` 等          |



------

### ✅ 面试答题模板（总结型）

> 如果主从数据不一致，我会先通过 `SHOW SLAVE STATUS` 查看复制状态和报错信息。然后使用 `pt-table-checksum` 检查数据是否一致



## mysql优化

### 1️⃣ **查询优化**

#### 1.1 **使用合适的索引**

- **添加索引**：确保对查询中涉及的列（尤其是 `WHERE` 和 `JOIN` 字段）建立合适的索引。
- **避免冗余索引**：检查索引是否重复，可以通过 `SHOW INDEX` 查看现有索引。
- **复合索引**：对于多个列的查询，可以使用复合索引（多个列的组合索引）来提高查询效率。
- **避免在索引列上使用 `LIKE` 模糊查询**：如果前缀匹配（`LIKE 'abc%'`）可以使用索引，但通配符开头的查询（`LIKE '%abc'`）会导致全表扫描。

#### 1.2 **使用 `EXPLAIN` 分析查询**

- 使用 `EXPLAIN` 或 `EXPLAIN ANALYZE` 分析查询计划，识别慢查询并找到问题所在。
- 查找可能的全表扫描、文件排序等问题，并考虑加索引或修改查询逻辑。

```
EXPLAIN SELECT * FROM users WHERE age > 30;
```

#### 1.3 **避免SELECT ***

- 在查询时避免使用 `SELECT *`，明确指定需要的字段，避免不必要的 I/O 操作。

#### 1.4 **优化 `JOIN` 操作**

- 对于 `JOIN` 操作，确保连接条件字段有索引。
- 使用合适的 `JOIN` 类型，尽量避免 `N+1` 查询问题，避免大量不必要的查询。

```
SELECT u.name, o.order_date
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.order_date > '2024-01-01';
```

------

### 2️⃣ **配置优化**

#### 2.1 **缓冲区和缓存调整**

- **key_buffer_size**：适用于 MyISAM 存储引擎，设置为系统内存的 25-50%。
- **innodb_buffer_pool_size**：适用于 InnoDB 存储引擎，设置为系统内存的 70-80%。
- **query_cache_size**：可以开启查询缓存来加速重复查询（适用于读多写少的场景）。

```
innodb_buffer_pool_size = 8G
key_buffer_size = 512M
query_cache_size = 64M
```

### 2.2 **连接管理**

- **max_connections**：根据访问量调节最大连接数，防止连接过多导致内存溢出。
- **wait_timeout**：避免长期不活跃的连接占用资源，设置适当的超时值。
- **thread_cache_size**：适当配置线程缓存，提高线程重用率。

```
max_connections = 1000
wait_timeout = 300
thread_cache_size = 64
```

------

### 3️⃣ **硬件资源优化**

#### 3.1 **存储优化**

- **磁盘IO性能**：使用高性能的 SSD 或 RAID 10 配置以提高磁盘读写性能，避免使用 RAID 5。
- **调整数据文件和日志文件的存储位置**：将数据文件（`datadir`）和日志文件（`log_bin`）分别放在不同的磁盘上以减少磁盘瓶颈。

#### 3.2 **内存优化**

- 适当增加内存，确保可以缓存尽可能多的数据。
- 使用 `vmstat`、`iostat` 等工具监控内存使用情况，避免内存频繁交换（swap）。

#### 3.3 **网络优化**

- 确保数据库网络与应用网络之间的带宽不受限制，避免网络延迟和吞吐量瓶颈。
- 在高并发场景下，可以使用 **TCP_NODELAY**，确保延迟较低。

------

#### 4️⃣ **表设计优化**

#### 4.1 **规范化设计**

- 确保数据库表按照第三范式（3NF）规范化设计，避免冗余数据存储。

#### 4.2 **表分区**

- 对大表进行分区，可以根据时间、范围等进行分区，使得查询时能够快速定位需要的分区数据。

```
CREATE TABLE logs (
  log_id INT,
  log_date DATE,
  message TEXT
) PARTITION BY RANGE (YEAR(log_date)) (
  PARTITION p0 VALUES LESS THAN (2023),
  PARTITION p1 VALUES LESS THAN (2024),
  PARTITION p2 VALUES LESS THAN (2025)
);
```

#### 4.3 **避免数据类型过大**

- 确保字段数据类型适当，避免过大的字段类型。例如，`VARCHAR(255)`，如果实际需求是 `VARCHAR(50)`，就不要设置成 255。
- 使用适当的整数类型（`TINYINT`, `SMALLINT`）而不是大整数类型来节省空间。

------

### 5️⃣ **慢查询优化**

#### 5.1 **开启慢查询日志**

- 开启慢查询日志并分析哪些查询耗时过长，进行针对性的优化。

```
slow_query_log = 1
slow_query_log_file = /var/log/mysql/mysql-slow.log
long_query_time = 1
```

#### 5.2 **分析慢查询**

- 使用 `mysqldumpslow` 或 `pt-query-digest` 工具分析慢查询日志，找出瓶颈查询并优化。

```
mysqldumpslow -s t /var/log/mysql/mysql-slow.log
```

------

### 6️⃣ **备份和恢复优化**

#### 6.1 **增量备份**

- 使用 `mysqldump` 配合 `--single-transaction` 参数进行增量备份，减少对数据库的锁定时间。

#### 6.2 **异步备份**

- 使用 **Percona XtraBackup** 等工具进行异步备份，避免全表锁定影响在线业务。

------

### 📋 **面试标准答题模板 (直接背)**

> 我曾在生产环境中进行过多次 MySQL 优化，主要优化了查询、配置、硬件和表设计等方面
>  例如，在查询优化方面，我通过添加合适的索引、使用 `EXPLAIN` 分析查询，减少了全表扫描并提高了查询效率
>  在配置方面，我调整了 `innodb_buffer_pool_size`（MySQL InnoDB 存储引擎的核心内存区域）、`max_connections`（最大连接数）和 `query_cache_size` （查询缓存大小）等参数，显著提高了数据库的性能
>  另外，我还通过合理的硬件资源分配（如 SSD 存储和内存优化）和表分区技术，提升了数据库在大数据量下的处理能力
>  我能够通过分析慢查询日志进行针对性优化，提升了系统的响应速度和稳定性

------

### 💡 **加分项**

- 使用 **ProxySQL** 作为数据库中间层进行负载均衡和流量控制。
- **MySQL高可用性**：部署主从复制或 Galera Cluster，确保业务持续可用。
- 数据库自动化运维工具（如 **Ansible**）来管理配置和自动化调整。



## mysql出现错误，排查思路

当 MySQL 出现错误时，排查问题需要遵循“从现象到本质、从日志到配置、从资源到操作”的系统思路。下面是 **一套系统化的 MySQL 错误排查思路**，适用于运维工程师和 DevOps 在生产环境中实际处理问题。

------

### 🧭 一、排查总思路（五步法）

1. **观察现象**：错误提示、连接失败、SQL 执行慢、服务起不来？
2. **查看日志**：错误日志、慢查询日志、系统日志
3. **确认服务状态**：服务是否在运行，监听端口是否开放
4. **检查系统资源**：内存、磁盘、CPU 是否异常
5. **分析配置与权限**：配置文件、用户权限、网络访问控制

------

### 🔍 二、常见错误及排查方法

#### 1. **无法连接 MySQL**

- 🔹 错误信息：`Can't connect to MySQL server on 'host' (111)`
- ✅ 排查步骤：
  - `systemctl status mysqld` 检查服务是否运行
  - `ss -lntp | grep 3306` 是否监听端口
  - `firewalld` 或 `iptables` 是否放通
  - 配置文件 `bind-address` 是否设置为 `0.0.0.0`
  - 用户是否授权远程访问：`GRANT ALL ON *.* TO 'user'@'%' IDENTIFIED BY 'pwd';`

------

#### 2. **登录失败：Access Denied**

- 🔹 错误信息：`Access denied for user 'xxx'@'host'`
- ✅ 排查步骤：
  - 用户名/密码是否正确
  - `mysql.user` 表中是否存在对应授权记录
  - 主机是否匹配 (`'%'`, `'localhost'`, `'192.168.%'`)
  - 是否改过密码但客户端未更新
  - 使用 `SHOW GRANTS FOR 'user'@'host';` 查看权限

------

#### 3. **MySQL 启动失败**

- 🔹 日志信息：`InnoDB: Unable to lock ./ibdata1`
- ✅ 排查步骤：
  - 是否已有 mysqld 进程运行
  - 数据目录权限是否正确
  - 空间是否满：`df -h`，`du -sh /var/lib/mysql`
  - 检查 `my.cnf` 配置错误

------

#### 4. **SQL 查询慢、卡顿**

- 🔹 现象：业务响应慢、慢查询日志中记录
- ✅ 排查步骤：
  - 开启慢查询日志：`slow_query_log = ON`
  - 查看慢日志文件，找出执行时间长的语句
  - 使用 `EXPLAIN` 分析执行计划
  - 是否缺少索引 / 是否全表扫描
  - 表是否碎片化（InnoDB 表可用 `OPTIMIZE TABLE`）

------

#### 5. **磁盘满导致异常**

- 🔹 错误：`The table 'xxx' is full`、`Disk full writing`
- ✅ 排查步骤：
  - `df -h` 查看磁盘使用
  - 日志文件太大？可手动清理 binlog
  - 设置 binlog 清理策略：`expire_logs_days`
  - 查询临时目录是否满 `/tmp`，如大查询未执行完

------

#### 6. **MySQL 占用内存过高或崩溃**

- 🔹 现象：MySQL 被系统 kill、OOM
- ✅ 排查步骤：
  - `dmesg | grep -i kill` 是否被 OOM 杀死
  - 调整 `innodb_buffer_pool_size`
  - 是否并发太高，连接数设置是否合理

------

### 🧠 三、实战排查技巧（建议记住）

| 操作                | 命令示例                       |
| ------------------- | ------------------------------ |
| 查看 MySQL 错误日志 | `tail -f /var/log/mysqld.log`  |
| 查看监听端口        | `ss -lntp                      |
| 查看连接数          | `SHOW PROCESSLIST;`            |
| 查看当前运行状态    | `SHOW STATUS LIKE 'Threads%';` |
| 查看表结构、索引    | `SHOW CREATE TABLE xxx;`       |
| SQL 执行计划分析    | `EXPLAIN SELECT ...;`          |



------

### 📌 四、建议配置检查项（`my.cnf`）

```
[mysqld]
bind-address = 0.0.0.0
max_connections = 500
slow_query_log = ON
long_query_time = 1
innodb_buffer_pool_size = 1G
log_error = /var/log/mysqld.log
```

------

### 🧑‍💼 五、面试答题模板

> 遇到 MySQL 报错时，我首先会从错误日志入手定位原因，比如常见的连接失败、权限拒绝、磁盘空间满等问题。
>  接着通过系统工具（如 netstat、df、dmesg）排查资源问题，同时分析配置项与 SQL 执行状态，快速定位并处理。
>  对于慢查询问题，我会配合慢查询日志与 EXPLAIN 工具优化语句、添加索引等方式处理，必要时做性能压测。



## mysql使用



### 🛠️ 一、登录 & 退出

```
mysql -u root -p            # 登录 MySQL，提示输入密码
mysql -h 主机 -P 端口 -u 用户 -p  # 远程登录
exit                        # 退出
```

------

### 🧱 二、数据库操作

```
SHOW DATABASES;                     -- 查看所有数据库
CREATE DATABASE db_name;            -- 创建数据库
USE db_name;                        -- 选择数据库
DROP DATABASE db_name;             -- 删除数据库
```

------

### 📋 三、数据表操作

```
SHOW TABLES;                         -- 查看所有表
DESC table_name;                     -- 查看表结构
CREATE TABLE 表名 (...);             -- 创建表
DROP TABLE 表名;                     -- 删除表
RENAME TABLE old TO new;            -- 重命名表
ALTER TABLE 表名 ADD 列定义;         -- 添加列
ALTER TABLE 表名 MODIFY 列定义;      -- 修改列
ALTER TABLE 表名 DROP COLUMN 列名;   -- 删除列
```

------

### 📌 四、数据操作（增删改查）

```
-- 插入
INSERT INTO 表名 (列1, 列2) VALUES ('值1', '值2');

-- 查询
SELECT * FROM 表名;
SELECT name, age FROM 表名 WHERE age > 20 ORDER BY age DESC;

-- 更新
UPDATE 表名 SET 列1='新值' WHERE 条件;

-- 删除
DELETE FROM 表名 WHERE 条件;
```

------

### 🔍 五、索引操作

```
CREATE INDEX idx_name ON 表名(列名);    -- 创建索引
DROP INDEX idx_name ON 表名;           -- 删除索引
SHOW INDEX FROM 表名;                  -- 查看索引
```

------

### 🔑 六、用户与权限

```
CREATE USER 'zhangsan'@'192.168.1.%' IDENTIFIED BY '123456';  -- 创建用户
GRANT ALL PRIVILEGES ON db_name.* TO 'zhangsan'@'192.168.1.%';  -- 授权
REVOKE 权限 ON 数据库.* FROM 用户;                            -- 回收权限
DROP USER 'zhangsan'@'192.168.1.%';                           -- 删除用户
FLUSH PRIVILEGES;                                             -- 刷新权限
```

------

### 📦 七、备份与还原

```
# 备份
mysqldump -u 用户 -p 数据库名 > db.sql

# 还原
mysql -u 用户 -p 数据库名 < db.sql
```

------

### 📊 八、其他常用

```
SELECT VERSION();         -- 查看 MySQL 版本
SHOW PROCESSLIST;         -- 查看当前连接
SHOW VARIABLES LIKE '%char%';  -- 查看字符集设置
SET NAMES utf8mb4;        -- 设置字符集
```



```sql
#创建用户并授权

CREATE USER 'zhangsan'@'192.168.10.%' IDENTIFIED BY 'your_password';
GRANT ALL PRIVILEGES ON *.* TO 'zhangsan'@'192.168.10.%';
FLUSH PRIVILEGES;
#说明：
#'zhangsan'@'192.168.10.%' 表示仅允许从 192.168.10.0/24 网段的主机登录。
#your_password 替换为张三自己的密码。
#ALL PRIVILEGES 代表所有权限，也可以指定具体数据库，例如：db1.*。

#查看创建好的用户
SELECT user, host FROM mysql.user WHERE user = 'zhangsan';
```



# Prometheus

## 四种指标类型（Metric Types）

| 类型名        | 中文名 | 典型用途                         |
| ------------- | ------ | -------------------------------- |
| **Counter**   | 计数器 | 只能递增的值，如请求次数、错误数 |
| **Gauge**     | 仪表盘 | 可增可减的值，如温度、内存使用量 |
| **Histogram** | 直方图 | 衡量值的分布，如接口响应时间     |
| **Summary**   | 摘要   | 类似 Histogram，包含分位值统计   |

## Prometheus 默认组件相关指标

### 1. Prometheus 自身指标

- `prometheus_engine_query_duration_seconds`：查询耗时
- `prometheus_tsdb_head_chunks`：当前在内存中的时间序列块数
- `prometheus_target_interval_length_seconds`：采集间隔统计

### 2. Node Exporter（监控主机）

- `node_cpu_seconds_total`：CPU 各状态消耗时间
- `node_memory_MemAvailable_bytes`：可用内存
- `node_disk_io_time_seconds_total`：磁盘 I/O 时间
- `node_filesystem_avail_bytes`：文件系统可用空间

### 3. cAdvisor / kubelet（Kubernetes 容器）

- `container_cpu_usage_seconds_total`：容器 CPU 使用时间
- `container_memory_usage_bytes`：容器内存使用
- `container_fs_usage_bytes`：容器文件系统使用量
- `container_network_receive_bytes_total`：容器接收网络流量

### 4. 自定义指标（业务监控）

应用开发者可以通过客户端库暴露自定义指标，例如：

```
go复制编辑httpRequestsTotal := prometheus.NewCounter(
    prometheus.CounterOpts{
        Name: "myapp_http_requests_total",
        Help: "Total number of HTTP requests.",
    })
```







## **Prometheus Adapter vs cAdvisor 区别总结（面试标准版）**

| 维度             | **Prometheus Adapter**                                       | **cAdvisor**                                                 |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **作用**         | **把 Prometheus 指标暴露为 Kubernetes 自定义指标（Custom Metrics / External Metrics）供 HPA / API Server 使用** | **采集单个节点上容器的资源使用情况（CPU、内存、网络 IO、磁盘 IO）** |
| **工作层级**     | 集群级 **指标适配器**                                        | Node 级 **容器资源采集器**                                   |
| **主要用途**     | - HPA 基于 Prometheus 指标实现**自定义扩缩容** - 支持 External Metrics（如 QPS） - 连接 Prometheus 和 Kubernetes API | - 采集容器/Pod 的 CPU、内存、网络、磁盘指标 - Prometheus 通过 **Node Exporter + cAdvisor** 拉取数据 |
| **输出对象**     | Kubernetes API Server **Custom Metrics API** / **External Metrics API** | 采集指标 → 暴露为 `/metrics` 端点，供 Prometheus 拉取        |
| **部署位置**     | 独立 Deployment 组件，集群部署                               | kubelet 内嵌 or 单独二进制运行在 Node 节点                   |
| **对接组件**     | Prometheus、K8s API Server、HPA                              | Prometheus、Node Exporter                                    |
| **项目经验举例** | 「我们项目中用 Prometheus Adapter + Prometheus Adapter 配置文件暴露自定义 QPS 指标，供 HPA 做自动扩缩容」 | 「我们 Prometheus 通过 Node Exporter + cAdvisor 监控节点和容器资源使用率，Grafana 展示」 |



------

#### **一句话总结（面试必背）**

> cAdvisor 负责采集节点和容器资源指标，Prometheus Adapter 负责把 Prometheus 中的指标适配给 Kubernetes API，支持 HPA 等自定义扩缩容。
>  一个采集数据、一个适配数据给 K8s 用，职责完全不同，配合使用。

------

### **如果面试官追问「你项目里怎么配合用的？」**

你可以直接这样答（结合你 Prometheus 项目经历）：

> 我们项目中，

- 通过 **cAdvisor + Node Exporter** 采集节点和容器 CPU/内存等指标，Prometheus 拉取后 Grafana 展示
- 通过 **Prometheus Adapter** 把 Prometheus 里的 QPS、请求延迟等业务指标暴露为 Custom Metrics，供 **HPA 自动扩缩容**使用
   例如：HPA 配置 target QPS 100，Prometheus Adapter 提供了 `myapp_requests_per_second` 指标，HPA 自动扩缩容 Pod 副本数

------

### **生产建议（加分项）**

> - cAdvisor 指标量大，建议配合 **Prometheus relabel_configs + metric_relabel_configs** 降采集粒度
> - Prometheus Adapter 配置文件要合理写 PromQL 映射关系，避免查询过重，影响 Prometheus 性能
> - 实际生产中**两者同时使用**，缺一不可



## prometheus的构架

在生产环境中部署 Prometheus 时，通常不会直接采用默认单实例模式，而是使用**模块化、可扩展、易于维护**的架构。下面是常见的 **生产级 Prometheus 架构设计**，结合实际经验进行了详细说明。

------

### ✅ 一、典型的生产环境 Prometheus 架构图（逻辑视图）

```
                ┌────────────────────────┐
                │   Grafana Dashboard    │   ← 查询展示
                └──────────┬─────────────┘
                           │
                  ┌────────▼────────┐
                  │   Prometheus    │   ← 多实例部署（按业务或模块）
                  └──┬──────┬───────┘
                     │      │
        ┌────────────┘      └─────────────┐
        │                                  │
┌───────▼────────┐               ┌────────▼────────┐
│ Alertmanager   │               │  Remote Storage │ ←（可选）长时间存储
└────────────────┘               │  Thanos / Mimir │
                                 └─────────────────┘
                     ▲
                     │
        ┌────────────┴──────────────────────────┐
        │          多种 Exporter 数据源         │
        └───────────────────────────────────────┘
        包括：Node Exporter、Blackbox、Cadvisor、Kube-State-Metrics、Pushgateway 等
```

------

### 🧩 二、核心组件说明

#### 1. **Prometheus Server**

- 主体组件，定期拉取各类 Exporter 暴露的指标数据
- 支持分区部署多个实例，按模块划分（如 infra、k8s、应用等）
- 支持告警规则、PromQL 查询

#### 2. **Alertmanager**

- 接收 Prometheus 告警（Alert）
- 支持聚合、静默、抑制等功能
- 多渠道通知：邮件、Slack、钉钉、飞书、微信、PagerDuty 等

#### 3. **Grafana**

- 通过 Prometheus 数据源进行可视化展示
- 提供面板、告警、用户权限管理

#### 4. **Exporter 组件**

用于暴露各种数据指标，按角色划分：

| Exporter 名称      | 作用                              |
| ------------------ | --------------------------------- |
| node_exporter      | 主机级别监控（CPU、内存、磁盘等） |
| kube-state-metrics | 获取 Kubernetes 资源状态          |
| cadvisor           | 获取容器运行时的资源使用          |
| blackbox_exporter  | 检测外部服务状态（如 Ping、HTTP） |
| mysqld_exporter    | 监控 MySQL 实例                   |
| pushgateway        | 用于非周期性任务主动推送指标      |



#### 5. **Remote Storage（可选）**

- Prometheus 默认存储只保留 15 天左右数据（磁盘限制）
- 可接入远程长时间存储方案（如：**Thanos、Cortex、Mimir**）
- 支持横向扩展、历史数据查询、对象存储（如 MinIO、S3）

------

### 🔁 三、架构部署方式建议（推荐使用 Helm）

#### 1. 使用 **Helm + Prometheus Operator** 统一管理：

```
bash复制编辑helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install kube-prometheus prometheus-community/kube-prometheus-stack -f values.yaml
```

Prometheus Operator 会自动管理：

- Prometheus 实例（CRD）
- Alertmanager 实例
- ServiceMonitor / PodMonitor
- Grafana 默认面板
- 自动 ServiceDiscovery

------

### 🧠 四、生产经验要点总结

| 方向         | 实践建议                                                     |
| ------------ | ------------------------------------------------------------ |
| 存储性能     | Prometheus 实例部署建议使用 SSD，TSDB 会写入大量指标数据     |
| 数据保留策略 | 配置 `--storage.tsdb.retention.time=15d`，避免磁盘爆满       |
| 多实例分片   | 避免一个 Prometheus 实例抓取过多 target，可按命名空间、业务模块分实例 |
| 高可用告警   | Alertmanager 需要配置 HA，至少部署 2 个副本并配置 mesh 集群互通 |
| 高可用查询   | 接入 Thanos Query，实现多个 Prometheus 实例的数据聚合查询    |
| 可观测性     | 对 Prometheus 自身也要用 `prometheus-exporter` 监控（包括 TSDB 状态） |
| 安全隔离     | 可使用 RBAC、TLS 配置数据访问限制；Grafana 提供多租户看板隔离 |



------

### 📘 五、面试/简历用语示例

> 在生产环境中，我们基于 Prometheus Operator 构建了完整的监控系统，采用多实例 Prometheus 分别负责 Kubernetes 基础设施、应用服务、数据库、中间件等维度的监控采集。为了解决长期存储与多实例聚合问题，接入了 Thanos 组件实现高可用的存储与查询架构，并结合 Alertmanager 实现了钉钉和邮件等多渠道告警通知。同时通过 Grafana 提供可视化展示，便于业务方快速定位问题。



## prometheus生产中遇到的问题及排查思路

在生产环境中使用 **Prometheus** 时，常见的问题主要集中在 **数据采集异常、告警误报、存储瓶颈、查询性能下降、版本兼容性、以及资源占用过高等方面**。以下是详细的常见问题及排查思路，适用于 SRE、运维工程师等角色日常定位与修复问题。

------

### ✅ 一、数据采集异常类问题

#### 1. Target 状态变为 `DOWN`

**表现：** Prometheus UI 中 `/targets` 页面部分采集目标为 Down。

**排查思路：**

- 检查目标服务是否存活（如 `node_exporter` 是否在运行）
- 检查服务 IP、端口是否变更
- 检查 Prometheus 配置文件中的 target 地址或 service discovery 是否正确
- 检查网络连通性：`curl <target>:9100/metrics`
- 检查目标返回内容是否正确（非 200 或格式错误会被判定为 down）

------

#### 2. 抓取失败（scrape failed）或 samples dropped

**表现：** 采集失败、样本数异常下降。

**排查思路：**

- 检查 `/targets` 页面 scrape error 提示

- 查看 Prometheus 自身日志是否有 `context deadline exceeded` 或 `read: connection reset`

- 查询相关指标：

  ```
  rate(scrape_samples_scraped[5m])
  rate(scrape_samples_dropped[5m])
  ```

------

#### 3. 采集间隔太长，数据点不连续

**排查思路：**

- 检查抓取间隔 `scrape_interval` 是否被全局配置或 job 覆盖
- 检查目标是否负载过高，响应太慢（指标：`scrape_duration_seconds`）
- 检查是否配置 `sample_limit`、`label_limit` 等采样限制

------

### 📦 二、存储与性能类问题

#### 4. Prometheus 磁盘写满或写入慢

**表现：** Prometheus crash 或数据无法写入。

**排查思路：**

- 检查数据目录磁盘使用率：

  ```
  du -sh /var/lib/prometheus
  df -h
  ```

- 查看 TSDB 指标：

  ```
  prometheus_tsdb_head_series
  prometheus_tsdb_wal_truncate_duration_seconds
  ```

- 设置合适的保留策略，如：

  ```
  --storage.tsdb.retention.time=15d
  ```

------

#### 5. 查询 PromQL 很慢或 Prometheus 页面卡顿

**排查思路：**

- 查看是否是高基数 label，查询 label 值太多（如 IP、用户 ID）

- 优化 PromQL 表达式，避免 `rate(metric[30d])` 这类窗口太大的计算

- 检查查询并发数限制：

  ```
  --query.max-concurrency
  ```

- 查看查询时间指标：

  ```
  histogram_quantile(0.99, sum(rate(prometheus_engine_query_duration_seconds_bucket[5m])) by (le))
  ```

------

### 🔔 三、告警系统相关问题

#### 6. 告警未触发或误报

**表现：** 明明条件满足，但告警没触发；或告警一直存在。

**排查思路：**

- 使用 `promtool check rules` 检查语法
- 用 UI 运行表达式，检查是否真正返回了数据（是否为 `NaN` 或空值）
- 检查 `for:` 是否设置过长导致告警未触发
- 检查 Alertmanager 是否正确接收到告警（查看 `/alerts` 和 `/api/v1/alerts`）

------

#### 7. 告警发送失败（钉钉、邮件等）

**排查思路：**

- 查看 Alertmanager 日志，是否存在发送失败的错误
- 检查 `alertmanager.yml` 通知渠道配置是否正确
- 网络是否能访问钉钉 / 邮件服务器
- 钉钉 Webhook 是否启用加签校验（timestamp + secret）

------

### 🧱 四、服务稳定性问题

#### 8. Prometheus 频繁 OOM 或崩溃

**排查思路：**

- 检查是否被抓取的数据量过大（series 数过多）

  ```
  prometheus_tsdb_head_series
  ```

- 是否存在高基数 label

  ```
  count by (__name__)({__name__=~".+"})
  topk(10, count by (job,instance)(some_metric))
  ```

- 增加内存、限制抓取维度、过滤 metrics 等手段降低压力

------

#### 9. Prometheus 启动失败或配置热加载失败

**排查思路：**

- 检查配置文件语法：

  ```
  promtool check config prometheus.yml
  ```

- 检查规则语法：

  ```
  promtool check rules rules.yml
  ```

- 查看 `systemctl status prometheus` 或容器日志

- 查看是否有配置文件路径错误或权限问题

------

### 🧪 五、工具辅助排查

| 工具            | 功能                     |
| --------------- | ------------------------ |
| `promtool`      | 校验配置与规则           |
| `/status` 页面  | 查看配置、TSDB 状态      |
| `/targets` 页面 | 查看 targets 采集状态    |
| `/metrics` 页面 | Prometheus 自身指标      |
| Grafana         | 可视化排查性能与时序波动 |
| Alertmanager UI | 检查告警状态与通知日志   |



------

### ✅ 六、建议建立的内部告警规则

| 规则                | 表达式示例                                                   |
| ------------------- | ------------------------------------------------------------ |
| Target Down         | `up == 0`                                                    |
| 抓取失败率高        | `rate(scrape_samples_dropped[5m]) > 100`                     |
| Prometheus 内存过高 | `process_resident_memory_bytes > 4 * 1024 * 1024 * 1024`     |
| Query 查询延迟高    | `histogram_quantile(0.95, sum(rate(prometheus_engine_query_duration_seconds_bucket[5m])) by (le)) > 1` |
| 时间序列爆炸        | `prometheus_tsdb_head_series > 1e6`                          |



## prometheus优化

在生产环境中，**Prometheus 优化**的核心目标是：

- 提高数据采集与查询性能
- 控制资源使用，避免 OOM 或磁盘爆满
- 保证时序数据准确、稳定
- 提高高可用性与可扩展性

以下是生产中 Prometheus 的全面优化建议，适用于物理机、VM、Kubernetes 等不同部署方式：

------

### ✅ 一、抓取性能优化（Scrape 优化）

#### 1. **合理设置 scrape_interval 和 timeout**

- 默认值 `scrape_interval: 15s`，一般可接受

- 高频采集（如 5s）会显著增加存储和计算压力

- 示例配置：

  ```
  scrape_interval: 15s
  scrape_timeout: 10s
  ```

#### 2. **目标分组：分 job 配置采集**

将不同类型目标（node_exporter、app_exporter、kubelet 等）分 job，利于调优与管理。

```
scrape_configs:
  - job_name: 'node'
    static_configs:
      - targets: ['192.168.1.10:9100']
  - job_name: 'app'
    static_configs:
      - targets: ['192.168.1.20:8080']
```

#### 3. **通过 relabel_configs 剔除无用指标**

使用 `drop` 过滤掉不关心的指标/标签，减小样本数：

```
metric_relabel_configs:
  - source_labels: [__name__]
    regex: "go_.+"
    action: drop
```

------

### 📊 二、存储优化（TSDB）

#### 1. **控制保留时间与磁盘使用**

- 控制数据保存时长，避免磁盘爆满

  ```
  --storage.tsdb.retention.time=15d
  --storage.tsdb.retention.size=50GB
  ```

- 启用数据压缩与分片（Prometheus 自动处理）

- 使用大块磁盘（SSD），避免 I/O 瓶颈

#### 2. **远程写入远程存储（Remote Write）**

把数据写入长期存储系统，如：

- [Thanos](https://thanos.io/)
- [VictoriaMetrics](https://victoriametrics.com/)
- [Cortex](https://cortexmetrics.io/)

配置示例：

```
remote_write:
  - url: http://thanos-receive:19291/api/v1/receive
```

------

### 🧠 三、查询性能优化（PromQL）

#### 1. **避免高开销查询**

- 少用 `rate(metric[1d])`、`avg_over_time(x[30d])` 这类窗口太大的表达式
- 对长期趋势建议配合 Thanos/Cortex 查询

#### 2. **控制 label 维度**

- 避免 high cardinality 标签（如用户ID、IP等）
- 用 `topk()`、`group_left` 时控制数据维度

#### 3. **合理使用 recording rules**

将常用表达式预聚合保存为新的时间序列，降低计算成本：

```
groups:
  - name: app_rules
    interval: 30s
    rules:
      - record: instance:cpu:rate5m
        expr: rate(node_cpu_seconds_total[5m])
```

------

### 💾 四、内存和资源占用优化

#### 1. **限制时间序列数量**

监控指标：

```
prometheus_tsdb_head_series
```

若超过 1M，需排查维度爆炸的 metric，可用：

```
topk(10, count by (__name__)({__name__=~".+"}))
```

#### 2. **调整 Prometheus 启动参数**

- 限制并发查询数：`--query.max-concurrency=10`
- 限制数据块压缩线程：`--storage.tsdb.max-block-duration=2h`
- 限制目标样本采集数：`--storage.remote.flush-deadline`

------

### 🔔 五、告警规则优化

#### 1. **使用 recording rules 做基础聚合**

避免在告警规则中重复复杂表达式

#### 2. **设置合理的 `for:`**

防止告警抖动：

```
- alert: NodeDown
  expr: up == 0
  for: 5m
```

#### 3. **分类告警规则文件**

按业务组件分类管理（node、k8s、数据库、app 等）

------

### 🔐 六、安全与可用性优化

#### 1. **使用反向代理提供 HTTPS 与认证**

Prometheus 原生不支持认证，建议用 Nginx/Envoy 实现：

```
location / {
  auth_basic "Prometheus";
  auth_basic_user_file /etc/nginx/.htpasswd;
  proxy_pass http://localhost:9090;
}
```

#### 2. **部署多实例 + 高可用架构（HA）**

- 一主一备（但 Prometheus 自身不支持 HA 写）
- 多实例 + Thanos Query 网关进行聚合
- Grafana 查询聚合结果

------

### ⚙️ 七、Kubernetes 场景下优化（如使用 Prometheus Operator）

#### 1. 使用 CRD 管理配置

- `ServiceMonitor`、`PodMonitor`、`PrometheusRule`
- 自动滚动配置，无需重启 Prometheus

#### 2. 限制抓取对象数量

使用 labelSelector 限定采集范围：

```
selector:
  matchLabels:
    app: node-exporter
```

#### 3. 调整 StatefulSet 资源限制

```
resources:
  limits:
    memory: 4Gi
  requests:
    memory: 2Gi
```

------

### 🧩 八、Grafana 展示优化

- 配合 recording rule 提前聚合数据
- 使用变量筛选 panel 降低查询压力
- 加入缓存插件（如 `grafana-image-renderer`）

------

### 🔚 总结

| 优化方向 | 关键措施                                 |
| -------- | ---------------------------------------- |
| 抓取性能 | 控制 scrape 频率、标签维度、目标分组     |
| 存储容量 | 限保留时间/空间、使用远程存储            |
| 查询性能 | recording rule、避免高基数、限制查询并发 |
| 内存优化 | 限制并发、爆炸标签过滤、指标规整         |
| 安全可用 | TLS + 认证、HA 架构部署                  |
| K8s 优化 | ServiceMonitor 控制范围、资源限制配置    |







# 网络

## 三次握手

### 🎯 目的：

建立可靠的连接，双方确认彼此收发能力正常，初始化序列号。

### 📈 流程图：

```
lua复制编辑客户端                            服务端
   │-------- SYN -------->│      第一次握手
   │                      │
   │<----- SYN + ACK -----│      第二次握手
   │                      │
   │-------- ACK -------->│      第三次握手
```

### 📋 步骤说明：

1. **第一次握手**（客户端 → 服务端）：
   - 客户端发送一个 SYN 报文，请求建立连接，并随机初始化一个序列号 `Seq = x`。
   - 状态：客户端进入 `SYN_SENT`，服务端进入 `LISTEN`。
2. **第二次握手**（服务端 → 客户端）：
   - 服务端收到 SYN，回复一个 `SYN + ACK` 报文。
   - 表示“我收到了你的 SYN，我也发送 SYN 并确认你的 SYN”，设置 `Seq = y`，`Ack = x+1`。
   - 状态：服务端进入 `SYN_RECV`。
3. **第三次握手**（客户端 → 服务端）：
   - 客户端收到服务端的 SYN+ACK 报文，发送一个 ACK 报文，表示确认。
   - `Ack = y+1`。
   - 状态：客户端进入 `ESTABLISHED`，服务端收到 ACK 后也进入 `ESTABLISHED`。

✅连接建立完成，双方可以开始数据传输。

## 四次断开

### 🎯 目的：

优雅地断开连接，确保双方数据收发都已经完成。

### 📈 流程图：

```
lua复制编辑客户端                            服务端
   │-------- FIN -------->│      第一次挥手
   │                      │
   │<-------- ACK --------│      第二次挥手
   │                      │
   │<-------- FIN --------│      第三次挥手
   │                      │
   │-------- ACK -------->│      第四次挥手
```

### 📋 步骤说明：

1. **第一次挥手**（客户端 → 服务端）：
   - 客户端发送 FIN 报文，表示“我没有数据要发了，但还能接收数据”。
   - 状态：客户端进入 `FIN_WAIT_1`。
2. **第二次挥手**（服务端 → 客户端）：
   - 服务端回复 ACK，表示“我知道你要关闭了”。
   - 状态：客户端进入 `FIN_WAIT_2`，服务端进入 `CLOSE_WAIT`。
3. **第三次挥手**（服务端 → 客户端）：
   - 服务端也没有数据要发，发送 FIN 报文。
   - 状态：服务端进入 `LAST_ACK`。
4. **第四次挥手**（客户端 → 服务端）：
   - 客户端回复 ACK。
   - 状态：客户端进入 `TIME_WAIT`，等待一段时间后完全关闭；服务端收到 ACK 后进入 `CLOSED`。



## 简述https的工作过程？

```
1、客户端发起请求
2、服务端将证书传给客户端
3、客户端使用CA公钥解析验证证书，生成一个随机值，使用服务器公钥加密随机值发送给客户端
4、服务器收到公钥加密随机值，使用自己的私钥解密
5、后续双方使用随机值对称加密
6、数据传输结束，客户端和服务器可以关闭连接，会话密钥也会被丢弃，保证每次使用不同的密钥加密
7、一旦 HTTPS 会话结束，双方都会销毁用于加密的密钥，防止密钥被恶意攻击者窃取
```



# tomcat

## tomcat优化

### **1. JVM 参数优化**

Tomcat 的性能高度依赖 JVM，因此调整 JVM 参数是优化的核心：

#### **堆内存分配**

- 根据服务器内存大小合理配置：

  ```
  -Xms2g -Xmx2g
  ```

  - `-Xms`：初始堆大小。
  - `-Xmx`：最大堆大小。

#### **GC 调优**

- 选择适合的垃圾回收器：

  ```
  -XX:+UseG1GC
  ```

  - 对于高并发应用，G1 GC 提供更好的暂停时间控制。

- 配置垃圾回收参数：

  ```
  -XX:MaxGCPauseMillis=200 -XX:+ParallelRefProcEnabled
  ```

#### **线程栈大小**

- 避免线程栈占用过多内存：

  ```
  -Xss512k
  ```

------

### **2. 连接器优化**

Tomcat 使用的 HTTP 连接器（如 NIO、APR）可以通过调整参数提升性能。

#### **启用 NIO 或 APR**

- 修改 server.xml：

  ```
  <Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol" 
              maxThreads="500" 
              minSpareThreads="50" 
              acceptCount="200" 
              connectionTimeout="20000"
              enableLookups="false" 
              URIEncoding="UTF-8"/>
  ```

  - `maxThreads`：最大工作线程数，控制并发能力。
  - `minSpareThreads`：空闲线程数，减少频繁创建线程的开销。
  - `acceptCount`：请求队列最大长度。
  - `connectionTimeout`：连接超时时间。

#### **开启 Keep-Alive**

- 保持长连接以减少 TCP 建立的开销：

  ```
  <Connector port="8080" protocol="HTTP/1.1" 
              maxKeepAliveRequests="100" 
              keepAliveTimeout="5000"/>
  ```

  - `maxKeepAliveRequests`：限制单个连接允许的最大请求数。
  - `keepAliveTimeout`：Keep-Alive 超时时间。

------

### **3. 内存和线程池优化**

#### **优化线程池**

- 配置线程池大小以适应负载：

  - 调整 server.xml 的 Executor 元素：

    ```
    <Executor name="tomcatThreadPool" 
              namePrefix="catalina-exec-" 
              maxThreads="300" 
              minSpareThreads="20"/>
    ```

#### **控制会话内存**

- 配置会话持久化策略：

  - 在 context.xml 中禁用会话持久化：

    ```
    <Manager pathname="" />
    ```

  - 对于分布式部署，使用外部会话存储（如 Redis）。

------

### **4. 静态资源优化**

#### **配置静态资源缓存**

- 在 web.xml 中启用缓存：

  ```
  <servlet>
      <servlet-name>default</servlet-name>
      <servlet-class>org.apache.catalina.servlets.DefaultServlet</servlet-class>
      <init-param>
          <param-name>cacheMaxSize</param-name>
          <param-value>40960</param-value>
      </init-param>
      <init-param>
          <param-name>cacheTTL</param-name>
          <param-value>60000</param-value>
      </init-param>
  </servlet>
  ```

------

### **5. 压缩传输**

#### **启用 Gzip 压缩**

- 在 server.xml 中添加压缩支持：

  ```
  <Connector port="8080" protocol="HTTP/1.1"
              compression="on"
              compressionMinSize="1024"
              noCompressionUserAgents="gozilla, traviata"
              compressableMimeType="text/html,text/xml,text/plain,text/css,application/json,application/javascript"/>
  ```

  - `compression="on"`：启用压缩。
  - `compressionMinSize`：设置触发压缩的最小数据大小。
  - `compressableMimeType`：指定需要压缩的 MIME 类型。

------

### **6. 日志管理**

#### **减少日志开销**

- 调整日志级别：

  - 在  logging.properties 中设置日志级别为 INFOINFO

    ```
    properties
    org.apache.catalina.level = INFO
    ```

#### **分离访问日志**

- 将访问日志分离以减少 I/O 压力：

  - 修改 server.xml

    ```
    <Valve className="org.apache.catalina.valves.AccessLogValve"
           directory="logs"
           prefix="access_log"
           suffix=".txt"
           pattern="%h %l %u %t &quot;%r&quot; %s %b" />
    ```

------

### **7. 安全性优化**

#### **限制管理功能访问**

- 配置管理界面访问 IP：

  - 修改 conf/tomcat-users.xml

    ```
    <role rolename="manager-gui"/>
    <user username="admin" password="securepassword" roles="manager-gui"/>
    ```

  - 使用防火墙限制管理功能访问。

#### **禁用未使用的服务**

- 删除 `webapps` 中不必要的应用（如 `examples`、`docs`）。

#### **启用 HTTPS**

- 配置 HTTPS 连接：

  ```
  <Connector port="8443" protocol="org.apache.coyote.http11.Http11NioProtocol"
              SSLEnabled="true" 
              maxThreads="200" 
              scheme="https" 
              secure="true"
              keystoreFile="conf/keystore.jks" 
              keystorePass="changeit"/>
  ```

------

### **8. 系统级优化**

- 文件描述符限制

  - 确保系统允许足够的文件描述符数：

    ```
    ulimit -n 65535
    ```

- TCP 调优

  - 调整操作系统 TCP 参数：

    ```
    echo "net.ipv4.tcp_fin_timeout=30" >> /etc/sysctl.conf
    ```

## 什么是OOM，Java程序如何解决OOM问题

**OOM（Out of Memory）** 是 Java 中常见的运行时错误，全称是 **OutOfMemoryError**，表示程序运行时无法为对象分配足够的内存。通常由内存不足或内存管理问题引发。

**常见的 OOM 类型**

1. **Java Heap Space**
   - 堆内存不足，无法为新对象分配空间。
   - 原因：
     - 创建了过多的对象且未被及时回收。
     - 堆内存配置不足。
     - 内存泄漏（对象不被回收）。
2. **GC Overhead Limit Exceeded**
   - 垃圾回收耗时过多但未能释放足够内存。
   - 原因：
     - 内存不足，导致 GC 频繁触发。
     - 不断创建新对象，GC 来不及回收。
3. **Metaspace**（JDK 8+）
   - Metaspace 内存不足，无法加载类元数据。
   - 原因：
     - 动态加载类过多。
     - 元空间设置不足。
4. **Direct Buffer Memory**
   - NIO 的直接内存不足。
   - 原因：
     - 分配的直接内存超过 JVM 允许范围。
     - 未正确释放直接内存。
5. **Unable to Create New Native Thread**
   - 无法创建新的线程，通常由于系统资源限制。
   - 原因：
     - 线程数过多。
     - 系统级资源（如文件描述符、内存）耗尽。

------

### **如何解决 OOM 问题**

#### **1. Java Heap Space**

**解决思路：**

- **增加堆内存**：
  使用 JVM 参数调整堆大小，例如：

  ```
  -Xms2g -Xmx4g
  ```

  - `-Xms`：初始堆大小。
  - `-Xmx`：最大堆大小。

- **定位内存泄漏**：

  - 使用工具分析堆转储文件（Heap Dump），例如：
    - **VisualVM**。
    - **Eclipse MAT（Memory Analyzer Tool）**。
  - 检查长时间占用内存的对象及其引用关系。

- **优化代码**：

  - 避免无用对象（如大集合）长期占用内存。
  - 减少大对象使用或及时清理。

------

#### **2. GC Overhead Limit Exceeded**

**解决思路：**

- **增加堆大小**：

  - 提高最大堆大小以减少 GC 频率：

    ```
    -Xmx4g
    ```

- **优化垃圾回收器**：

  - 选择适合的 GC 策略：

    - 对吞吐量要求高的场景：`-XX:+UseParallelGC`。
    - 对低延迟要求高的场景：`-XX:+UseG1GC`。

  - 调整 GC 参数，例如：

    ```
    -XX:MaxGCPauseMillis=200
    ```

- **检查内存使用**：

  - 确保没有过度创建短生命周期的对象。

------

#### **3. Metaspace**

**解决思路：**

- 调整元空间大小：

  - 增加元空间限制：

    ```
    -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m
    ```

- 检查类加载逻辑：

  - 避免频繁动态生成类（如使用 CGLIB、Javassist 动态代理）。
  - 确保不重复加载相同的类。

------

#### **4. Direct Buffer Memory**

**解决思路：**

- 调整直接内存大小：

  - 增加直接内存限制：

    ```
    -XX:MaxDirectMemorySize=512m
    ```

- 及时释放直接内存：

  - 确保使用的 `ByteBuffer` 在不用时手动清理。
  - 使用 `sun.misc.Cleaner` 工具清理直接内存。

------

#### **5. Unable to Create New Native Thread**

**解决思路：**

- **减少线程数**：

  - 检查线程池配置，避免线程过多。

  - 使用线程池代替直接创建线程，例如：

    ```
    ExecutorService executor = Executors.newFixedThreadPool(10);
    ```

- **增加系统资源限制**：

  - 调整系统对线程数量的限制：

    - 修改 ulimit 配置：

      ```
      ulimit -u 65535
      ```

    - 增加 /etc/security/limits.conf中的用户线程数限制：

      ```
      *  soft  nproc  65535
      *  hard  nproc  65535
      ```

------

### **监控和预防 OOM**

#### **1. 启用 JVM 监控**

- 使用工具监控内存使用情况：
  - JConsole。
  - VisualVM。
  - Prometheus + Grafana。

#### **2. 定期导出 Heap Dump**

- 当程序出现 OOM 时，自动生成堆转储文件：

  ```
  -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dump
  ```

#### **3. 代码优化**

- 避免滥用单例、静态集合等长期存储数据的结构。
- 减少频繁的短生命周期对象创建。

------

### **总结**

OOM 是 Java 应用内存管理中的常见问题，可以通过调整 JVM 参数、优化代码逻辑以及定期监控内存来解决和预防。及时分析堆转储文件和运行日志是定位问题的关键步骤。



## 基于客户端的分布式机集群和基于服务端的分布式集群有什么区别

基于**客户端**的分布式集群和基于**服务端**的分布式集群在架构设计、数据处理方式、负载均衡以及开发复杂性等方面有明显的区别。以下是两者的主要区别：

------

### **1. 集群架构**

- **基于客户端的分布式集群：**
  - 客户端直接与集群中的各节点交互。
  - 客户端负责选择目标节点，并管理与节点之间的通信。
  - 常见于分布式数据库（如 MongoDB、Cassandra）和分布式缓存（如 Redis 的 Cluster 模式）。
- **基于服务端的分布式集群：**
  - 客户端只与一个或多个服务端入口（如负载均衡器、网关）通信。
  - 服务端（或负载均衡器）负责请求的分发和处理。
  - 常见于 Web 服务（如 Nginx 反向代理集群）和分布式文件系统（如 Hadoop HDFS）。

------

### **2. 请求路由和负载均衡**

- **基于客户端的分布式集群：**
  - 客户端自行实现负载均衡，通常通过以下方式：
    - 哈希算法（如一致性哈希）。
    - 节点列表（通常通过服务注册发现获取）。
  - 客户端需要有足够的逻辑来处理节点故障、超时重试等情况。
- **基于服务端的分布式集群：**
  - 请求首先被服务端的负载均衡器或代理分发，负载均衡方式包括：
    - 轮询、加权轮询。
    - 最小连接数。
    - 动态响应时间。
  - 客户端无需感知集群内部细节。

------

### **3. 数据一致性管理**

- **基于客户端的分布式集群：**
  - 数据一致性主要由客户端负责：
    - 客户端需要知道数据存储在哪些节点。
    - 客户端可能需要处理分片（sharding）或副本（replication）。
  - 数据模型的复杂性会增加，特别是在需要事务支持的场景下。
- **基于服务端的分布式集群：**
  - 数据一致性由集群服务端统一管理：
    - 服务端可以实现分布式事务或强一致性协议（如 Raft、Paxos）。
    - 客户端只需关心请求结果，不需要参与数据一致性逻辑。

------

### **4. 故障处理**

- **基于客户端的分布式集群：**
  - 客户端需要负责节点状态检测和故障切换（Failover）。
  - 如果一个节点不可用，客户端需选择其他节点重试。
  - 客户端逻辑更复杂，可能会导致实现成本上升。
- **基于服务端的分布式集群：**
  - 故障处理通常由服务端完成：
    - 负载均衡器可动态移除故障节点。
    - 服务端可以实现自动恢复机制。
  - 客户端对集群的容错感知较弱，但系统可靠性更高。

------

### **5. 复杂性与维护成本**

- **基于客户端的分布式集群：**
  - 优点：
    - 适用于高性能场景，客户端直接与目标节点通信，减少了中间代理的性能损耗。
    - 扩展性好，新增节点后客户端可动态感知。
  - 缺点：
    - 客户端需要实现复杂的逻辑，如服务发现、负载均衡、故障切换。
    - 不同的客户端实现可能导致不一致行为。
- **基于服务端的分布式集群：**
  - 优点：
    - 客户端逻辑简单，仅需与服务端通信。
    - 服务端可集中管理集群，简化了运维和管理。
  - 缺点：
    - 代理层可能成为性能瓶颈（需要优化负载均衡器性能）。
    - 增加了额外的网络跳转开销。

------

### **6. 使用场景**

- **基于客户端的分布式集群：**
  - 分布式数据库（如 MongoDB、Cassandra）。
  - 分布式缓存（如 Redis Cluster 模式）。
  - 分布式消息队列（如 Kafka 的客户端分区选择）。
- **基于服务端的分布式集群：**
  - Web 服务集群（如使用 Nginx 或 Envoy 做反向代理）。
  - 分布式文件系统（如 Hadoop HDFS）。
  - 大型微服务架构中的 API 网关（如 Spring Cloud Gateway）。

------

### **总结**

| **特点**       | **基于客户端的分布式集群**   | **基于服务端的分布式集群**         |
| -------------- | ---------------------------- | ---------------------------------- |
| 请求路由方式   | 客户端负责                   | 服务端（负载均衡器）负责           |
| 负载均衡       | 客户端实现（如哈希）         | 服务端实现（如轮询、最小连接数等） |
| 故障处理       | 客户端感知节点故障，处理切换 | 服务端动态移除故障节点             |
| 数据一致性管理 | 客户端负责分片和一致性逻辑   | 服务端统一管理                     |
| 复杂性         | 客户端复杂，需实现更多逻辑   | 服务端复杂，客户端简单             |
| 使用场景       | 分布式数据库、分布式缓存等   | Web 服务、文件系统、微服务网关等   |

两者的选择应根据系统架构需求、性能目标以及开发和维护成本权衡。



## 在工作中监控过Java程序的哪些指标

在工作中监控 Java 程序是保障应用稳定性和性能的重要任务。以下是常见的 Java 程序监控指标及其意义：

------

### **1. JVM 内存指标**

#### **堆内存使用情况（Heap Memory Usage）**

- 监控内容：
  - 当前堆内存使用量。
  - 堆内存最大值。
  - 老年代（Old Generation）和新生代（Young Generation）的内存使用。
- 意义：
  - 判断是否存在内存泄漏。
  - 评估 GC 的效果，防止内存不足导致 OOM。
- 工具：
  - JConsole、VisualVM、Prometheus（结合 JVM Exporter）。

------

#### **非堆内存使用情况（Non-Heap Memory Usage）**

- 监控内容：
  - 元空间（Metaspace）使用情况。
  - 直接内存（Direct Memory）的分配和使用。
- 意义：
  - 确保类加载和 NIO 分配足够的内存，避免 OOM。

------

#### **垃圾回收（GC）指标**

- 监控内容：
  - GC 次数（Minor GC 和 Full GC）。
  - GC 时间（每次和总计）。
  - GC 停顿时间（Stop-the-World）。
- 意义：
  - 过多的 GC 次数和时间表明内存使用或配置可能有问题。
- 工具：
  - jstat、GC 日志（通过 `-Xlog:gc` 开启 GC 日志）。
  - APM 工具（如 Prometheus、Grafana）。

------

### **2. 线程指标**

#### **线程状态**

- 监控内容：
  - 各类线程状态的数量（运行中、阻塞、等待、终止等）。
  - 死锁检测。
- 意义：
  - 确保线程没有因锁或资源争用导致阻塞或死锁。
- 工具：
  - jstack。
  - VisualVM。

#### **线程池监控**

- 监控内容：
  - 线程池中的当前活跃线程数。
  - 任务队列长度。
  - 拒绝的任务数。
- 意义：
  - 确保线程池配置合理，避免线程资源耗尽或任务积压。
- 工具：
  - 自定义线程池监控，通过 `ThreadPoolExecutor` 提供的监控方法。

------

### **3. CPU 使用**

#### **应用级 CPU 使用**

- 监控内容：
  - Java 进程的 CPU 占用。
  - 每个线程的 CPU 时间（热点线程）。
- 意义：
  - 检查是否存在性能瓶颈或 CPU 使用过高的问题。
- 工具：
  - `top`/`htop` 命令。
  - Java Mission Control。
  - APM 工具。

#### **线程级 CPU 使用**

- 监控内容：
  - 找出高 CPU 占用的线程。
  - 检查线程是否处于无限循环或其他异常情况。
- 工具：
  - 使用 `jstack` 获取线程堆栈。
  - `ps -L` 查看线程的 CPU 占用。

------

### **4. I/O 指标**

#### **文件 I/O**

- 监控内容：
  - 磁盘读写速率。
  - 文件描述符使用数。
- 意义：
  - 评估文件操作性能，避免文件描述符耗尽。
- 工具：
  - lsof。
  - APM 工具。

#### **网络 I/O**

- 监控内容：
  - 网络连接数。
  - 每秒数据包发送和接收速率。
- 意义：
  - 检查是否存在连接泄漏或网络性能问题。
- 工具：
  - Netstat。
  - Tcpdump。

------

### **5. 请求和事务指标**

#### **请求吞吐量（TPS/QPS）**

- 监控内容：
  - 每秒处理的请求数量。
- 意义：
  - 反映系统的处理能力。

#### **响应时间**

- 监控内容：
  - 平均响应时间。
  - 最大响应时间（P99、P95）。
- 意义：
  - 确保系统响应符合性能要求。

#### **错误率**

- 监控内容：
  - 请求的失败率。
  - 常见异常的数量。
- 意义：
  - 评估系统的可靠性。
- 工具：
  - APM 工具（如 Prometheus、Skywalking）。

------

### **6. 应用级指标**

#### **类加载**

- 监控内容：
  - 已加载类的总数。
  - 类卸载的数量。
- 意义：
  - 监控动态类加载情况，避免类加载器泄漏。

#### **锁争用**

- 监控内容：
  - 锁等待的线程数量。
  - 锁等待时间。
- 意义：
  - 确保没有线程因锁争用导致性能问题。
- 工具：
  - `jstack`。
  - Java Flight Recorder。

------

### **7. 自定义业务指标**

- 根据业务需求监控：
  - 队列长度（如消息队列、任务队列）。
  - 缓存命中率（如 Redis、Guava 缓存）。
  - 数据库查询时间和失败率。

------

### **监控工具推荐**

#### **开源工具**

- Prometheus + Grafana：通用监控平台，可监控 JVM 和业务指标。
- ELK（Elasticsearch, Logstash, Kibana）：日志监控和分析。
- Zabbix：传统监控工具。

#### **专业 APM 工具**

- Skywalking：分布式链路跟踪。
- Pinpoint：轻量级 Java 应用性能监控。
- New Relic 或 AppDynamics：商业化 APM 工具。

#### **JVM 专属工具**

- VisualVM：监控 JVM 性能。
- Java Mission Control：JDK 自带，适合分析 GC 和性能瓶颈。
- JConsole：轻量级的 JVM 监控工具。

------

### **总结**

Java 程序监控涵盖 JVM 内存、GC、线程、CPU、I/O、请求响应等多个方面。通过适当的工具和监控指标，可以快速定位性能瓶颈或异常，提升应用的稳定性和运行效率。





## java对象进入老年代的原因

在 JVM 的垃圾回收机制中，**堆内存**通常分为 **年轻代（Young Generation）** 和 **老年代（Old Generation）**。对象从年轻代进入老年代的主要原因与对象的生命周期、内存使用和垃圾回收策略有关。以下是对象进入老年代的常见原因：

------

### **1. 对象年龄（Age）超过晋升阈值**

- 机制：

  - 新生对象一般分配在年轻代的 **Eden 区**。
  - 当对象在年轻代的垃圾回收（Minor GC）中幸存一次，其年龄（Age）加 1。
  - 当对象的年龄达到 **晋升阈值（默认 15）** 时，就会被移入老年代。

- 参数控制：

  - `-XX:MaxTenuringThreshold`：设置对象年龄阈值。

  - 示例：

    ```
    -XX:MaxTenuringThreshold=10
    ```

------

### **2. 老年代空间不足**

- 机制：

  - 如果一个对象体积较大，且年轻代无法容纳，则直接分配到老年代（**大对象直接进入老年代**）。
  - 常见于大型数组或字符串对象。

- 参数控制：

  - `-XX:PretenureSizeThreshold`：设置超过此大小的对象直接分配到老年代。

  - 示例：

    ```
    -XX:PretenureSizeThreshold=1M
    ```

------

### **3. 动态年龄判断**

- 机制：
  - JVM 会根据实际情况动态调整对象的晋升条件。
  - 如果某一年龄段的对象累计大小超过 **Survivor 区的一半**，则该年龄及以上的所有对象会直接晋升到老年代。
- 目的：
  - 避免 Survivor 区被占满，提升 GC 效率。

------

### **4. Survivor 区不足**

- 机制：

  - 新生对象在 Eden 区分配，经过 Minor GC 后存活的对象被移动到 Survivor 区（S0 或 S1）。
  - 如果 Survivor 区空间不足，存活的对象会直接晋升到老年代。

- 参数控制：

  - `-XX:SurvivorRatio`：调整 Eden 区和 Survivor 区的比例。

  - 示例：

    ```
    -XX:SurvivorRatio=8
    ```

------

### **5. 长期存活的对象**

- 机制：
  - 长生命周期的对象，如缓存、静态对象等，一旦被判断为长期存活，就会被晋升到老年代。
  - 常见于：会话对象（Session）、数据库连接池等。

------

### **6. Full GC 后幸存**

- 机制：
  - 在 Full GC（针对整个堆的 GC）时，如果一个对象存活并且年轻代没有足够空间接纳，最终会被移入老年代。

------

### **7. 直接分配到老年代**

- 机制：
  - 某些情况下，JVM 会直接将对象分配到老年代：
    - 启用了 `-XX:+UseSerialGC` 或其他垃圾收集器策略。
    - 应用场景中频繁分配的大对象，超过年轻代的分配能力。
- 参数控制：
  - `-XX:PretenureSizeThreshold`（见第 2 点）。

------

### **8. 垃圾收集器的特性**

不同的垃圾收集器对老年代分配和晋升的策略可能不同：

- G1 垃圾收集器：
  - 对象按分区管理，可能直接从年轻代晋升到老年代的特定分区。
- CMS 垃圾收集器：
  - 老年代使用并发标记清除，晋升策略与默认垃圾收集器类似。

------

### **参数优化建议**

- 调整晋升阈值：
  - **适合短生命周期对象：** 增大 `MaxTenuringThreshold`，延迟对象晋升。
  - **适合长生命周期对象：** 减小 `MaxTenuringThreshold`，加快晋升速度。
- 配置 Survivor 区：
  - 增大 Survivor 区的比例，避免对象过早晋升。
- 管理大对象：
  - 使用 `-XX:PretenureSizeThreshold`，防止大对象频繁触发 GC。
- 选择合适的垃圾收集器：
  - 针对高吞吐量选择 G1，针对低延迟选择 ZGC 或 Shenandoah。

------

通过监控 GC 日志和调整 JVM 参数，可以优化对象的分配和晋升策略，从而降低 GC 开销，提升程序性能。



## tomcat报错oom和jc问题怎么解决的

##### OOM是指 JVM 无法为应用程序分配足够的内存，导致程序崩溃

通过 JVM 启动参数增加堆内存的初始值和最大值

修改`catalina.sh`脚本的 JAVA_OPTS 参数，JAVA_OPTS="-Xms512m -Xmx1024m"

根据应用程序的特点和性能需求，选择合适的垃圾回收器，调整G1垃圾回收器清理的时间参数

##### jc问题

**编译工具配置错误**：Tomcat 依赖的 Java 编译器（如 JDK 自带的`javac`）配置不正确，导致编译失败。

**JDK 版本不兼容**：应用程序使用的 Java 代码特性与当前 JDK 版本不兼容，从而引发编译错误。

**类路径问题**：编译时找不到所需的类文件，可能是类路径配置错误或依赖库缺失

##### 解决办法

**检查和配置编译工具**：确保 Tomcat 使用的 JDK 版本正确，并且 JDK 的环境变量（如`JAVA_HOME`）配置无误。可以通过以下命令检查 JDK 版本

**确保 JDK 版本兼容**：检查应用程序的 Java 代码特性，确保使用的 JDK 版本支持这些特性。如果代码使用了较新的 Java 特性，需要升级 JDK 版本；如果代码需要兼容旧版本的 Java，需要调整代码或使用合适的 JDK 版本。



## 生产中tomcat用到的问题及排查思路

在生产环境中使用 Tomcat 时，常见的问题主要集中在 **性能、资源、连接、部署、日志、安全等方面**。下面我为你整理一份生产中 Tomcat 常见问题及排查思路，结构清晰、实战导向，适合云计算运维、SRE、DevOps 岗位使用。

------

### 🔧 一、常见问题分类与排查思路

#### 1. 🧠 启动失败

#### 📌 常见问题：

- 端口被占用（默认 8080）
- JAVA_HOME 设置错误
- 内存不足或权限问题
- webapps 目录下 WAR 包异常

#### 🔍 排查思路：

```
# 检查端口是否被占用
netstat -tulnp | grep 8080

# 检查 catalina.out / 日志
tail -n 50 /data/server/tomcat/logs/catalina.out

# 检查环境变量
echo $JAVA_HOME
java -version
```

------

### 2. 🐢 访问慢、接口响应慢（性能问题）

#### 📌 常见原因：

- JVM 堆内存不足，频繁 GC
- 应用逻辑阻塞（数据库慢、IO 慢）
- Tomcat 线程池耗尽
- 后端依赖超时

#### 🔍 排查思路：

```
# 查看 JVM 参数
ps -ef | grep tomcat

# 查看 GC 情况
jstat -gc <pid> 1000 5

# 查看线程情况
ps -Lf <pid> | wc -l

# 查看 APM 工具指标（如 SkyWalking）
```

> 建议启用 `-Xlog:gc*` 或 `-verbose:gc` 并结合 `jvisualvm` 或 `arthas` 查看热点和线程状态。

------

### 3. ❌ 页面 404/500 错误

#### 📌 常见原因：

- WAR 包未部署成功或结构错误
- Spring/Servlet 异常
- 路由配置错误

#### 🔍 排查思路：

```
# 确认 webapps 目录下是否解压成功
ls /data/server/tomcat/webapps/

# 查看 web.xml 配置、应用日志
less logs/catalina.out
less logs/localhost.*.log
```

------

### 4. 📉 内存溢出（OutOfMemoryError）

#### 📌 表现：

- OOM 异常、Tomcat 崩溃重启、Full GC 卡死

#### 🔍 排查思路：

```
# 查看 catalina.out 是否有 java.lang.OutOfMemoryError
grep OutOfMemoryError logs/catalina.out

# 增加堆内存，设置 JVM 参数
-Xms1g -Xmx1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heap.hprof

# 使用 jmap 导出堆，jhat 或 MAT 分析
jmap -dump:format=b,file=/tmp/dump.hprof <pid>
```

------

### 5. 🔄 Session 丢失 / 登录异常

#### 📌 原因：

- 多实例部署但没有 session 共享
- session 失效时间过短
- Cookie 设置错误

#### 🔍 排查：

- 检查 `server.xml` 中 session 配置
- 检查负载均衡器是否设置了粘性会话（sticky session）
- 使用 Chrome DevTools 查看 Cookie

------

### 6. 🔒 安全相关问题

#### 📌 风险项：

- 默认管理页面未禁用 `/manager/html`
- 目录遍历、日志暴露
- 输入未过滤，存在 XSS/SQL 注入风险

#### 🔍 建议：

- 删除不必要的默认应用（`docs`、`examples`、`manager`）
- 禁止目录列表功能：`listings=false`
- 使用 WAF 或 nginx 前端拦截异常请求

------

### 7. 📊 高并发下连接数耗尽（连接池 / 线程池）

#### 📌 原因：

- `maxThreads` 设置太小
- 数据库连接池耗尽
- 请求处理慢未释放连接

#### 🔍 检查配置：

```
# server.xml
<Connector port="8080" maxThreads="300" ... />

# 数据库连接池（如 HikariCP）
maxActive / maxPoolSize 设置过小
```

------

### 8. 🔁 部署后不生效 / 无法热更新

#### 📌 原因：

- 新 WAR 包未完全覆盖旧文件
- 缓存未清理
- `autoDeploy=false`

#### 🔍 建议：

- 删除原有应用目录后再部署 WAR 包
- 设置 autoDeploy=true 或使用 CI 工具部署（如 Jenkins）

------

### 🧰 实用排查工具/命令

| 工具/命令               | 用途               |
| ----------------------- | ------------------ |
| `jps` / `ps -ef`        | 查看 Java 进程     |
| `top` / `htop`          | 监控资源使用       |
| `jstat -gc`             | 查看 JVM GC 情况   |
| `jmap -dump`            | 导出堆             |
| `netstat` / `ss -tulnp` | 查看端口占用       |
| `lsof -i :8080`         | 查看指定端口占用   |
| `tcpdump`               | 抓包分析           |
| `curl -v`               | 模拟请求排查返回头 |

------

### ✅ 总结

| 问题类型   | 排查关键词              |
| ---------- | ----------------------- |
| 启动异常   | 日志、端口、权限        |
| 内存问题   | GC、OOM、jmap           |
| 性能瓶颈   | 线程、连接池、慢 SQL    |
| 连接问题   | maxThreads、数据库连接  |
| 安全风险   | 默认页面、路径暴露      |
| 多实例部署 | Session共享、Cookie粘性 |





# Nginx

## nginx功能

负载均衡upstream、反向代理proxy、访问控制access、gzip压缩、代理缓存proxy_cache_path、防盗链referer、长连接-keepalive

## nginx做过哪些优化

1、指定worker进程数，使其一个CPU核心上执行一个进程

2、隐藏版本号属性信息，在网页上面有nginx的版本号会让别人更容易攻击你的服务器
实现方法：将nginx主配文件http模块的server_tokens属性设置为off

3、调整worker进程的数量和每个worker进程能够同时处理的最大连接数
实现方法：nginx主配置文件下修改worker_processes和worker_connections属性信息

4、开启gzip压缩功能，减小传送资源的大小，从而节约网络资源
实现方法：通过gzip相关指令实现

5、添加防盗链，使用rewrite模块，重写URL
实现方法：通过referer和rewrite模块相关指令实现

6、设置请求限制
定义一定时间段内服务器请求的连接数，防止别人通过大量请求恶意轰炸nginx服务器



## nginx获取用户的来源ip



 ✅ **基础获取方式**
 ✅ **反向代理/多层代理正确配置**
 ✅ **实战案例 (K8s/云环境)**
 ✅ **面试标准答法**

------

### **1️⃣ 获取用户来源 IP — 最基础**

在 **Nginx 日志**里配置日志格式，打印客户端 IP

```
log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                '$status $body_bytes_sent "$http_referer" '
                '"$http_user_agent" "$http_x_forwarded_for"';

access_log /var/log/nginx/access.log main;
```

#### ✅ **$remote_addr**

直接连 Nginx 机器的客户端 IP

------

### **2️⃣ 反向代理/多层代理 (重点)**

如果 **前面还有一层代理** (比如 Nginx → Nginx、CDN → Nginx)，
 Nginx 默认 `$remote_addr` 只拿到「上游代理 IP」，不是用户真实 IP

#### **解决办法**

**启用 X-Forwarded-For 头**

```
real_ip_header X-Forwarded-For;
set_real_ip_from 0.0.0.0/0;
real_ip_recursive on;
```

✅ 说明

- `real_ip_header X-Forwarded-For;` → 信任 HTTP 头里带的 IP
- `set_real_ip_from` → 允许哪些上游 IP 注入 XFF 头 (生产里写可信代理 IP 段)
- `real_ip_recursive on;` → 拿 X-Forwarded-For 头里的第一个真实 IP

------

### **3️⃣ 云环境 / Kubernetes / 复杂代理 (实战重点)**

| 场景                 | 正确变量                                                    |
| -------------------- | ----------------------------------------------------------- |
| 普通单层访问         | `$remote_addr`                                              |
| 反向代理 (1层)       | `$http_x_forwarded_for`                                     |
| 多层代理 / 云WAF/CDN | 配置 `real_ip_header` 后再用 `$remote_addr` (恢复为真实 IP) |



✅ **查看 IP 日志 (验证)**

```
grep your_ip /var/log/nginx/access.log
```

------

### **4️⃣ 面试标准背诵版**

> Nginx 默认通过 `$remote_addr` 获取客户端 IP
>  如果前面有反向代理 (如 CDN/Nginx/WAF)，需要配置 `real_ip_header` 与 `set_real_ip_from`
>  使 Nginx 从 X-Forwarded-For 头中提取真实客户端 IP
>  我实际项目里都会加 `real_ip_recursive on` 保障多层代理正确解析
>  日志格式中也会同时记录 `$remote_addr` 与 `$http_x_forwarded_for` 方便排查溯源

------

### **5️⃣ 配置示例 (企业生产标准)**

```
http {
    log_format main '$remote_addr $http_x_forwarded_for - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent"';

    set_real_ip_from 10.0.0.0/8;    # 只信任内网代理
    set_real_ip_from 192.168.0.0/16;
    real_ip_header X-Forwarded-For;
    real_ip_recursive on;

    access_log /var/log/nginx/access.log main;
}
```

------

### **6️⃣ (实战加分)**

> 我项目中容器化 Nginx + Ingress Controller 也配置了 `real_ip` 保障真实 IP 记录
>  另外我会定期用 `awk '{print $1}' access.log | sort | uniq -c | sort -nr` 统计访问 IP 热点，辅助安全分析

------

### **总结**

| 内容         | 重点                                                  |
| ------------ | ----------------------------------------------------- |
| 获取变量     | `$remote_addr` `$http_x_forwarded_for`                |
| 反向代理配置 | `real_ip_header X-Forwarded-For` + `set_real_ip_from` |
| 多层代理     | `real_ip_recursive on`                                |
| 日志调试     | `log_format` 同时记录 2个变量                         |



## 限制nginx资源访问

很好，这题属于「**Nginx 静态资源缓存优化**」典型考点，
 特别适合回答在 **网站加速 / 反向代理 / 运维优化** 项目中。
 我直接帮你完整整理：
 ✅ **作用原理 (Cache-Control + Expires)**
 ✅ **标准 Nginx 配置**
 ✅ **生产实践 (加分项)**
 ✅ **面试标准答法**

------

### **1️⃣ 原理：设置浏览器缓存时间**

> 让浏览器缓存图片，不用每次都请求服务器，提升性能、节省带宽。

| 指令                       | 作用                                   |
| -------------------------- | -------------------------------------- |
| `expires`                  | 设置 `Expires` 头 + `Cache-Control` 头 |
| `add_header Cache-Control` | 精细控制缓存策略                       |



✅ **7天缓存时间** = `7d`
 Nginx 会自动设置 HTTP 头部：

```
Cache-Control: max-age=604800
Expires: <7天后日期>
```

------

### **2️⃣ Nginx 配置：jpg/png 资源缓存7天**

```
server {
    location ~* \.(jpg|jpeg|png)$ {
        expires 7d;
        add_header Cache-Control "public";
    }
}
```

✅ 说明

- `~*` → 忽略大小写的正则
- `expires 7d;` → 缓存7天
- `add_header Cache-Control "public";` → 允许代理服务器也缓存 (更高效)

------

### **3️⃣ 进阶：区分资源类型缓存时间 (生产加分)**

```
location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
    expires 7d;
    add_header Cache-Control "public";
}

location ~* \.(pdf|doc|xls)$ {
    expires 30d;
    add_header Cache-Control "public";
}
```

------

### **4️⃣ 验证配置 (实战习惯)**

```
curl -I http://your.domain/image.jpg
```

✅ 应该看到响应头

```
Cache-Control: public
Expires: <7天后的时间戳>
```

------

### **5️⃣ 面试标准背诵版**

> 我在项目中通过 Nginx 为静态资源 (如 jpg/png) 设置浏览器缓存7天
>  具体配置为 location ~*.(jpg|png)$ 内用 expires 7d 与 Cache-Control public
>  这样浏览器会缓存图片，提升访问速度，减轻服务器压力
>  生产中我会根据资源类型灵活设置不同缓存时间，并通过 curl 验证配置效果

------

### **6️⃣ 进阶加分：强制不缓存接口**

```
location /api/ {
    add_header Cache-Control "no-store, no-cache, must-revalidate";
}
```

------

### **7️⃣ (K8s/云项目经验加分)**

> 我在容器化 Nginx / Ingress Controller 环境下，也同步配置静态资源缓存
>  保证前端静态资源访问加速，结合 CI/CD 资源指纹 (hash) 实现缓存更新机制

------

### **总结**

| 内容     | 重点                                           |
| -------- | ---------------------------------------------- |
| 设置指令 | `expires 7d; add_header Cache-Control public;` |
| 作用     | 浏览器缓存图片7天，加速访问                    |
| 验证     | `curl -I` 查看响应头                           |
| 加分项   | 区分资源类型缓存 / 强制不缓存接口              |



## **应用层 404 排查标准流程**

(一句话口诀：**路径 → Nginx → 应用日志 → 应用代码 → 方法**)

------

#### **1️⃣ 明确404是应用层还是Nginx层**

```
curl -I http://domain/path
```

- **返回 Server 头 (nginx / tomcat / gunicorn)**，确认 404 来源
- 如果是 Nginx 直接返回 404，是 Nginx 静态资源问题
- 如果 Nginx proxy_pass 正常，404 由应用返回 → **应用层 404**

------

#### **2️⃣ Nginx access.log 验证路径与代理转发**

```
tail -f /var/log/nginx/access.log
```

- 确认请求 URL 是否完整正确

- 确认 Nginx `location / proxy_pass` 配置转发路径是否丢失/错位
   **常见问题：**

  ```
  location /api/ {
      proxy_pass http://backend/;  # 结尾斜杠不同会影响路径
  }
  ```

✅ **如果发现 Nginx 配置转发路径错，修正 Nginx 配置**

------

#### **3️⃣ 应用服务日志 (Tomcat/Java/Node/PHP)**

```
tail -f /var/log/app/app.log
```

- 查应用是否有 404 日志、"No mapping found"/"Route not found" 类错误
- 确认应用收到的路径 (部分框架日志会打印请求路径)

✅ **如果应用没收到请求** → 反代错
 ✅ **如果应用明确返回404** → 看代码

------

#### **4️⃣ 应用代码确认路由定义**

- 查对应 Controller / Route 配置
- 确认路径写法一致 (大小写、斜杠敏感)
- 确认 Controller 模块是否被加载 (有没有部署漏)

> **例子 (Spring Boot)**

```
@RequestMapping("/api")
@GetMapping("/userinfo")
```

前端请求 `/api/usernfo` → 拼写错，404

✅ **如果发现代码没定义该路由，明确是接口不存在**

------

#### **5️⃣ 方法匹配验证 (GET/POST)**

- 确认前端请求方法和后端接口定义是否一致
   **例子 (后端只定义 POST)**

```
@PostMapping("/login")
```

前端用 GET 访问 `/login` → 也可能 404

✅ **如果发现方法不匹配，修正前端请求或补充接口**

------

#### **6️⃣ 浏览器开发者工具 (Network)**

- F12 → Network → 查看请求路径/方法/响应状态码
- 结合 curl 二次确认

```
curl -X POST http://domain/api/userinfo
```

------

#### **7️⃣ 统一404处理页 (生产加分项)**

> 我们项目习惯配置「统一404处理」，便于定位和用户提示

------

#### ✅ **面试标准答案 (背诵版)**

> 我排查应用层404，思路是 ① 先确认404来源 (Nginx还是应用)
>  ② 查 Nginx access.log 与配置 proxy_pass 是否正确转发
>  ③ 查应用日志确认路径与错误
>  ④ 结合应用代码确认路由是否有定义
>  ⑤ 最后确认请求方法是否匹配
>  生产环境我也会配置统一404处理，便于监控与排查

------

#### 📋 **总结表**

| 步骤                  | 操作                    | 工具       |
| --------------------- | ----------------------- | ---------- |
| 1. 确认来源           | curl/Server头           | curl       |
| 2. 查Nginx路径        | access.log / proxy_pass | tail / vim |
| 3. 查应用日志         | app.log                 | tail       |
| 4. 看应用代码         | Controller 路由         | IDE        |
| 5. 验证方法           | GET/POST匹配            | curl       |
| 6. 浏览器验证         | Network                 | F12        |
| 7. 统一404处理 (加分) | 自定义页面              | 代码       |



## 常见的状态码




 ✅ **分类记忆表**
 ✅ **标准解释 + 实战例子**
 ✅ **面试标准答题版**

------

### 🌐 **HTTP 常见状态码 (分类速记)**

| 类别 | 范围    | 代表意思          |
| ---- | ------- | ----------------- |
| 1xx  | 100–199 | 信息提示 (较少用) |
| 2xx  | 200–299 | 成功              |
| 3xx  | 300–399 | 重定向            |
| 4xx  | 400–499 | 客户端错误        |
| 5xx  | 500–599 | 服务器错误        |



------

### ✅ **1️⃣ 2xx 成功**

| 状态码         | 含义             | 场景                  |
| -------------- | ---------------- | --------------------- |
| 200 OK         | 请求成功         | 正常返回网页/接口数据 |
| 201 Created    | 成功创建资源     | POST 创建新用户/数据  |
| 204 No Content | 成功但无返回内容 | 删除接口成功，无返回  |



------

### ✅ **2️⃣ 3xx 重定向**

| 状态码                | 含义       | 场景                      |
| --------------------- | ---------- | ------------------------- |
| 301 Moved Permanently | 永久重定向 | 网站域名迁移，SEO友好     |
| 302 Found             | 临时重定向 | 登录后跳转页面            |
| 304 Not Modified      | 资源未改动 | 浏览器缓存命中 (节省带宽) |



------

### ✅ **3️⃣ 4xx 客户端错误**

| 状态码                 | 含义              | 场景                 |
| ---------------------- | ----------------- | -------------------- |
| 400 Bad Request        | 请求格式错误      | JSON 参数不规范      |
| 401 Unauthorized       | 未认证 (需要登录) | 访问受限接口未登录   |
| 403 Forbidden          | 禁止访问          | 权限不足/被封禁      |
| 404 Not Found          | 资源不存在        | 路径拼错/接口未定义  |
| 405 Method Not Allowed | 方法不允许        | POST接口用GET访问    |
| 408 Request Timeout    | 请求超时          | 客户端请求过慢被断开 |



------

### ✅ **4️⃣ 5xx 服务器错误**

| 状态码                    | 含义                  | 场景               |
| ------------------------- | --------------------- | ------------------ |
| 500 Internal Server Error | 服务器内部错误        | 应用崩溃/代码异常  |
| 502 Bad Gateway           | 网关错误 (上游无响应) | Nginx 转发后端挂掉 |
| 503 Service Unavailable   | 服务不可用            | 应用维护/限流      |
| 504 Gateway Timeout       | 网关超时              | Nginx转发后端超时  |



------

### 🛠️ **面试标准答法 (可直接背)**

> HTTP 状态码主要分为5类
>  ① 2xx 成功 ② 3xx 重定向 ③ 4xx 客户端错误 ④ 5xx 服务器错误
>  项目中常见有：200成功、301/302重定向、304缓存命中、400参数错、401未登录、403权限不足、404路径不存在
>  还有 500应用异常、502/504反向代理超时错
>  生产环境我习惯结合 Nginx 日志和应用日志，通过状态码快速定位故障类型

------

### ✅ **高频面试加分技巧 (状态码与运维关联)**

| 状态码 | 运维排障经验                    |
| ------ | ------------------------------- |
| 404    | 应用层/反代配置错/资源丢失      |
| 500    | 代码Bug/服务异常/内存溢出       |
| 502    | Nginx反代后端服务挂掉           |
| 504    | Nginx转发超时 (后端慢查询)      |
| 503    | 应用限流/维护中 (K8s pod重启时) |
| 304    | Nginx静态资源缓存优化效果好     |



------

### 📋 **总结表 (考试背诵版)**

| 分类 | 状态码                      | 含义                                             |
| ---- | --------------------------- | ------------------------------------------------ |
| 2xx  | 200 / 201 / 204             | 成功 / 创建 / 无内容                             |
| 3xx  | 301 / 302 / 304             | 永久跳转 / 临时跳转 / 缓存命中                   |
| 4xx  | 400 / 401 / 403 / 404 / 405 | 参数错 / 未登录 / 权限不足 / 路径不存在 / 方法错 |
| 5xx  | 500 / 502 / 503 / 504       | 服务器错 / 反代坏 / 服务不可用 / 超时            |



## Nginx和apache有什么区别

```
Nginx:
1、Nginx 是一个事件驱动的异步 Web 服务器，它采用 非阻塞 I/O 模型，能够同时处理大量的连接请求。每个请求都是独立的，因此 Nginx 可以高效地处理大量的并发请求，而不容易耗尽系统资源。
2、它是 轻量级 和 高效能 的，尤其在处理静态内容和高并发请求时表现非常出色。
3、由于其非阻塞的设计，Nginx 能够高效地处理大量并发连接，尤其是在处理静态资源时，性能比 Apache 优越。
4、它适用于高并发和高流量的网站，能够轻松应对数以千计的并发请求。
Apache:
1、Apache 采用 多线程/多进程模型，也可以配置为事件驱动模式（如使用 worker 或 event MPM）。在默认配置下，Apache 为每个请求创建一个新的线程或进程，导致在高并发情况下消耗较多的内存和 CPU 资源。
2、这种模式适合于处理动态内容，但在面对大量的并发连接时，可能会显得性能不如 Nginx。
3、Apache 在单一请求的处理上表现良好，但由于其线程/进程模型，在高并发环境下会出现性能瓶颈。
4、处理静态文件时，Apache 的性能往往不如 Nginx，但如果启用了适当的模块（如 mod_php），它可以在动态内容处理上表现得更好。
```



## 攻击者使用未注册的域名访问服务器

当有攻击者使用未注册的域名访问服务器时，默认的 Nginx 配置可能会处理这些请求。如何解决？

```
配置默认的server_name
	server_name _;  # 匹配任何未指定的域名
	return 444;
```



## 请简述Nginx的进程结构

```
Master进程
	Master 进程是 Nginx 的核心进程，负责管理和控制其他工作进程。它不直接处理客户端请求，而是负责启动、停止和维护工作进程，管理配置文件的加载和重载。
		启动和监控工作进程。
		监听信号，如平滑重载配置、停止工作进程等。
		创建共享资源，如共享内存、缓存等。
		当配置文件修改时，负责重新加载配置，并平滑重启工作进程。
		如果某个工作进程崩溃，master 进程会自动重新启动它。
worker进程
		Worker 进程是负责实际处理客户端请求的进程。每个 Worker 进程独立处理网络连接、请求、响应等。
		处理客户端请求，读取请求、解析、执行相关操作，并返回响应。
		一个 Nginx 实例可以有多个 Worker 进程，通常根据 CPU 核心数来配置，保证充分利用多核 CPU 进行并行处理。
		Worker 进程之间共享内存中的缓存、连接池等资源，但每个进程是独立的，互不干扰。
Worker Connection
		每个 Worker 进程可以同时处理多个连接，它们通过事件驱动机制来处理并发连接。Nginx 使用非阻塞的 I/O 模型和事件通知机制（如 epoll、kqueue、select）来提高并发处理能力。
```



## Nginx的优点是什么

```
1. 高性能
2. 低资源消耗
3. 高可靠性和稳定性
4. 负载均衡
5. 反向代理和缓存功能
6. 安全性
```



## 什么是正向代理和反向代理？

```
正向代理
	正向代理是指客户端通过代理服务器访问目标服务器。它的主要功能是让客户端可以绕过某些网络限制（如访问控制、地域限制等），或者隐藏客户端的真实 IP 地址。
反向代理
	向代理是指客户端并不直接访问目标服务器，而是通过代理服务器来访问。目标服务器并不知道客户端的存在，所有请求都由反向代理服务器转发到正确的后端服务器。反向代理通常用于负载均衡、安全保护和优化性能等目的。
```



## Nginx负载均衡的算法怎么实现的?策略有哪些?

```
轮询：
	请求按照顺序依次分发给每个后端服务器，当分发完所有服务器后，重新从第一个服务器开始分配。

加权轮询：
	加权轮询中，每个后端服务器都有一个权重值。Nginx 按照权重比例将请求分配给服务器，权重较高的服务器会分配到更多的请求。

IP Hask
	Nginx 使用客户端 IP 地址的哈希值来决定请求转发的服务器。通过哈希算法将客户端 IP 地址映射到某个服务器。
	
最少连接数
	当有多个服务器时，Nginx 会选择当前负载最轻的（即连接数最少的）服务器来处理请求。
```



## 你对nginx做过哪些优化

```powershell
1、调整 worker_processes 和 worker_connections
	worker_processes：设置工作进程数，通常设置为 CPU 核心数或 auto。
	worker_connections：每个 worker 进程能够处理的最大连接数。通常根据服务器的硬件资源来调整。
	worker_processes auto;
	worker_connections 1024;
2、开启异步事件驱动模型 Nginx 默认采用异步事件驱动模型，这样可以最大化利用系统资源。
	vents {
    	worker_connections 1024;
    	use epoll;
	}
3、加权轮询 对后端服务器配置不同的权重，确保负载根据服务器能力分配，避免过载。
	upstream static {
    	server 10.0.0.1 weight=3;
    	server 10.0.0.2 weight=2;
    	server 10.0.0.3;
	}
4、使用 least_conn 使用 least_conn（最少连接数）策略，选择当前连接数最少的服务器进行处理，避免过载
	upstream static {
    	least_conn;
    	server 10.0.0.1;
    	server 10.0.0.2;
	}
5、使用 proxy_cache 或 fastcgi_cache 对后端内容进行缓存，以减少数据库和应用服务器的负担。
	location / {
    	proxy_cache my_cache;
    	proxy_cache_valid 200 1h;
    	proxy_cache_use_stale error timeout updating;
	}
6、设置 limit_conn 和 limit_req 来限制连接和请求频率。
	limit_conn_zone $binary_remote_addr zone=addr:10m;
	limit_conn addr 1;
7、配置 Nginx 为反向代理服务器，并启用缓存，减少后端服务器的负载。对于动态内容，可以根据缓存策略决定缓存时间和更新频率。
	location /api/ {
    	proxy_cache my_cache;
    	proxy_cache_valid 200 1m;
    	proxy_cache_use_stale error timeout updating;
    }
  启用缓存控制
	location / {
    	add_header Cache-Control "public, max-age=3600";
	}
8、结亲缘
	worker_processes auto;
	worker_cpu_affinity 01 10;
```



## 说一下nginx的location中匹配优先级

```
= 	>	 ^~ 	>	 ~* 	>	 ~ 	>	 /str 
```



## 你用过的nginx的常用模块有哪些

```
Core Modules (核心模块)
	ngx_http_core_module： 这是 Nginx 最基础的模块，提供了 HTTP 请求的基本处理能力，例如请求路由、位置匹配、响应返回等。
	ngx_http_rewrite_module： 提供 URL 重写功能，常用于 URL 结构优化和重定向等操作。
	ngx_http_access_module： 用于访问控制，可以限制特定 IP 地址或地址段的访问。
	ngx_http_gzip_module： 启用 GZIP 压缩，减少传输数据量，加速页面加载。
	ngx_http_static_module： 用于处理静态文件（如图片、CSS、JavaScript）请求的模块，默认启用。

Load Balancing Modules (负载均衡模块)
	ngx_http_upstream_module： 用于配置反向代理和负载均衡，支持多种负载均衡算法（如轮询、最少连接等）。
	ngx_http_healthcheck_module： 提供健康检查功能，定期检查后端服务器的健康状况，并根据检查结果自动调整负载均衡策略。

Security Modules (安全模块)
	ngx_http_limit_conn_module： 用于限制每个 IP 地址的并发连接数，防止过度的并发请求。
	ngx_http_limit_req_module： 用于限制请求频率，防止 DoS 攻击和恶意请求。
	ngx_http_headers_module： 用于配置 HTTP 响应头，增强安全性（如 Strict-Transport-Security、X-Frame-Options 等）。

SSL and Security Modules (SSL 和安全模块)
	ngx_http_ssl_module： 用于启用 HTTPS 支持，提供 SSL/TLS 加密功能。
	ngx_http_secure_link_module： 用于生成和验证安全链接，可以用于防止文件盗链和限制文件的访问。

```







# linux

## Crash处理方式

### 一、Crash 处理的总体思路

1. **现场保留（第一要务）**
    尽量不要立刻重启或强制关机，优先保留崩溃现场信息，尤其是日志和内存镜像。
2. **快速恢复服务（降低影响）**
    在保留数据后，评估是否需要重启服务或切换至备用机，保障业务连续性。
3. **深度分析原因（根因排查）**
    分析系统日志、转储文件（core dump / kdump）、硬件监控数据，定位问题根因。
4. **制定预防方案（防止复发）**
    根据排查结果，更新系统配置、打补丁或替换硬件，防止类似 Crash 再次发生。

------

### 二、常见 Crash 场景与处理方法

#### 1. 内核崩溃（Kernel Panic）

**症状**
 黑屏、自动重启，终端提示 `kernel panic` 相关字样。

**操作步骤**

- 查看 `/var/log/messages`、`/var/log/kern.log`，定位 panic 前后的日志。

- 启用 **kdump** 捕获内核崩溃 dump（需预先配置）：

  - 查看 `/var/crash/` 下的转储文件并用 `crash` 工具分析。

- 分析是否由于：

  - 内核 Bug（考虑更新内核）
  - 驱动冲突（禁用/更换驱动）
  - 硬件故障（内存条、电源等）

- 参考命令：

  ```
  dmesg | less
  less /var/log/messages
  crash /usr/lib/debug/lib/modules/$(uname -r)/vmlinux /var/crash/<vmcore>
  ```

------

#### 2. 文件系统损坏

**症状**
 系统启动失败，提示 `fsck` 或文件无法读写。

**操作步骤**

- 进入救援模式（Live CD 或单用户模式）。

- 执行文件系统检查修复：

  ```
  fsck -y /dev/sdX
  ```
  
- 查看 `dmesg` 和 `/var/log/messages` 判断是否磁盘硬件故障。

- 备份重要数据，必要时更换磁盘。

------

#### 3. 内存不足（OOM Killer）

**症状**
 应用异常终止，日志提示 `Out of Memory` 或 `oom-killer invoked`。

**操作步骤**

- 查看 `/var/log/messages`、`dmesg` 查找 OOM 记录。

- 分析占用内存进程：

  ```
  free -h
  top
  cat /proc/meminfo
  ```

- 调整：

  - 增加 Swap 空间
  - 优化内存泄漏进程
  - 配置 `vm.overcommit_memory` 或应用 `ulimit`

------

#### 4. 硬件故障（硬盘/内存/电源）

**症状**
 随机重启、I/O Error、多次 Kernel Panic。

**操作步骤**

- 检查硬盘 S.M.A.R.T 状态：

  ```
  smartctl -a /dev/sdX
  ```
  
- 执行内存检测（如 `memtest86+`）

- 查看硬件日志（如 IPMI SEL / BMC 日志）

- 联系硬件厂商更换故障部件

------

### 三、Crash 应急处理清单（可实际操作）

| 操作事项     | 关键命令 / 工具                           |
| ------------ | ----------------------------------------- |
| 查看最近日志 | `journalctl -xe` `less /var/log/messages` |
| 分析内核日志 | `dmesg`                                   |
| 捕获内核转储 | 预先配置 `kdump`，查看 `/var/crash/`      |
| 检查磁盘健康 | `smartctl -a /dev/sdX`                    |
| 文件系统修复 | `fsck -y /dev/sdX`                        |
| 内存占用分析 | `free -h` `top` `vmstat 1`                |
| 生成硬件报告 | `lshw` `dmidecode`                        |



------

### 四、预防性配置建议（平时准备）

- 配置 **kdump** 捕获崩溃内核镜像。
- 定期执行 **SMART 检测** 和内存测试。
- 配置 **自动化日志收集和告警**（如 Prometheus + Alertmanager + ELK）。
- 配置 **HA（高可用集群）/备份方案** 保障业务持续。

------

如果你告诉我你的场景是：
 **云计算运维 / Kubernetes / 虚拟化环境 / 普通物理服务器**
 我可以给你“更细化”的 Crash 处理方案。



## liunx系统优化

在生产环境中，**Linux 系统配置优化** 主要从以下几个方面入手：**性能优化、网络优化、安全加固、内核参数调优、文件系统调优等**。下面是你在面试中可以回答的一套 **系统优化清单**，结构清晰、条理分明，适合面试表达：

------

### ✅ 一、CPU、内存与进程优化

#### 1. 设置系统资源限制（ulimit）

```
ulimit -n 65535      # 打开文件数限制
ulimit -u 65535      # 用户最大进程数
```

> 配置文件：`/etc/security/limits.conf`、`/etc/systemd/system.conf`

------

### ✅ 二、网络参数优化（高并发场景重要）

```
# 修改 /etc/sysctl.conf 或临时生效
net.core.somaxconn = 1024               # backlog 队列长度
net.core.netdev_max_backlog = 5000      # 接收数据包队列
net.ipv4.tcp_tw_reuse = 1               # TIME_WAIT 端口复用
net.ipv4.tcp_fin_timeout = 15           # FIN_WAIT 时间
net.ipv4.tcp_syncookies = 1             # SYN 攻击防护
net.ipv4.ip_local_port_range = 1024 65535  # 本地端口范围
bash


sysctl -p    # 使配置生效
```

------

### ✅ 三、内核参数调优（高负载场景）

```
vm.swappiness = 10         # 降低内存换出频率，建议设为 10
vm.max_map_count = 262144  # Elasticsearch 等中间件需要
fs.file-max = 655350       # 最大打开文件句柄数
```

> 修改文件 `/etc/sysctl.conf`，或使用 `sysctl -w key=value` 临时修改

------

### ✅ 四、磁盘与 I/O 优化

- 修改挂载参数，启用 `noatime` 减少磁盘写入
- 检查磁盘 I/O 调度器（适合 SSD 的为 `none` 或 `deadline`）

```
cat /sys/block/sdX/queue/scheduler
echo deadline > /sys/block/sdX/queue/scheduler
```

------

### ✅ 五、服务启动优化

- 关闭无用服务（节省内存和启动时间）

```
systemctl disable bluetooth firewalld cups avahi-daemon
```

- 使用 `systemd-analyze` 检查启动耗时

------

### ✅ 六、安全加固优化

- 禁用不必要的端口和服务（如 telnet、ftp）

- 开启防火墙（如使用 `firewalld`、`iptables`）

- 设置 SSH 安全参数：

  ```
  PermitRootLogin no
  PasswordAuthentication no
  ```

- 配置 Fail2Ban 防止暴力破解

------

### ✅ 七、日志轮转和系统日志优化

- 使用 `logrotate` 管理系统日志
- 限制日志保留大小和天数，防止占满磁盘

------

### ✅ 八、时钟同步

- 安装并启用 `chronyd` 或 `ntpd`，确保系统时间准确

```
yum install chrony -y
systemctl enable --now chronyd
```

------

### ✅ 九、自动化优化脚本（建议）

你可以写一个自动化的 shell 脚本，实现批量系统初始化优化，面试中可以提一句：“我还编写过系统初始化优化脚本，用于批量自动配置内核参数、时区、最大连接数等。”

------

### 🎯 面试回答示例（可参考背诵）

> 在生产环境中，我通常会从系统资源限制（如 ulimit）、内核参数（如 tcp backlog、swappiness）、网络连接（如 TIME_WAIT 复用）、磁盘调度器、日志轮转、安全策略（如 SSH 加固、防火墙）等多个维度对 Linux 系统进行优化，并根据具体业务特性做定制化调优。同时会使用脚本进行自动化初始化，提升配置一致性和效率。



## linux系统配置优化有哪些

防火墙、selinux

修改文件最大描述符，vim /etc/sysctl.conf，fs.file-max = 1048576，sysctl -p，在处理大量并发连接时，每个连接都需要一个文件描述符。如果文件描述符数量受限，服务器在达到限制后就无法再接受新的连接

使用 Nexus 构建过私有仓库，当团队成员需要下载依赖时，Nexus 会首先检查本地仓库中是否已经存在该依赖，如果没有则从公共仓库下载，并缓存到本地。这样下次再有相同的下载请求时，就可以直接从本地获取，加快下载速度

云环境中，直接从公共互联网仓库获取软件依赖，可能会产生较高的外网流量费用，且在网络不稳定时影响效率。Nexus 私有仓库可作为本地缓存，将常用的软件组件存储在云内，团队成员再次获取相同依赖时，可直接从私有仓库获取，大大减少对外网的访问，降低流量成本，同时提升访问速度，避免因外网网络波动导致的下载中断等问题



## 机器上是哪块磁盘满了，查看是哪些文件导致的，依次会用到那些命令

要查看一台 Linux 机器上是哪块磁盘满了，以及具体是哪些文件导致的磁盘空间占用，通常我们会按以下**排查顺序**来执行命令：

------

### 🧭 一、查看磁盘使用情况（找出哪个分区满了）

```
df -h
```

#### 示例输出：

```
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda2        40G   39G  500M  99% /
/dev/sdb1       100G   20G   80G  20% /data
```

#### 分析：

- 重点看哪个分区 `Use%` 比较高，尤其是 `99%` 或 `100%` 的。
- 假设 `/` 分区满了，我们接下来就查 `/` 目录下是哪个目录/文件导致的。

------

### 🧭 二、定位大目录（逐层找出占用空间最多的目录）

```
# 从根目录查看，找出占用最大的子目录
sudo du -xhd1 / | sort -hr | head -n 10
```

#### 参数解释：

- `du`：显示目录或文件的磁盘使用量
- `-x`：不要跨文件系统（只看当前挂载点）
- `-h`：以人类可读的方式显示（如 GB、MB）
- `-d1`：只显示一层子目录
- `sort -hr`：按大小倒序排列
- `head -n 10`：取前 10 条

#### 示例输出：

```
3.2G    /var
2.1G    /usr
800M    /root
...
```

然后依次往下深入，比如发现 `/var` 很大：

```
sudo du -xhd1 /var | sort -hr | head -n 10
```

------

### 🧭 三、定位大文件（精确找到哪个文件最大）

```
sudo find /var -type f -size +100M -exec ls -lh {} \; | sort -k5 -hr | head -n 20
```

#### 含义：

- 查找 `/var` 目录下所有大于 100MB 的文件
- 显示文件大小、路径
- 按文件大小排序取前 20 个

------

### 🧭 四、常见的磁盘占用来源（排查重点目录）

| 目录              | 排查内容                                                  |
| ----------------- | --------------------------------------------------------- |
| `/var/log`        | 日志是否爆涨（如 `messages`、`audit.log`、`kubelet.log`） |
| `/tmp`            | 临时文件未清理                                            |
| `/var/lib/docker` | 容器日志、镜像占满磁盘                                    |
| `/home`           | 用户下载或测试文件                                        |
| `/root`           | 超管日志或下载包                                          |
| `/var/cache`      | 缓存文件过多                                              |



------

### 🧹 五、常用清理命令（谨慎执行）

> ⚠️ 生产环境前一定要确认是否能删除，建议先备份。

#### 清理系统日志：

```
sudo journalctl --vacuum-time=3d      # 清理 3 天前的日志
sudo journalctl --disk-usage          # 查看占用空间
```

#### 清理 docker 镜像/容器（如果用到 docker）：

```
docker system df                      # 查看 docker 占用
docker system prune -af               # 删除所有未用的容器/镜像/网络
```

------

### ✅ 总结流程图：

```
1. df -h       ← 先看哪个磁盘满了
      ↓
2. du -xhd1 /path    ← 找出最大目录
      ↓
3. find + sort       ← 找出大文件
      ↓
4. rm / logrotate    ← 决定是否清理
```





## linux的常用命令

### 一、文件与目录操作

| 命令    | 说明           | 示例                       |
| ------- | -------------- | -------------------------- |
| `ls`    | 列出目录内容   | `ls -l /etc`               |
| `cd`    | 切换目录       | `cd /var/log`              |
| `pwd`   | 显示当前目录   | `pwd`                      |
| `mkdir` | 创建目录       | `mkdir testdir`            |
| `rmdir` | 删除空目录     | `rmdir testdir`            |
| `rm`    | 删除文件或目录 | `rm -rf testdir/`          |
| `cp`    | 复制文件或目录 | `cp file1.txt /tmp/`       |
| `mv`    | 移动或重命名   | `mv a.txt b.txt`           |
| `touch` | 创建空文件     | `touch new.txt`            |
| `find`  | 查找文件       | `find /etc -name "*.conf"` |

------

### 二、文件内容查看

| 命令   | 说明             | 示例                           |
| ------ | ---------------- | ------------------------------ |
| `cat`  | 查看文件内容     | `cat /etc/hosts`               |
| `more` | 分页查看         | `more /etc/services`           |
| `less` | 更强大的分页查看 | `less /var/log/messages`       |
| `head` | 查看前几行       | `head -n 20 file.log`          |
| `tail` | 查看尾部内容     | `tail -f /var/log/syslog`      |
| `grep` | 内容搜索         | `grep 'error' /var/log/syslog` |

------

### 三、用户与权限管理

| 命令       | 说明         | 示例                       |
| ---------- | ------------ | -------------------------- |
| `useradd`  | 添加用户     | `useradd testuser`         |
| `passwd`   | 修改密码     | `passwd testuser`          |
| `userdel`  | 删除用户     | `userdel -r testuser`      |
| `groupadd` | 添加组       | `groupadd devops`          |
| `chmod`    | 修改权限     | `chmod 755 script.sh`      |
| `chown`    | 修改所有者   | `chown root:root file.txt` |
| `id`       | 查看用户信息 | `id testuser`              |

------

### 四、系统状态与资源管理

| 命令     | 说明                         | 示例                |
| -------- | ---------------------------- | ------------------- |
| `top`    | 实时查看进程                 | `top`               |
| `htop`   | 彩色进程查看（需安装）       | `htop`              |
| `ps`     | 查看进程信息                 | `ps aux             |
| `free`   | 查看内存                     | `free -h`           |
| `df`     | 查看磁盘空间                 | `df -h`             |
| `du`     | 查看目录大小                 | `du -sh /var/log/*` |
| `uptime` | 查看系统运行时间             | `uptime`            |
| `vmstat` | 查看系统资源                 | `vmstat 1`          |
| `iostat` | 查看磁盘IO（需安装 sysstat） | `iostat -x 1`       |

------

### 五、网络相关

| 命令               | 说明               | 示例                                  |
| ------------------ | ------------------ | ------------------------------------- |
| `ip a` / `ip addr` | 查看IP地址         | `ip a`                                |
| `ip r`             | 查看路由表         | `ip route`                            |
| `ping`             | 网络连通测试       | `ping 8.8.8.8`                        |
| `netstat`          | 查看端口（需安装） | `netstat -tulnp`                      |
| `ss`               | 替代 netstat       | `ss -tuln`                            |
| `curl`             | 请求 URL           | `curl http://example.com`             |
| `wget`             | 下载文件           | `wget http://example.com/file.tar.gz` |
| `scp`              | 远程复制           | `scp file user@host:/path/`           |
| `ssh`              | 远程登录           | `ssh user@192.168.1.10`               |

------

### 六、软件包管理（以常见系统为例）

- **Debian/Ubuntu**

| 命令                | 说明           |
| ------------------- | -------------- |
| `apt update`        | 更新软件源     |
| `apt upgrade`       | 升级所有软件包 |
| `apt install <pkg>` | 安装软件       |
| `apt remove <pkg>`  | 删除软件       |

- **RHEL/CentOS/Rocky**

| 命令                | 说明     |
| ------------------- | -------- |
| `dnf install <pkg>` | 安装软件 |
| `dnf remove <pkg>`  | 卸载软件 |
| `dnf update`        | 更新系统 |

------

### 七、服务管理（以 systemd 为例）

| 命令                | 说明         | 示例                      |
| ------------------- | ------------ | ------------------------- |
| `systemctl start`   | 启动服务     | `systemctl start nginx`   |
| `systemctl stop`    | 停止服务     | `systemctl stop nginx`    |
| `systemctl restart` | 重启服务     | `systemctl restart nginx` |
| `systemctl status`  | 查看服务状态 | `systemctl status nginx`  |
| `systemctl enable`  | 开机自启     | `systemctl enable nginx`  |
| `systemctl disable` | 禁用开机启动 | `systemctl disable nginx` |

------

### 八、压缩与解压

| 命令       | 说明             | 示例                           |
| ---------- | ---------------- | ------------------------------ |
| `tar -czf` | 压缩为 `.tar.gz` | `tar -czf backup.tar.gz /data` |
| `tar -xzf` | 解压 `.tar.gz`   | `tar -xzf backup.tar.gz`       |
| `zip -r`   | 压缩为 `.zip`    | `zip -r backup.zip /data`      |
| `unzip`    | 解压 `.zip`      | `unzip backup.zip`             |



##  文本三剑客

当然可以！Linux 中的“文本三剑客”指的是：

> **`grep`、`sed`、`awk`**

这三者是处理文本的强大工具，常用于日志分析、批量替换、数据提取等场景，是 Linux 运维和开发人员必学技能。以下是整理好的内容，便于理解和查阅。

------

### 🧩 文本三剑客总览表

| 工具   | 全称                            | 功能定位     | 常见用途                 |
| ------ | ------------------------------- | ------------ | ------------------------ |
| `grep` | Global Regular Expression Print | 文本过滤     | 查找包含某些模式的行     |
| `sed`  | Stream EDitor                   | 流编辑器     | 批量替换、删除、插入文本 |
| `awk`  | Aho-Weinberger-Kernighan        | 报表生成工具 | 按列处理文本、格式化输出 |



------

### 🔍 一、`grep` — 查找器

#### 常用功能

- 从文本中查找包含特定“模式”的行
- 支持正则表达式匹配

#### 常用语法

```
grep [选项] "模式" 文件
```

#### 示例

```
grep "error" /var/log/syslog              # 查找包含 error 的行
grep -i "error" syslog.log                # 忽略大小写查找
grep -v "DEBUG" syslog.log                # 反向匹配
grep -r "timeout" /var/log                # 递归目录查找
```

------

### 🔧 二、`sed` — 替换器

#### 常用功能

- 对文本进行 **“查找 + 替换”** 操作
- 支持删除、插入、追加行等

#### 常用语法

```
sed [选项] '操作命令' 文件
```

#### 常见操作命令格式：`s/原内容/新内容/`

#### 示例

```
sed 's/http/https/' file.txt              # 将第一处 http 替换为 https
sed 's/http/https/g' file.txt             # 替换所有 http
sed -i 's/old/new/g' file.txt             # 原地修改文件（写回文件）
sed -n '5,10p' file.txt                   # 仅打印第 5 到 10 行
sed '/^#/d' config.cfg                    # 删除所有以 # 开头的行
```

------

### 📊 三、`awk` — 报表大师

#### 常用功能

- 按列处理文本
- 支持运算、条件判断、格式化输出
- 类似一个专门处理结构化文本的迷你脚本语言

#### 常用语法

```
awk '条件 {动作}' 文件
```

#### 示例

```
awk '{print $1}' file.txt                 # 打印每行第1列
awk '{print $1, $3}' file.txt             # 打印第1和第3列
awk -F: '{print $1}' /etc/passwd          # 指定分隔符为冒号
awk '$3 > 1000 {print $1, $3}' /etc/passwd # 第三列大于1000时打印
```

------

### 🔗 三剑客组合应用示例

#### 示例 1：查找包含错误关键字的日志并高亮

```
grep --color=auto -i "error" /var/log/nginx/error.log
```

#### 示例 2：批量替换配置文件中的路径

```
sed -i 's/\/usr\/local/\/opt\/tools/g' *.conf
```

#### 示例 3：分析访问日志的 IP 排行榜

```
awk '{print $1}' access.log | sort | uniq -c | sort -nr | head
```

------

### 🧠 总结记忆技巧

| 工具   | 功能关键字 | 快速记忆法         |
| ------ | ---------- | ------------------ |
| `grep` | 查找       | 找出你要的行       |
| `sed`  | 替换       | 像编辑器一样替内容 |
| `awk`  | 提取       | 想要哪列就取哪列   |





## 正则匹配ipv4地址

```
\b(?:(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]?\d)\.){3}(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]?\d)\b
```



# CICD

### cicd发布流程

CI阶段：

开发人员提交代码到 GitLab，Jenkins 通过 webhook 自动触发构建流程，进行代码拉取、编译打包，构建后会自动执行单元测试、集成

测试，并接入 SonarQube 做代码质量扫描，测试和代码检查通过后，生成测试报告反馈给开发人员。

 CD阶段：

然后 Jenkins 会将构建产物（如 jar 包）推送到Harbor，之后自动部署到预发布环境，进行功能测试和性能测试，如果测试通过，会通过

审批流程确认，最终部署到生产环境，上线后，我们通过zabbix、Grafana 等工具实时监控服务状态，一旦发现异常，可以快速回滚并通

知开发团队修复

## jenkins



## gitlab





# ansible

## `ansible-doc` 命令

这是查找模块参数的官方命令行工具，适合所有用户。

### 示例：查找 `copy` 模块的所有参数

```
ansible-doc copy
```

## ansible常用的模块

**setup模块（重点）**

收集主机的系统信息，这些facts信息可以直接以变量的形式使用，但是如果主机较多，会影响执行速度，可以使用`gather_facts:no`来禁止Ansible收集facts信息

**copy模块（重点）**

将ansible主机上的文件复制到远程主机，此模块具有幂等性

**yum/apt**

管理软件包，支持安装、更新、删除等操作

**service**

用于管理系统服务，如启动、停止、重启、设置开机自启等

**lineinfile**

主要对文件单行进行替换修改

**blockinfile**

插入或替换多行文本块

**template模块**

使用 Jinja2 模板引擎将本地的模板文件渲染后复制到远程主机，常用于根据不同的主机变量生成不同的配置文件

**replace模块**

与lineinfile模块功能类似，也是基于正则匹配的模式来修改文件，但与lineinfile不同的是replace模块用于多行匹配和修改

**script模块**

可以在远程主机上运行ansible机器上的脚本（而且脚本文件可以没有执行权限），这里的脚本并不仅仅只是shell脚本，只要远程主机上能执行的，都可以，包括但不限于php,sh,py等

**set_fact模块**

用于在Ansible中动态设置变量。这些变量(或“事实”)在任务执行期间可以被后续任务引用。 通过`set_fact`，你可以在Ansible playbook中创建或更新变量，甚至构建复杂的数据结构

**debug模块**

主要用于调试时使用，通常的作用是将一个变量的值打印出来

## playbook的格式

#### 1、定义play

定义用于描述这个 play 的目的（name）

指定执行任务的目标主机或主机组（hosts）

指定连接到目标主机时使用的远程用户（remote_user）

#### 2、定义具体任务

定义要在远程主机上执行的具体操作（tasks），每个任务由name和实现具体任务的模块组成

可以在playbook中使用变量、条件判断、循环、处理器来实现各种功能结果

变量可以在Playbook中直接定义，也可以从外部文件或命令行参数中引入

handlers处理器不直接执行，通过notify触发调用，handlers处理器才会执行自身所定义的内容

```powershell
---
# Playbook 开头标记（可选）
- name: Playbook描述         # 整个Playbook的描述（可选）
  hosts: target_hosts        # 目标主机或主机组
  vars:                      # 变量定义部分（可选）
    variable1: value
    variable2: value
  tasks:                     # 任务列表
    - name: 任务1描述        # 每个任务的描述
      module_name:           # 使用的模块
        module_parameter: value
    - name: 任务2描述
      module_name:
        module_parameter: value
```

#### 部署zabbix agent的playbook

```powershell
---
- name:   部署 Zabbix Agent
  hosts: all
  become: yes
  vars:
    zabbix_repo_url: "https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-4+ubuntu20.04_all.deb"
    zabbix_server_ip: "192.168.1.100"
    zabbix_hostname: "{{ inventory_hostname }}"

  tasks:
    - name: 下载 Zabbix 仓库包
      get_url:
        url: "{{ zabbix_repo_url }}"
        dest: /tmp/zabbix-release.deb

    - name: 安装 Zabbix 仓库包
      apt:
        deb: /tmp/zabbix-release.deb

    - name: 更新 apt 缓存
      apt:
        update_cache: yes

    - name: 安装 Zabbix Agent
      apt:
        name: zabbix-agent
        state: present

    - name: 配置 Zabbix Agent
      template:
        src: zabbix_agentd.conf.j2
        dest: /etc/zabbix/zabbix_agentd.conf
      notify:
        - 重启 Zabbix Agent

    - name: 确保 Zabbix Agent 服务已启动并设置为开机自启
      service:
        name: zabbix-agent
        state: started
        enabled: yes

  handlers:
    - name: 重启 Zabbix Agent
      service:
        name: zabbix-agent
        state: restarted 


# Zabbix Agent 配置文件
### 基础配置
PidFile=/var/run/zabbix/zabbix_agentd.pid
LogFile=/var/log/zabbix/zabbix_agentd.log
LogFileSize=0

### 服务器连接配置
Server={{ zabbix_server_ip }}
ServerActive={{ zabbix_server_ip }}
Hostname={{ zabbix_hostname }}   
```

## ansible正式跑测试的时候一般加什么参数

`--syntax-check `    检查 Playbook 文件的语法是否正确

**`--check`**   模拟执行 Playbook 中的任务

**`-v` 或 `-vv` 或 `-vvv` 或 `-vvvv`**   用于增加输出的详细程度。`-v` 显示详细信息，`-vv` 显示更详细信息，`-vvv` 显示非常详细信息，`-vvvv` 则是最详细信息，会包含连接信息、模块执行过程等。在调试时，详细输出有助于定位问题

**`--limit`** 限制 Playbook 或命令仅在指定的主机或主机组上执行。当你只想在部分目标主机上测试任务时很有用

`--start-at-task`   从指定名称的任务开始执行，调试特定任务



##  小技巧

- `ansible-playbook -C` 可以 dry-run（预演）Playbook。

- 结合 `tags` 使用，可仅调试部分任务：

- ```
  - name: 调试网络
    debug:
      var: ansible_default_ipv4
    tags: net_debug
  ```

- 然后运行时只执行调试相关任务：

- ```
  ansible-playbook playbook.yml --tags net_debug
  ```

## docker

## dockerfile格式

```powershell
FROM			# 指定基础镜像是谁
LABEL	 		# 添加镜像基础信息，如镜像作者、版本等
RUN				# 用于执行FROM指定镜像所支持的linux命令
ENV 			# 定义环境变量和值
COPY			# 将宿主机文件和目录复制到容器中
ADD				# 增强版的COPY，在COPY原有的基础上还支持自动解压缩
CMD 			# 指定容器启动时默认执行的命令
EXPOSE 			# 指定容器对外暴露的端口号
ENTRYPOINT 		# 类似于CMD，配置容器启动后执行的命令及参数
SHELL			# 设置镜像的shell类型
USER 			# 指定运行容器的用户名或UID，前提是RUN要事先创建出来该用户
ARG 			# 在build 阶段指定变量，和ENV不同的是，ARG仅在构建过程中有效，不能在容器运行时使用，允许写在FROM的前面
VOLUME			# 创建匿名卷，用于实现容器数据的持久化保存
WORKDIR			# 指定容器内默认工作路径
HEALTHCHECK		# 定义容器的健康性检查，检查语句自己定义
ONBUILD			# 指定当该镜像作为基础镜像时执行的指令，这些指令不会在当前构建中执行，而是在基于该镜像构建其他镜像时执行
STOPSIGNAL		# 指定退出容器的系统调用信号
```

## docker与k8s的区别

```
docker名称空间
mnt： 管理文件系统的
ipc： 保证进程间通讯的
uts： 提供内核，主机名和域名隔离
pid： 提供进程隔离，使得每个容器都有自己的独有的进程id
net： 提供网络隔离
user： 提供用户隔离
```

```
- docker中的名称空间不能随意添加删除，因为它是内核里面自带的，不能自定义
- k8s中的名称空间可以根据用户的需要随时创建和删除
- docker的名称空间实现不同容器系统级的资源隔离，而k8s是为了实现不同用户的需要的API资源的隔离，
k8s的名称空间可以用户自行指定，
```

## docker优化

```
在/etc/docker/daemon.json目录下进行编辑

把一个高速磁盘，并且空间足够用的一个单独硬盘来存放docker相关的数据
指定容器日志文件的最大值，比如设置max-size为300m，指定容器日志文件个数，比如设置maxfile为2，这样可以确保硬盘空间不会被打满
开启了本地公司内网的仓库
配置支持远程连接
加上"live-restore为true",确保docker重启时，不会影响容器的运行
对 Cgroups 的使用进行了优化，提供更精细的资源控制
```



## docker制作镜像的优化要点

1、选择合适的基础镜像，精简版的或者官方的（alpine，busybox，ubuntu）；

2、将多个指令尽可能合并，减少镜像层数；

3、将频繁变化的指令放在后面，有效利用缓存，提高镜像制作的速度

（哪个指令变化了，制作镜像时，就会从此指令向后重新执行，指令前面有缓存不需要重新执行）

4、多阶段构建，尽可能缩小镜像大小

5、清理不必要的文件，在安装或构建过程结束后，删除不需要的文件和临时文件。例如，删除下载的软件包缓

存、编译生成的中间文件等。（使用 RUN 指令时，可以添加清理命令）



### entrypoint和CMD的区别？

entrypoint和CMD可以共存，但是如果共存的话，CMD不再成为容器的启动进程，而将成为entrypoint的参数，但是正常不会让cmd当参数，可以让entrypoint和cmd配合执行，entrypoint负责环境初始化，entrypoint后面跟一个脚本，脚本最终执行完以后再通过exec "$@"指令将控制权还给cmd，exec会让原本将作为参数的CMD替换程序本身，继续作为容器的启动进程。

如果两个不共存，CMD和entrypoint的作用效果一样，都将作为容器的启动进程



## Docker 的网络支持5种网络模式:

```powershell
说一说docker如何实现跨宿主机的容器之间的网络通讯？
none,host,brige：三种真正的独立模型
container,自定义网络：这两种并不是真正独立的模式，有依赖关系，是前面三种模式进一步的组合
#bridge:
	此模式是docker的默认网络模式，此模式创建的容器会为每一个容器分配自己的网络 IP 等信息，并将容器连接到一个虚拟网桥与外界通信，可以和外部网络之间进行通信，通过SNAT访问外网，Docker在宿主机上创建一个名为docker0的虚拟网桥（Linux Bridge）。当一个容器以桥接模式启动时，Docker会为该容器分配一个虚拟网卡，并将其连接到这个网桥上。容器之间以及容器与宿主机之间的通信就像它们在同一个局域网中一样。每个容器都会获得一个独立的IP地址，并且可以通过iptables规则实现端口映射，使得外部能够访问容器内的服务。
	#这是docker的默认网络模式，它会为每个创建的容器分配自己的网络IP等信息，并会将其连接到一个名为docker0的虚拟网桥上，通过这个虚拟网桥可以实现容器和网络之间的相互通信
#host：
	新创建的容器不会创建自己的虚拟网卡，而是直接使用宿主机的网卡和IP地址，因此在容器里面查看到的IP信息就是宿主机的信息，访问容器的时候直接使用宿主机IP+容器端口即可，不过容器内的其他资源仍和宿主机保持隔离，此模式网络性能最好，但是容器端口容易起冲突
#None：
	在使用 none 模式后，只能看到一个lo的本地回环网卡，Docker容器不会进行任何网络配置，没有网卡、没有IP也没有路由，因此默认无法与外界通信，需要手动添加网卡配置IP等，所以极少使用
#container：
	新创建的容器不会创建自己的网卡也不会配置自己的IP，而是和一个被指定的已经存在的容器共享IP和端口范围，已经存在的容器的网络可能是bridge，或none，或者host，而第二个容器模式依赖于第一个容器，它们共享网络，如果已经存在的容器停止，则无法创建后面的container模式的容器
#自定义网络：
	新建容器可以使用自定义的网段地址，网关等信息，可以使用自定义网络模式,实现不同集群应用的独立网络管理,而互不影响,而且在同一个自定义网络内,可以直接利用容器名相互访问，非常便利
	#使用自定义网络模式,实现不同集群应用的独立网络管理,而互不影响,而且在同一个自定义网络内,可以直接利用容器名相互访问，非常便利
```



# minio

## mc mirror 备份

### **什么是 `mc mirror` ？**

> `mc` 是 MinIO 提供的官方命令行工具（MinIO Client），用来管理对象存储中的 bucket 和文件。
>  其中 **`mc mirror`** 命令用于**实时/定时双向同步或单向备份 bucket 数据**，相当于「S3 级别的 rsync 工具」。

------

### **生产环境 `mc mirror` 典型用途**

> 用于把生产 MinIO 集群的数据定期同步到**异地备份服务器 / 冷备份 MinIO 集群 / 远端对象存储**
>  保障业务数据多副本、降低数据丢失风险

**典型场景：**

| 生产场景                                | 方案                   |
| --------------------------------------- | ---------------------- |
| 本地 MinIO -> 异地 MinIO                | Disaster Recovery 备份 |
| 本地 MinIO -> 本地硬盘目录              | 数据归档冷备           |
| 本地 MinIO -> 其他 S3 存储（如 AWS S3） | 云端冷备               |



------

### **基本语法**

```
mc alias set prod http://10.0.0.11:9000 minioadmin minioadmin
mc alias set backup http://10.0.0.22:9000 minioadmin minioadmin

mc mirror prod/bucket1 backup/bucket1
```

> 这条命令会把 `prod` MinIO 里的 `bucket1` 全量同步到 `backup` MinIO 里的 `bucket1`
>  支持增量同步、断点续传、版本控制

------

### **常用参数**

| 参数                       | 作用                             |
| -------------------------- | -------------------------------- |
| `--overwrite`              | 已存在目标文件强制覆盖           |
| `--remove`                 | 删除源端删除的文件（保持一致性） |
| `--watch`                  | 实时同步，源端有变化立刻同步     |
| `--preserve`               | 保留对象元数据                   |
| `--schedule "*/5 * * * *"` | 每 5 分钟定时同步                |



------

### **你简历里的项目怎么答？**

> 在 MinIO 集群项目中，我们结合 `mc mirror` 实现了多副本异地备份：
>
> - **场景**：本地 4 节点 MinIO 集群 → 备份 MinIO 服务器
> - **命令**：

```
mc mirror --overwrite --remove --schedule "0 * * * *" prod/logs backup/logs
```

> - 每小时同步一次日志 bucket 数据，保障主集群与备份集群数据一致
> - 结合 Prometheus 监控磁盘空间 + 备份状态，异常时告警
> - 测试过节点宕机 / 磁盘损坏场景，验证了备份数据可用性

------

### **面试答法（直接背）**

> 我们生产中通过 `mc mirror` 实现 MinIO bucket 数据定时/实时备份，保障业务数据多副本安全。
>  结合 `--schedule` 实现自动化，`--remove` 保持一致性，Prometheus 监控备份状态，确保备份有效性和恢复能力。

------

### **如果面试官追问「恢复怎么做？」**

你可以接着答：

> 出现主集群数据丢失时，我们通过 `mc mirror backup/logs prod/logs` 反向同步快速恢复数据
>  也可以直接通过 `mc cp`、`mc restore` 恢复单个 bucket 或对象，满足不同恢复需求。



## minio高可用构架

生产环境中的 **MinIO 高可用分布式架构** 应具备以下关键特性：**多节点部署、纠删码容错、负载均衡访问、持久化存储、监控告警、安全加固（TLS、用户权限）**。下面是一个典型的企业级部署架构设计，适用于物理机、虚拟机、容器平台（如 Docker）、以及 Kubernetes（建议使用 MinIO Operator）。

------

### ✅ 一、生产级 MinIO 高可用部署目标

| 目标     | 要求                                 |
| -------- | ------------------------------------ |
| 高可用性 | 任意一个或多个节点宕机仍可访问数据   |
| 容灾能力 | 数据采用纠删码冗余存储，避免单点丢失 |
| 横向扩展 | 支持后期无缝扩容节点和磁盘           |
| 负载均衡 | 对客户端提供统一入口，均衡流量       |
| 安全保障 | 数据传输加密、认证授权               |
| 易于运维 | 提供监控、告警、生命周期管理         |

------

### 🧱 二、MinIO 高可用架构图（生产版）

```
                     +--------------------+
                     |   Clients / Apps   |
                     +--------+-----------+
                              |
                     +--------v--------+
                     |  Load Balancer  |   <—— HAProxy / Nginx / LVS / K8s Ingress
                     +--------+--------+
                              |
    -------------------------------------------------
    |              |              |              |
+---v---+      +---v---+      +---v---+      +---v---+
| MinIO |      | MinIO |      | MinIO |      | MinIO |  <—— 至少 4 个节点
|Node 1|      |Node 2|      |Node 3|      |Node 4|
|/data1|...   |/data2|...   |/data3|...   |/data4|...
+-------+     +-------+     +-------+     +-------+
    |              |              |              |
    ------------>  Shared Cluster Metadata  <---------
```

------

### 📌 三、关键参数设计

| 参数       | 建议配置                                             |
| ---------- | ---------------------------------------------------- |
| 节点数     | ≥ 4 个节点，推荐偶数，如 4、6、8                     |
| 每节点盘数 | ≥ 2 块盘，支持横向扩展                               |
| 纠删码     | 默认 EC(4+2)：4 数据 + 2 冗余，容忍任意 2 个盘损坏   |
| LB 实现    | 推荐 HAProxy + Keepalived 或 Nginx，K8s 用 Ingress   |
| 网络要求   | 所有节点内网互通，稳定、低延迟                       |
| 存储目录   | 每块盘挂载到独立 `/dataX` 目录，避免 RAID 使用纠删码 |

------

### 🚀 四、生产部署命令（裸机示例）

假设 4 台服务器，分别为 `minio1~minio4`，每台服务器挂载 2 块盘（/data1、/data2）：

```
minio server http://minio{1...4}/data{1...2} --console-address ":9001"
```

- 该命令会自动将 8 块盘组成一个分布式集群，启用纠删码。
- 每个节点运行命令相同，但机器 IP/主机名不同。

> **建议使用 systemd 创建服务文件，设置为开机自启动，并启用 TLS 证书。**

------

### 🐳 五、生产部署（Kubernetes + MinIO Operator 推荐）

1. **安装 Operator**

```
kubectl apply -k "github.com/minio/operator?ref=v5"
```

1. **访问控制台**

```
kubectl port-forward svc/console -n minio-operator 9090:9090
```

1. **创建 Tenant（最小配置示例）**

- 节点数：4
- 每节点卷数：2
- 总容量：根据 PVC 设置
- 自动生成 Service / TLS / Secret / Console

1. **访问服务地址**

```
https://minio.minio-tenant.svc.cluster.local
```

------

### 🔐 六、安全与持久化设计

#### TLS 加密

- 生产必须开启 TLS，使用 Let's Encrypt 或公司内部 CA。

- 启动时配置：

  ```
  --certs-dir /etc/minio/certs
  ```

#### 用户认证

- 限制 Root 用户访问
- 使用 S3 策略实现最小权限控制（readonly、readwrite、admin）

#### 数据持久化（Docker/K8s）

- **裸机**：将数据目录挂载到独立磁盘
- **K8s**：使用 StatefulSet + PVC 保证数据不丢失

------

### 📊 七、运维与监控

| 工具                     | 用途                   |
| ------------------------ | ---------------------- |
| `mc admin info`          | 查看集群节点状态       |
| `mc admin heal`          | 手动修复节点或磁盘故障 |
| `Prometheus` + `Grafana` | MinIO 原生支持导出指标 |
| `mc admin trace`         | 查看实时请求追踪日志   |

------

### ✅ 八、优点总结

- 🚀 启动快：二进制运行即用
- ⚙️ 轻量：资源占用小
- 🧠 强一致：保证数据写后读一致
- 🧩 可扩展：按节点/磁盘扩容
- 💥 容灾强：纠删码应对节点/磁盘故障

------

### 📎 示例：使用 HAProxy 实现 LB

```
frontend minio
  bind *:9000
  default_backend minio_servers

backend minio_servers
  balance roundrobin
  server minio1 10.0.0.1:9000 check
  server minio2 10.0.0.2:9000 check
  server minio3 10.0.0.3:9000 check
  server minio4 10.0.0.4:9000 check
```





# ELK

## **K8s 中 Filebeat 监控 Pod 日志**

> 在 Kubernetes 集群中，**Filebeat 主要用于采集 Pod 产生的容器日志**，并发送到 Elasticsearch、Logstash 等日志平台，实现集中化日志分析与可视化。

------

### 1️⃣ **K8s 中 Pod 日志存储路径**

> Pod 容器日志，K8s 默认保存在每个 Node 节点的以下目录：

```
/var/log/pods/<namespace>_<podname>_<podUID>/
/var/log/containers/<containername>_<namespace>_<podname>-<containerID>.log
```

> 其实最终是 **container runtime（containerd/docker）** 把日志写到 `/var/log/containers/*.log`（JSON 格式）

------

### 2️⃣ **Filebeat 采集 Pod 日志原理**

> Filebeat 以 **DaemonSet** 部署在每个节点，自动发现并采集对应 Node 上的 Pod 容器日志
>  原理图：
>  Pod (stdout/stderr) → container runtime → /var/log/containers/*.log → **Filebeat DaemonSet** → Elasticsearch/Logstash

------

### 3️⃣ **Filebeat 采集 Pod 日志步骤**

#### ① **部署 Filebeat DaemonSet**

```
kubectl apply -f filebeat-kubernetes.yaml
```

> DaemonSet 确保每个 Node 上都部署一个 Filebeat 实例，采集本节点日志

------

#### ② **配置 Filebeat inputs（日志采集源）**

```
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  exclude_files: ['.gz$']
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'   # 处理多行日志，比如 Java 堆栈
  multiline.negate: true
  multiline.match: after
```

------

#### ③ **配置 Filebeat autodiscover（自动发现 Pod 元数据）**

> 通过 K8s API 自动发现 Pod 变更，并提取 metadata（namespace、podname、container name 等），方便日志分类

```
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      hints.enabled: true
```

------

#### ④ **配置日志输出（Elasticsearch / Logstash）**

```
output.elasticsearch:
  hosts: ["http://elasticsearch:9200"]
```

或

```
output.logstash:
  hosts: ["logstash:5044"]
```

------

### 4️⃣ **你项目中的标准答法（结合你的 ELK 项目）**

> 在我们 Prometheus + ELK 监控项目中，我们通过 **Filebeat DaemonSet** 实现 Pod 日志采集：
>
> - Filebeat 采集 `/var/log/containers/*.log`
> - 结合 **autodiscover** 自动打标签（namespace/pod/container）
> - 日志发送到 **Logstash**，实现分类解析和结构化处理
> - Logstash 转发到 **Elasticsearch**，最后通过 **Kibana** 可视化查询
> - 配置 **日志告警**，比如关键错误关键词触发 Prometheus 告警

------

### 5️⃣ **一句话总结（面试必背）**

> 我们生产中通过 Filebeat DaemonSet 自动发现并采集 Pod 容器日志，结合 Kubernetes metadata 打标签，发送到 ELK 平台，实现日志集中采集、检索与告警。

------

### 6️⃣ **加分项（面试官继续追问时）**

> - **如何过滤不同应用日志？**
>    → 我们通过 Filebeat **autodiscover + annotation hints** 实现按 namespace/app 维度打标签、分索引
> - **如何防止日志丢失？**
>    → Filebeat 有 **registry offset 机制**，断点续传；同时配置 **bulk output + backpressure control** 防止过载
> - **如何处理大日志量 / 热点 Node？**
>    → 配置 Filebeat **multiline** 处理堆栈日志，优化 pipeline worker 数，Logstash 配置多个 pipeline 分流

------

### **实战 YAML 模板（送你面试备用）**

```
annotations:
  co.elastic.logs/enabled: "true"
  co.elastic.logs/module: nginx
  co.elastic.logs/fileset.stdout: access
  co.elastic.logs/fileset.stderr: error
```

------

### **如果需要，我可以帮你准备：**

✅ Filebeat DaemonSet 完整部署 YAML
 ✅ Filebeat + Logstash 多索引分流配置
 ✅ Filebeat + Prometheus Exporter 监控 Filebeat 状态



## 生产中的es故障及解决方法


 ✅ **典型生产故障清单**
 ✅ **标准排查与处理方法**
 ✅ **面试标准答题模板**
 ✅ **企业加分项 (进阶)**

------

### 🛠️ **1️⃣ 生产中常见 ES 故障类型**

| 故障类别           | 具体表现                               |
| ------------------ | -------------------------------------- |
| 集群不可用         | Yellow / Red 状态，节点掉线            |
| 分片异常           | Unassigned / 分片丢失 / 分片初始化失败 |
| 查询性能问题       | 慢查询 / 响应超时 / 超高 CPU           |
| 索引写入失败       | Read-only / 磁盘满 / Mapping冲突       |
| 内存问题           | OOM / JVM GC频繁 / 节点崩溃            |
| 堆积数据导致磁盘满 | 写入过多 / 未清理旧索引                |
| 节点间网络分裂     | Split-brain / Master节点频繁选举       |
| 安全问题           | 认证失败 / 证书过期 / 跨权限访问风险   |



------

### 🔍 **2️⃣ 标准排查 + 处理流程 (企业版)**

#### 🚨 ① 集群状态 Yellow / Red

```
GET _cluster/health
```

**排查方向**

- 分片分配失败？
- 节点掉线？(GET _cat/nodes?v)

**处理方法**

- 重新分配分片

```
POST _cluster/reroute?retry_failed
```

- 修复节点 (重启 / 网络恢复)

#### 🚨 ② 分片 Unassigned / 分片丢失

```
GET _cat/shards?v
```

**原因**

- 节点宕机导致分片丢失
- 分片损坏 (corrupt)
- Mapping冲突

**处理**

- 迁移分片

```
PUT _cluster/settings
{
 "transient": {
   "cluster.routing.allocation.enable": "all"
 }
}
```

- 强制分配 (忽略校验)

```
POST _cluster/reroute
{
 "commands": [
   {
     "allocate_stale_primary": {
       "index": "index_name",
       "shard": 0,
       "node": "node_name",
       "accept_data_loss": true
     }
   }
 ]
}
```

#### 🚨 ③ 磁盘满 + 索引变只读 (read-only)

```
GET _cluster/allocation/explain
```

**处理**

- 清理旧索引

```
DELETE index-2024-01
```

- 取消只读

```
PUT _all/_settings
{
 "index.blocks.read_only_allow_delete": null
}
```

- 扩容磁盘

#### 🚨 ④ JVM 内存 / GC 频繁

```
GET _nodes/stats/jvm
```

**处理**

- 增大堆内存 (JVM options)
- 降低 fielddata / cache 占用

```
PUT index/_settings
{
 "indices.fielddata.cache.size": "10%"
}
```

- 优化查询 (减少 aggregations)

#### 🚨 ⑤ 查询慢 / CPU高

```
GET _nodes/hot_threads
```

**排查**

- 慢查询日志

```
PUT _cluster/settings
{
 "transient": {
   "search.slowlog.threshold.query.warn": "5s"
 }
}
```

**处理**

- 增加分页 scroll / search_after
- 增加 replica 扩展读能力
- 归档冷数据

#### 🚨 ⑥ Master 节点频繁切换

```
GET _cat/master
```

**原因**

- Master 资源不足
- 网络分裂

**处理**

- 增加稳定的 Master 节点 (3个或5个 odd-number)
- 配置 minimum_master_nodes

```
discovery.zen.minimum_master_nodes: (N/2)+1
```

------

### 📋 **3️⃣ 面试标准答题模板 (直接背)**

> 生产中ES常见故障包括：集群Yellow/Red状态、分片丢失/未分配、索引只读、磁盘满、JVM内存异常和Master频繁切换
>  我会通过_cluster/health 和 _cat/nodes/_cat/shards 快速定位故障范围
>  典型处理方法如reroute重分配分片、清理旧索引释放磁盘、调优JVM heap和查询DSL、修复Master选举配置
>  生产经验中我遇到过磁盘满导致集群read-only，及时清理数据和扩容磁盘，恢复集群可写性
>  我平时也结合Prometheus监控ES指标，预防性发现集群风险

------

### ✅ **4️⃣ 企业加分项 (进阶)**

✅ **分片自动分配策略优化**

```
"cluster.routing.allocation.awareness.attributes": "rack"
```

✅ **ILM (Index Lifecycle Management)**
 自动清理和归档冷数据

✅ **跨集群复制 (CCR)**
 灾备容灾方案

✅ **Prometheus + ElasticSearch Exporter + Grafana**
 可视化监控磁盘 / 内存 / 查询耗时

✅ **快照备份 (Snapshot)**

```
PUT _snapshot/my_backup
```

✅ **安全强化**
 ElasticSearch X-Pack + HTTPS + 认证授权



## 🛠️ **Elasticsearch 磁盘满导致集群只读 — 生产事故处理案例**

### 📅 **背景**

- 项目环境：**8节点 Elasticsearch 7.17 集群 (3 Master + 3 Data + 2 Client)**
- 存储类型：**本地 SSD**
- 数据规模：**2TB 日志索引**，每天写入量 100GB
- 版本管理：**ILM (Index Lifecycle Management)** 自动滚动索引

### ⚠️ **事故发生**

- 事故时间：2024年3月15日凌晨3点
- 现象：应用日志写入报错 `403 index read-only / allow delete (api)`
- ES 状态：集群 Yellow，部分分片未分配
- 监控报警：磁盘利用率 > 95%

### 🔍 **排查过程**

| 排查步骤        | 工具/命令               | 结果                                                 |
| --------------- | ----------------------- | ---------------------------------------------------- |
| 1. 查看集群健康 | `GET _cluster/health`   | Yellow                                               |
| 2. 查看分片状态 | `GET _cat/shards?v`     | 多个分片 unassigned                                  |
| 3. 查看磁盘使用 | `GET _cat/allocation?v` | 3个Data节点磁盘利用率 95%+                           |
| 4. 查看索引状态 | `GET _all/_settings`    | 多个索引 `index.blocks.read_only_allow_delete: true` |



#### **结论：磁盘阈值触发了 ES 自动只读保护机制**

Elasticsearch 默认配置：

```
cluster.routing.allocation.disk.watermark.high = 90%
cluster.routing.allocation.disk.watermark.flood_stage = 95%  # 触发 index read-only
```

### 🛠️ **处理过程**

| 步骤 | 操作                        | 目的                                                         |
| ---- | --------------------------- | ------------------------------------------------------------ |
| 1    | 暂停应用写入 (下游应用限流) | 防止继续写爆磁盘                                             |
| 2    | 删除过期旧索引              | `DELETE log-2024-01*`                                        |
| 3    | 手动关闭索引只读            | `PUT _all/_settings { "index.blocks.read_only_allow_delete": false }` |
| 4    | 检查磁盘空间                | `GET _cat/allocation?v`                                      |
| 5    | 强制分片重新分配            | `POST _cluster/reroute?retry_failed`                         |
| 6    | 恢复应用写入                | 取消限流                                                     |
| 7    | 后续清理                    | 优化 ILM 策略，缩短热数据保留周期                            |



### ✅ **最终结果**

- 事故处理总耗时：1小时45分钟
- 集群恢复 Green 状态
- 无数据丢失，应用恢复正常写入

### 🧩 **事后总结与改进**

| 问题                     | 改进措施                               |
| ------------------------ | -------------------------------------- |
| ILM 策略保留时间过长     | 缩短热数据保留，从60天改为30天         |
| 监控磁盘报警阈值偏高     | Prometheus+Alertmanager 调低阈值 (80%) |
| 集群扩容滞后             | 增加1台Data节点，提升存储容量30%       |
| 只读恢复操作流程未标准化 | 编写《ES磁盘满应急预案》SOP文档        |



------

### 📋 **面试标准答题模板 (直接背)**

> 我在生产环境中曾遇到过一次典型的ES磁盘满导致集群只读的事故
>  事故原因是磁盘利用率超过95%，触发Elasticsearch的flood_stage watermark机制，自动把索引设置为只读
>  当时我通过 GET _cat/allocation 和 GET _all/_settings 快速定位问题，并通过删除过期索引释放空间、关闭只读属性和重新分配分片恢复集群正常
>  事后我优化了ILM策略、扩容了存储节点，并制定了磁盘告警和只读恢复SOP
>  通过这次实战，我具备了ES集群故障快速定位、处理和预防的能力

------

### 💡 **加分讲法 (如果面试官点头，可补充)**

> 我还结合 Prometheus + ElasticSearch Exporter 实现了磁盘指标可视化，并提前预警，后续集群运行更平稳

 





# kafka

## kafka磁盘满了怎么处理



 ✅ **现象与风险**
 ✅ **生产标准排查流程**
 ✅ **短期应急处理**
 ✅ **根本性优化 (防止再发生)**
 ✅ **面试标准答题法**

------

### 🛠️ **1️⃣ 现象与风险**

| 现象                          | 影响                                               |
| ----------------------------- | -------------------------------------------------- |
| Kafka Broker 节点磁盘 100% 满 | Broker 停止接受生产和消费请求 (报错 Disk Full)     |
| Kafka 生产者 Producer 报错    | `No space left on device` / `LEADER_NOT_AVAILABLE` |
| 分区副本失效 (ISR 不一致)     | 消费延迟 / 数据丢失风险                            |
| Controller频繁选举            | 集群不稳定                                         |
| ZooKeeper 连接异常            | 影响集群元数据管理                                 |



⚠️ **风险：集群不可用 + 数据积压 + 生产消费阻塞**

------

### 🕵️ **2️⃣ 生产标准排查流程**

✅ **1. 确认哪个 Broker 磁盘满**

```
bash复制编辑df -h
du -sh /data/kafka-logs/*
```

✅ **2. Kafka 集群状态**

```
bash复制编辑kafka-topics.sh --describe --bootstrap-server broker:9092
kafka-consumer-groups.sh --describe ...
```

✅ **3. Kafka 日志排查**

```
tail -f /data/kafka-logs/server.log
```

- 看磁盘报错 / ISR 警告 / Controller 变更
- Producer 报 `UNKNOWN_TOPIC_OR_PARTITION`、`LEADER_NOT_AVAILABLE`

✅ **4. 影响面**

- 仅单个 Broker ？还是多个节点？
- 仅生产受影响 ？还是消费也阻塞？

------

### 🚨 **3️⃣ 短期应急处理 (恢复可用性)**

| 方案                  | 操作                                        |
| --------------------- | ------------------------------------------- |
| 清理旧 topic 数据     | 删除过期不需要的 topic                      |
| 手动清理过期 segment  | **风险低**，Kafka 自动 log cleanup 比较温和 |
| 临时扩容磁盘          | 增挂硬盘 / 扩容云盘 (最快恢复)              |
| 迁移数据到其他 Broker | 增加 broker 数量，做 partition reassignment |
| 调高删除阈值          | 减小 log retention 时间/大小 (快速清理数据) |



✅ **快速删 topic**

```
kafka-topics.sh --bootstrap-server broker:9092 --delete --topic old_topic
```

✅ **调低保留时间** (删除旧数据)

```
kafka-configs.sh --bootstrap-server broker:9092 \
--entity-type topics --entity-name your_topic \
--alter --add-config retention.ms=3600000  # 1小时
```

✅ **Broker级别清理策略 (server.properties)**

```
log.retention.hours=24
log.retention.bytes=10737418240  # 10G
log.segment.bytes=1073741824     # 1G
```

✅ **挂盘扩容 (云主机)**
 阿里云 / 腾讯云：在线扩容云盘 + ext4/xfs resizefs

------

### 🔄 **4️⃣ 根本性优化 (避免复发)**

✅ **1. 设置合理数据保留策略**

- 按时间 (retention.ms)
- 按大小 (retention.bytes)

✅ **2. 监控磁盘空间**

- Prometheus + JMX Exporter 监控 Kafka 磁盘占用
- 设置 80%告警，90%预警，95%强制处理

✅ **3. topic 分区合理规划**

- 高频 topic 多 partition + 多 broker 分散压力

✅ **4. Kafka 日志目录多磁盘分布**

```
log.dirs=/data1/kafka-logs,/data2/kafka-logs
```

✅ **5. 数据分层 (冷热数据)**

- 重要数据保留久，普通日志类数据短保留

✅ **6. 定期巡检**

- 自动脚本每日巡检磁盘空间，Kafka topic 分布

------

### 📋 **5️⃣ 面试标准答题模板 (直接背)**

> Kafka Broker磁盘满，我处理思路是
>  ① 先确认磁盘使用情况和影响面 (df / du / kafka-topics.sh)
>  ② 临时应急方案包括清理不必要 topic，调低保留时间快速删除 segment，或临时扩容磁盘
>  ③ 为根本优化，我会合理设置 log.retention 策略，启用 Prometheus 监控磁盘空间并配置告警，防止磁盘再次满
>  ④ 生产中我也遇到过磁盘爆满导致 ISR 不一致，通过调低 retention + 扩容云盘恢复集群可用性

------

### ✅ **总结表**

| 阶段     | 操作                                | 工具                           |
| -------- | ----------------------------------- | ------------------------------ |
| 确认问题 | df / du / kafka-topics / 日志       | shell / kafka-cli              |
| 应急处理 | 清理数据 / 降 retention / 扩容磁盘  | kafka-config / 云盘扩容        |
| 预防优化 | retention合理 / 监控告警 / 多盘分布 | Prometheus / server.properties |



## zookeeper构架及原理

ZooKeeper 是一个 **分布式协调服务**，在大数据、微服务、高可用系统中常用于配置管理、命名服务、集群管理、选主和分布式锁等功能。

下面是 ZooKeeper 的架构及原理详解，适合运维人员、SRE、DevOps 或云平台从业者系统掌握。

------

### 一、ZooKeeper 架构组成（整体结构）

ZooKeeper 的典型集群结构如下图（逻辑）：

```
pgsql复制编辑         +-------------+
         |   Client A  |
         +-------------+
               |
         +-------------+
         |   Client B  |
         +-------------+
               |
       +-------+--------+
       |                |
+-------------+  +-------------+  +-------------+
| Follower-1  |  | Leader      |  | Follower-2  |
| (Server B)  |  | (Server A)  |  | (Server C)  |
+-------------+  +-------------+  +-------------+
         \         |        /
          \        |       /
           +-------+-------+
               ZAB 协议
```

------

### 二、核心组件解释

#### 1. Server 角色

ZooKeeper 集群由若干个服务器组成（必须是奇数个），每个 Server 的角色分为：

| 角色             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| Leader           | 负责事务请求处理、写请求协调（如写数据、创建节点）和集群协调 |
| Follower         | 处理客户端读请求，参与投票                                   |
| Observer（可选） | 不参与投票，只提供读服务，提高读性能                         |



------

#### 2. 客户端（Client）

ZooKeeper 客户端可以连接任意一台 ZooKeeper 服务器，自动感知 Leader 状态切换，并通过 **Watch机制** 实现事件通知。

------

### 三、数据模型（类似文件系统）

ZooKeeper 的数据结构是一个 **树状结构**，每个节点称为一个 **znode**。

```
/
├── app
│   ├── config
│   ├── service1
│   └── lock
├── zk
│   └── quota
```

每个 znode：

- 可以保存少量数据（不超过 1MB）
- 可以设置 Watch
- 可以是临时节点（session结束即消失）
- 支持顺序节点（ZK 自动添加编号）

------

### 四、工作原理（ZAB 协议）

ZooKeeper 采用自主设计的分布式一致性协议：**ZAB（ZooKeeper Atomic Broadcast）**，类似 Paxos/Raft。

#### ZAB 主要流程：

##### 1. **选举 Leader（Leader Election）**

- 集群启动时自动进行投票选举（半数以上同意才能选出 Leader）
- 使用服务器 ID 判断优先级（myid 文件）

##### 2. **同步数据（Synchronization）**

- 所有 Follower 从 Leader 同步最新的数据状态
- 确保所有节点视图一致后，Leader 才对外提供服务

##### 3. **广播事务（Atomic Broadcast）**

- 所有写操作必须经过 Leader
- Leader 广播 Proposal 给 Follower
- 半数以上 ACK 后提交（Commit）

##### 4. **Follower/Client 响应**

- 写操作由 Leader 分发到所有 Follower
- 读操作可以直接由 Follower 处理（非强一致）

------

### 五、数据一致性模型

ZooKeeper 保证的分布式一致性特性（CAP 中倾向于 CP）：

| 特性               | 含义                                       |
| ------------------ | ------------------------------------------ |
| 顺序一致性         | 客户端看到的更新顺序与发送顺序一致         |
| 原子性             | 要么成功，要么失败，不存在中间状态         |
| 单一系统镜像       | 所有客户端看到数据一致                     |
| 实时性（最终一致） | 更新最终对所有客户端可见（但不是实时传播） |



------

### 六、常见使用场景

| 场景                    | 说明                                    |
| ----------------------- | --------------------------------------- |
| 配置中心                | 保存动态配置，并支持 Watch 机制自动变更 |
| 服务注册与发现          | 注册服务信息，客户端从 ZK 获取地址      |
| 选主（Leader Election） | 保证分布式系统中只有一个主节点          |
| 分布式锁                | 通过顺序临时节点实现互斥                |
| 分布式队列              | 使用 znode 排列队列任务                 |



------

### 七、ZooKeeper 数据写入流程（关键原理）

```
客户端写请求
       ↓
连接到 Follower → 转发给 Leader
       ↓
  Leader 创建 Proposal（提议）
       ↓
广播 Proposal → 所有 Follower
       ↓
半数 Follower 返回 ACK
       ↓
Leader 发出 Commit
       ↓
所有节点应用事务 → 返回客户端成功
```

------

### 八、ZooKeeper 部署建议

- 建议部署奇数台（如 3、5、7 台）
- 数据目录分开配置（dataDir、dataLogDir）
- 配置 `tickTime`（心跳）、`initLimit`、`syncLimit`
- 使用 `myid` 唯一标识服务器编号
- 开启 `autopurge.snapRetainCount` 清理快照/事务日志
- 保证低网络延迟，避免脑裂

------

### 九、ZooKeeper 与 ETCD、Consul 对比

| 特性      | ZooKeeper    | etcd              | Consul            |
| --------- | ------------ | ----------------- | ----------------- |
| 协议      | ZAB          | Raft              | Raft              |
| 适合      | 高吞吐写请求 | 配置中心/服务发现 | 服务发现/健康检查 |
| Watch机制 | 支持，可靠   | 支持              | 支持              |
| 易用性    | 配置略复杂   | 简单              | 简单              |
| 存储模型  | 文件系统树   | KV                | KV                |



## nacos

> **Nacos = 服务注册与发现 + 动态配置管理 + 服务健康检查**

------

### ✅ Nacos 主要功能详解：

#### 1️⃣ 服务注册与发现（Service Registry & Discovery）

- 类似于 Dubbo、Spring Cloud 的注册中心
- 支持注册 **HTTP、gRPC、Dubbo 等服务**
- 支持临时实例与永久实例
- 服务消费者通过 Nacos 获取服务提供者的 IP/端口等信息

📌 类似于：

```
text复制编辑服务提供者：注册自己
服务消费者：通过 Nacos 获取服务地址
```

------

#### 2️⃣ 动态配置中心（Config Management）

- 类似于 Spring Cloud Config
- 支持配置热更新，无需重启服务
- 支持配置分组、命名空间（Namespace）
- 可使用控制台、API、或文件同步配置

📌 用来集中管理 `.properties` / `.yaml` 等应用配置文件。

------

#### 3️⃣ 服务健康检查

- 自动检测注册服务是否健康
- 支持 TCP 检查 / HTTP 检查 / 心跳方式
- 异常服务实例自动剔除，恢复时自动注册

------

### 🧩 Nacos 适合用在哪些场景？

| 场景               | 说明                        |
| ------------------ | --------------------------- |
| 微服务注册与发现   | 支持 Spring Cloud、Dubbo 等 |
| 动态配置管理       | 应用配置统一集中管理        |
| 多环境配置隔离     | 使用命名空间或分组          |
| 服务健康监控与治理 | 提高系统可用性              |



------

### 🛠️ 技术架构示意图：

```
text复制编辑                ┌─────────────┐
                │  服务提供者 │
                └─────┬───────┘
                      │ 注册服务
                      ▼
                 ┌─────────┐
                 │  Nacos  │ ←—————— 配置推送
                 └─────────┘
                      ▲
                      │  获取服务地址 / 配置
                ┌─────┴───────┐
                │  服务消费者 │
                └─────────────┘
```

------

### 🚀 Nacos 支持哪些生态？

- **Spring Cloud Alibaba**
- Dubbo / gRPC
- Kubernetes（可以和 K8s 集成使用）
- 支持 REST API 直接访问

------

### 📦 Nacos 的运行模式

| 模式       | 用途                       |
| ---------- | -------------------------- |
| 单机模式   | 开发测试使用               |
| 集群模式   | 生产环境推荐使用（高可用） |
| 支持 MySQL | 存储配置数据，持久化       |



------

### 👨‍💻 示例命令

**注册服务：**

```
curl -X POST 'http://localhost:8848/nacos/v1/ns/instance?serviceName=test-service&ip=10.0.0.1&port=8080'
```

**获取服务：**

```
curl -X GET 'http://localhost:8848/nacos/v1/ns/instance/list?serviceName=test-service'
```

------

如你希望我提供：

- 本地部署 Nacos 教程
- Nacos 与 Spring Boot 配合使用示例
- 与 Kubernetes/微服务架构整合方案



# 日常运维

## 体系化运维

“体系化运维工作”这个概念，其实就是指：**有标准、有流程、有工具、有体系地开展 IT 运维工作**，不只是“临时救火”或者“凭经验解决问题”。
 我来给你系统地梳理一下体系化运维的主要内容和框架，让你一看就清楚：

------

#### 1. **运维目标与原则**

- **目标**
  - 保证系统稳定性、高可用性
  - 降低故障率与恢复时间 (MTTR)
  - 提升运维效率，降低人工干预
  - 支撑业务持续交付与快速迭代
- **原则**
  - 自动化优先
  - 标准化配置
  - 可观测性强
  - 安全合规性保障

------

#### 2. **体系化运维五大核心模块**

| 模块                      | 主要内容                                         | 典型工具/实践                            |
| ------------------------- | ------------------------------------------------ | ---------------------------------------- |
| **1. 资产管理**           | 管理硬件设备、虚拟机、容器、云资源等资产台账     | CMDB (配置管理数据库)、Ansible Inventory |
| **2. 配置管理**           | 保证环境一致性、配置标准化、批量管理             | Ansible、SaltStack、Terraform (IaC)      |
| **3. 持续交付与变更管理** | 自动化部署、CI/CD流水线、变更审批与回滚          | GitLab CI/CD、ArgoCD、Jenkins            |
| **4. 监控与告警**         | 采集与分析性能指标、日志、链路追踪，快速发现异常 | Prometheus、Grafana、ELK、SkyWalking     |
| **5. 安全与合规管理**     | 账户权限管理、漏洞扫描、审计日志                 | Keycloak、堡垒机、OSSEC、Wazuh           |



------

#### 3. **体系化运维工作方法论**

- **ITIL (IT Infrastructure Library)**
   运维服务管理最佳实践 (事件管理、问题管理、变更管理等)
- **SRE (Site Reliability Engineering)**
   Google 推崇的运维工程方法论，强调自动化、可观测性与服务等级目标 (SLO/SLI/SLA)
- **DevOps**
   运维与开发紧密协作，追求持续交付与快速反馈

------

#### 4. **关键能力建设**

| 能力                 | 具体体现                         |
| -------------------- | -------------------------------- |
| **自动化能力**       | 批量部署、自动化巡检、自动化修复 |
| **可观测性能力**     | 统一监控、日志分析、链路追踪     |
| **容灾与高可用能力** | 负载均衡、主备切换、多活架构     |
| **安全与审计能力**   | 权限最小化、操作审计、数据加密   |
| **文档与标准化能力** | SOP 文档、运维手册、变更记录     |



------

#### 5. **典型体系化运维架构图 (例子)**

如果你需要，我可以画一张“云计算环境下的体系化运维架构图”，帮你更直观理解。

------

总结一句话：

> **体系化运维 = 技术工具 (自动化) + 流程制度 (标准化) + 团队协作 (规范化)**



## 巡检

很好，这个问题很关键。**“巡检”\**其实就是\**定期、有计划地检查系统运行状态，提前发现隐患，避免故障扩大化**。
 真正体系化的巡检工作，**绝对不是人工 SSH 登进去敲命令看一遍就完事**，而是要做到：
 **自动化、标准化、可记录、可追溯**。
 我来给你完整梳理一下【巡检怎么做】和【用什么机制做得好】。

------

### **1️⃣ 巡检内容 (巡检都检查什么？)**

| 巡检对象                       | 巡检项目                                 |
| ------------------------------ | ---------------------------------------- |
| **主机 (物理/虚拟/云主机)**    | CPU、内存、磁盘空间、I/O负载、登录历史   |
| **网络设备**                   | 端口状态、丢包率、网络延迟、带宽使用率   |
| **存储**                       | 磁盘健康 (SMART)、分区挂载、RAID状态     |
| **服务与应用**                 | 进程状态、服务端口、配置文件变更         |
| **中间件 (数据库、缓存等)**    | MySQL 主从状态、Redis 内存命中率、连接数 |
| **安全**                       | 用户账户、SSH Key、开放端口、弱口令检查  |
| **日志**                       | 系统日志、服务日志，关键错误关键词       |
| **容器/Kubernetes (如用 K8s)** | Pod 状态、节点资源利用率、事件 (Events)  |



------

### **2️⃣ 巡检机制 (怎么做巡检？)**

| 巡检方式                | 实现机制                                     | 说明                                  |
| ----------------------- | -------------------------------------------- | ------------------------------------- |
| **主动巡检 (定时任务)** | **脚本 + 定时任务** (cron)、Ansible Playbook | 每天/每周固定时间批量跑脚本采集巡检项 |
| **被动巡检 (持续监控)** | Prometheus + AlertManager、Zabbix            | 24h 实时监控，指标异常自动告警        |
| **智能巡检 (AI分析)**   | ELK + 机器学习模型 (如 anomaly detection)    | 通过日志和指标行为基线识别“潜在风险”  |
| **一键巡检 (手动触发)** | Ansible + 脚本、Web面板按钮                  | 需要时随时手动触发完整巡检            |



------

### **3️⃣ 典型巡检自动化工具**

| 工具                                   | 主要用途                      | 特点                               |
| -------------------------------------- | ----------------------------- | ---------------------------------- |
| **Ansible**                            | 批量巡检脚本 (主机/服务/配置) | 免Agent、YAML可读性强              |
| **Prometheus**                         | 实时指标采集 + 告警           | 可观测性强、生态丰富 (Grafana展示) |
| **Zabbix**                             | 传统主机监控 + 报表巡检       | 报表功能完善                       |
| **ELK**                                | 日志采集分析                  | 日志关键字告警                     |
| **自研脚本 (Shell/Python)**            | 特殊业务巡检                  | 灵活定制                           |
| **SRE 报表系统 (Grafana PDF、Redash)** | 巡检报表展示                  | 适合做月报/季报输出                |



------

### **4️⃣ 巡检输出与闭环 (不能只看不管)**

- **巡检报告** → Markdown文档、PDF报告 (自动生成)
- **风险分级** → 重大/一般/提示性隐患
- **整改单 & 跟踪** → Jira、Redmine、禅道等任务跟踪系统
- **巡检记录归档** → 存档，便于审计与复盘

------

### **5️⃣ 示例：Ansible 自动化巡检机制**

1. **写 Playbook**
    例如：检查 CPU 使用率、磁盘空间

```yaml
- hosts: all
  tasks:
    - name: Check CPU usage
      shell: top -bn1 | grep "Cpu(s)"
      register: cpu
    - name: Check disk usage
      shell: df -h
      register: disk
    - name: Save report
      copy:
        content: |
          CPU: {{ cpu.stdout }}
          Disk: {{ disk.stdout }}
        dest: /tmp/inspection_report.txt
```

1. **定时执行**
    Linux Crontab 计划任务

```bash
0 3 * * * ansible-playbook /opt/inspection.yml


字段位置	值	意思
分钟 (Minute)	0	整点 (0 分钟)
小时 (Hour)	3	凌晨 3 点
日 (Day of Month)	*	每天
月 (Month)	*	每月
星期 (Day of Week)	*	每星期 (不限制星期几)

完整意思：
每天 03:00 AM 执行 crontab 任务一次
```

1. **结果汇总/告警**
    把 /tmp/inspection_report.txt 收集回运维端，邮件 or 企业微信发送告警

------

#### **总结**

> **成熟企业的巡检机制 = 定时 + 自动 + 监控 + 报表 + 整改闭环**

------





### **Kubernetes 巡检内容 (应该巡检哪些重点？)**

| 巡检对象                     | 主要内容                                                     | 重点指标                                    |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------- |
| **集群节点 (Node)**          | 节点健康、资源利用率                                         | CPU / Memory / Disk 使用率，Node Ready 状态 |
| **核心组件 (Control Plane)** | kube-apiserver、kube-scheduler、kube-controller-manager 状态 | Pod Running 状态、etcd 健康性               |
| **工作负载 (Workloads)**     | Deployment、StatefulSet、DaemonSet 运行情况                  | Pod Ready、重启次数、镜像拉取状态           |
| **网络与服务**               | CNI 网络插件、Service 解析、Ingress 访问                     | Pod 网络连通性、Service DNS、Ingress 响应   |
| **存储**                     | PVC 挂载状态、PV 使用率                                      | PVC 绑定状态、磁盘 IOPS、挂载错误           |
| **安全**                     | RBAC 权限配置、证书有效期、API 端口暴露                      | 高权限账户、即将过期证书                    |
| **监控与日志**               | 集群指标、审计日志、组件日志                                 | 节点指标、组件 Error 日志、异常告警         |
| **配置与变更**               | ConfigMap、Secret 变更记录                                   | 不合理配置变更 (如 imagePullPolicy: always) |



------

#### **巡检机制 (K8s 环境下怎么做巡检)**

#### **1️⃣ 基础自动化巡检 (Ansible + kubectl)**

- 批量执行 kubectl 命令收集集群状态
   示例：

```
kubectl get nodes
kubectl get pods -A
kubectl top node
kubectl describe pod -A
kubectl get events -A --sort-by='.lastTimestamp'
```

- **Ansible Playbook 自动化批量采集**
   批量 SSH 节点采集 `top`, `df -h`, `docker info` 等

------

#### **2️⃣ 实时监控型巡检 (Prometheus + Grafana + AlertManager)**

| 模块                    | 用途                                               |
| ----------------------- | -------------------------------------------------- |
| **Prometheus (采集)**   | kubelet metrics、Node Exporter、kube-state-metrics |
| **Grafana (可视化)**    | 预设 K8s Dashboard (如 Node health, Pod health)    |
| **AlertManager (告警)** | 指标异常自动推送 (钉钉/企业微信/邮件)              |



> **重点监控指标：**

- `node_filesystem_usage`
- `container_cpu_usage_seconds_total`
- `kube_pod_container_status_restarts_total`
- `kube_node_status_condition{condition="Ready"}`

------

#### **3️⃣ 日志巡检 (EFK/ELK + Loki)**

- **日志采集**
   Filebeat / Fluentd / Loki 收集 Pod 日志、节点日志
- **关键字预警**
   例如 grep `OOMKilled`、`CrashLoopBackOff`、`FailedScheduling` 关键字

------

#### **4️⃣ 安全巡检 (Kube-bench + kube-hunter)**

- **kube-bench**
   检查集群是否符合 **CIS Kubernetes 安全基线**
- **kube-hunter**
   发现集群中可能存在的安全漏洞 (如 API Server 公开暴露)

------

#### **5️⃣ 证书与配置巡检 (脚本工具)**

- 检查 API Server、etcd、kubelet 证书有效期
   示例：

```
kubectl get csr
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep 'Not After'
```

- 检查 RBAC 权限 (过于宽泛的角色)

```
kubectl get clusterrolebinding -A
kubectl auth can-i --list
```

------

#### **典型巡检工具推荐**

| 工具                                | 用途                  |
| ----------------------------------- | --------------------- |
| **kubectl + bash 脚本**             | 快速采集状态          |
| **Ansible**                         | 批量 SSH 节点巡检     |
| **Prometheus Operator (Helm 部署)** | 集群监控与告警        |
| **Grafana Dashboards**              | 可视化集群健康        |
| **kube-bench**                      | 安全合规检查          |
| **kube-hunter**                     | 集群漏洞扫描          |
| **Sonobuoy**                        | 全集群一致性/合规测试 |
| **Velero**                          | 备份和恢复巡检        |



------

#### **巡检报告与闭环**

- 每次巡检生成 Markdown / PDF 报告 (可以用 Grafana Report 生成)
- 发现隐患 → 创建 Jira / 禅道任务 → 整改 → 复查
- 周报/月报形式固化巡检结果

------

#### **总结一句话：**

> **K8s 巡检 = kubectl 脚本 + Prometheus 监控 + 安全扫描 + 日志分析 + 闭环整改**

------



## 分布式容器巡检（标准面试答法）

> 分布式容器巡检，指的是对运行在 K8s 或容器平台中的多节点、多服务容器系统进行**定期状态检查、资源监控、日志审查和安全审计**，确保系统稳定、安全、性能达标。

------

### 🧱 一、巡检内容五大类

| 分类             | 巡检内容                                                     |
| ---------------- | ------------------------------------------------------------ |
| ① **集群健康**   | Master组件、Node节点状态、核心服务（etcd / kubelet / kube-proxy）是否正常 |
| ② **资源使用**   | CPU / 内存 / 磁盘 / 网络使用情况，是否存在瓶颈或异常（如 OOM） |
| ③ **容器状态**   | Pod 状态是否正常，是否 CrashLoopBackOff、Pending、ImagePullBackOff |
| ④ **日志与告警** | 容器日志 / 系统日志 / 应用日志，是否有 ERROR、告警事件       |
| ⑤ **安全与配置** | 镜像来源是否合规、是否有暴露端口、RBAC 权限是否合理、Secret 是否加密等 |



------

### 🔧 二、常用工具和命令（面试官爱问）

#### 🔹 Kubernetes 原生命令：

```
kubectl get nodes                # 查看节点状态  
kubectl get pods -A              # 查看所有命名空间容器状态  
kubectl describe pod <pod>       # 查看容器事件和详细状态  
kubectl top node/pod             # 查看资源使用  
kubectl get events -A            # 集群事件巡查  
```

#### 🔹 系统层巡检（结合容器底层）：

```
df -h / iostat / vmstat / free -m         # 查看磁盘、CPU、内存状态  
journalctl -u kubelet / docker            # 查看服务日志  
ps aux | grep containerd                  # 确保 containerd 正常  
```

#### 🔹 日志平台（你简历提到 ELK）：

> 结合 ELK（Elasticsearch + Logstash + Kibana）或 Loki+Grafana 实现日志集中采集，支持关键词搜索如：

- `error`
- `timeout`
- `connection refused`

------

### 📊 三、监控与告警集成（结合你 Prometheus 项目）

> 在实际项目中，我们通过 Prometheus + Grafana 对集群与应用进行 7x24 监控
>  结合 Alertmanager 设置容器资源异常、节点离线、Pod Crash 等告警规则
>  示例告警项：

- 节点 CPU 使用率 > 80%
- Pod OOMKilled 次数 > 3 次
- etcd 存储空间利用率 > 90%

------

### 🔄 四、常见问题与应急排查

| 问题                 | 巡检动作                                            | 修复方案                      |
| -------------------- | --------------------------------------------------- | ----------------------------- |
| Pod CrashLoopBackOff | `kubectl describe pod` 看是否资源不足或配置错误     | 调整 `resources`，检查依赖    |
| 节点 NotReady        | `kubectl describe node` / `journalctl -xeu kubelet` | 检查网络 / kubelet / 容器服务 |
| 镜像拉取失败         | 查看 `ImagePullBackOff` 原因                        | 仓库异常 / Secret 配置缺失    |
| 磁盘告警             | `df -h`，确认 `/var/lib/docker` 空间                | 清理老日志 / 镜像 / volume    |
| etcd 告警            | `etcdctl endpoint status`                           | 扩容 / 压缩 / 调整负载        |



------

### 🛡️ 五、安全巡检（Bonus 面试加分）

- 镜像安全：使用可信镜像源（Harbor 私有仓库 + 签名机制）
- 配置加密：Secret 应使用加密存储
- 网络安全：检查是否有不必要的 NodePort / 未授权访问
- 权限审计：定期审查 RBAC 权限配置

------

### 💬 一句话总结（面试背诵版）

> 分布式容器巡检包括集群状态、资源利用、容器运行状态、日志告警、安全配置五大方面，结合 Kubernetes 命令、Prometheus 监控、日志平台和自动化工具实现巡检闭环，能有效预防故障、快速定位问题，保障生产系统稳定运行。

------

### ✅ 结合你的实际项目（K8s + Prometheus + ELK）

你可以这样说：

> 在我们容器化改造与 Prometheus 监控项目中，我们每周进行例行容器巡检
>  使用 kubectl + Prometheus + ELK 三线并行，保证节点资源健康、容器运行正常、日志无误
>  出现问题我们通过 Alertmanager 联动钉钉机器人第一时间告警，实现稳定交付。

------

##### 

### 自动化巡检脚本模板



好的！以下是**Kubernetes 分布式容器平台的自动化巡检脚本模板**，适合用于：

- 日常巡检（每日/每周定期跑一次）
- CI/CD 流水线集成（例如脚本中返回异常可以触发告警）
- 面试中展示“自动化运维能力”

------

#### ✅ 脚本名称：`k8s_inspect.sh`

#### ✅ 功能概览：

- 检查节点健康
- 检查所有命名空间 Pod 状态
- 检查资源使用率（CPU / 内存 / 磁盘）
- 检查事件中是否存在异常
- 输出日志格式便于邮件或通知发送

------

#### 🧾 脚本内容（建议放到运维节点 cron 自动执行）

```
#!/bin/bash
# Kubernetes 分布式容器自动化巡检脚本
# 作者：你名字 / 公司 / 时间

DATE=$(date '+%Y-%m-%d %H:%M:%S')
REPORT="/tmp/k8s_inspect_report_$(date +%Y%m%d).log"

echo "===== [K8s 自动巡检报告] =====" > $REPORT
echo "生成时间：$DATE" >> $REPORT
echo "--------------------------------" >> $REPORT

# 1. 检查节点状态
echo "[1] 节点状态:" >> $REPORT
kubectl get nodes -o wide >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 2. 检查 POD 异常
echo "[2] Pod 异常状态检查:" >> $REPORT
kubectl get pods --all-namespaces --field-selector=status.phase!=Running >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 3. 资源使用情况
echo "[3] 节点资源使用（top node）:" >> $REPORT
kubectl top nodes >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT
echo "[4] 各命名空间资源 TOP Pod（CPU > 200m 或 Mem > 500Mi）:" >> $REPORT
kubectl top pod -A | awk '($3+0)>200 || ($4+0)>500 {print}' >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 4. 系统事件异常
echo "[5] 集群事件异常:" >> $REPORT
kubectl get events -A --sort-by='.lastTimestamp' | grep -E 'Warning|Failed' >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 5. 镜像拉取失败 / CrashLoopBackOff 等关键字
echo "[6] Pod 状态异常关键词（CrashLoopBackOff / ImagePullBackOff）:" >> $REPORT
kubectl get pods -A | grep -E 'CrashLoopBackOff|ImagePullBackOff|Error' >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 6. etcd 健康检查（可选）
echo "[7] etcd 健康检查（如启用）:" >> $REPORT
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key endpoint health >> $REPORT 2>&1
echo "--------------------------------" >> $REPORT

# 7. 日志路径（可发送给邮箱或告警平台）
echo "[8] 巡检日志保存路径：" >> $REPORT
echo "$REPORT" >> $REPORT
echo "===== 巡检结束 =====" >> $REPORT

# 可选发送告警或邮件（结合钉钉 / 企业微信 / 邮件）
# mail -s "K8s 巡检报告 $DATE" ops@example.com < $REPORT
```

------

#### 🧰 依赖说明：

- 需要部署好 `kubectl` 并配置上下文
- `kubectl top` 需要启用 `metrics-server`
- `etcdctl` 命令行可选，若运行在 Master 节点可启用

------

#### 📌 建议定期调度方式：

```
bash复制编辑# 每天早上 8 点自动执行巡检
crontab -e

0 8 * * * /usr/local/bin/k8s_inspect.sh
```

------

#### 📈 整合建议：

你可以将这个脚本集成进：

- Jenkins CI/CD 流水线（做健康检查前置步骤）
- ArgoCD Hooks（同步后检查资源）
- GitLab Runner中作为 pipeline job（结合监控打标签）

------

#### 💬 面试答法建议

> 在实际生产中我们使用自动巡检脚本对 Kubernetes 集群进行每日健康巡检
>  主要覆盖节点状态、容器异常、资源瓶颈、事件告警等关键指标
>  脚本支持邮件通知或接入钉钉 Webhook，实现自动化 + 告警闭环
>  可作为 CI/CD 流水线健康检查前置步骤，确保交付稳定性





## RAM 和 ROM

### **1️⃣ 面试官可能怎么问？**

✅ RAM 和 ROM 有什么区别？
 ✅ 计算机中 RAM / ROM 分别起什么作用？
 ✅ 为什么断电后 RAM 会丢数据？
 ✅ ROM 一定不能改写吗？
 ✅ 云计算 / 服务器里的 RAM 重要性体现在哪？

------

### **2️⃣ 面试标准回答模板**

> **回答逻辑 = 定义 + 特点 + 场景应用**

**【标准回答】**

> RAM 是「随机存取存储器」，用于临时存储正在运行的程序和数据，特点是读写速度快，但断电后数据会丢失，属于「易失性存储」。
>  ROM 是「只读存储器」，用于永久保存关键固件或启动程序，比如主板 BIOS，断电后数据不会丢失，属于「非易失性存储」。
>  在实际应用里，RAM 直接影响服务器运行效率，比如 K8s 集群或数据库的性能依赖可用内存，而 ROM 存储底层固化代码，确保硬件启动和管理。
>  因此，RAM 更侧重运行效率，ROM 侧重启动和硬件指令固化。

------

### **3️⃣ 面试时「加分项」**

✅ **主动举例 (和岗位相关)**

> 例如：「在云计算场景，我们给虚拟机分配 8G vRAM，保证应用运行，底层的 EFI 固件镜像就类似 ROM，帮助虚拟机启动」
>  例如：「容器镜像本质上是只读层，和 ROM 概念类似，但应用运行过程依赖宿主机 RAM」

✅ **结合面试岗位 (运维 / 云计算)**

> 「作为云运维岗位，RAM 资源监控与管理特别重要，比如我参与过的 K8s 集群，监控 node 内存使用率，合理配置 Pod Requests/Limit，确保集群稳定」

------

### **4️⃣ 面试官追问备选答案**

| 问题                  | 建议回答                                                     |
| --------------------- | ------------------------------------------------------------ |
| 为什么 RAM 会丢数据？ | RAM 依靠电容/晶体管保存数据，断电后电荷迅速泄漏，数据丢失    |
| ROM 一定不能改写吗？  | 传统 ROM 不能改写，但 EEPROM / Flash ROM 支持反复擦写 (BIOS 升级) |
| RAM / ROM 哪个更快？  | RAM 更快 (纳秒级访问)，ROM 速度较慢 (微秒~毫秒)              |



------

### **5️⃣ 我帮你写好一段「面试背诵版」**

你可以直接背：

> RAM 是计算机的临时读写存储器，存储正在运行的数据和程序，速度快但断电后数据会丢失，属于易失性存储。ROM 是永久只读存储器，主要保存 BIOS 等固件，断电不丢数据。对于云计算运维来说，RAM 直接影响服务器和容器集群的性能，ROM 保障硬件正常启动和管理。我在项目中也关注过 RAM 资源监控与调优，比如 Kubernetes 集群内存 Requests 配置和节点容量预警。



## 应急响应机制



在面试中被问到**“你们在生产环境怎么做应急响应？”**，面试官想考察你是否具备实际事故处理、恢复、协同和总结能力。以下是一份适合背诵的**Kubernetes 分布式平台应急响应机制总结**，结合云计算运维、SRE 方向岗位特点：

------

### ✅ 一、标准应急响应流程（“六步法”）

> 🔁 遇到故障，我们一般按照 **“发现 → 分级 → 响应 → 修复 → 复盘 → 优化”** 的闭环流程进行应急处理。

| 步骤       | 内容                                           |
| ---------- | ---------------------------------------------- |
| 1️⃣ 事件发现 | 来自 Prometheus 告警、日志告警、用户反馈       |
| 2️⃣ 故障分级 | P1（全站不可用）P2（服务异常）P3（单点问题）   |
| 3️⃣ 快速响应 | 通知值班人员，封网、限流、服务降级             |
| 4️⃣ 故障处置 | 排查日志、Pod 状态、网络、依赖服务，必要时回滚 |
| 5️⃣ 恢复验证 | 验证服务是否恢复、QPS、响应时间、无新告警      |
| 6️⃣ 事后复盘 | 撰写 RCA 报告，明确根因、补救、预防措施        |



------

### ✅ 二、常见应急场景举例（建议记住几个）

| 场景                   | 应急动作                                         |
| ---------------------- | ------------------------------------------------ |
| 🟥 节点 NotReady        | cordon 节点 + 查看 kubelet / 网络问题 + 迁移 Pod |
| 🟧 Pod CrashLoopBackOff | 查看日志 + 检查配置 / 资源 + 重启 Pod            |
| 🟨 镜像拉取失败         | 查看 ImagePullBackOff + 校验镜像仓库和 Secret    |
| 🟦 服务连接超时         | 查看依赖服务状态 + 检查 DNS / 网关 / 网络策略    |
| 🟩 etcd 空间不足        | 手动 compaction + 扩容 etcd 磁盘                 |



------

### ✅ 三、工具支持（展示你的运维工具链）

| 工具                            | 用法                                        |
| ------------------------------- | ------------------------------------------- |
| 🔔 **Prometheus + Alertmanager** | 提前配置好告警规则 + 告警分级（P1-P3）      |
| 📟 **ELK / Loki**                | 快速查看 Pod / Node / 应用日志定位根因      |
| 📶 **Kubernetes**                | kubectl + describe/log/top/event 等命令排查 |
| 📥 **镜像仓库回滚**              | Harbor 支持多版本镜像回滚                   |
| 🔄 **CI/CD**                     | 可快速一键部署回滚（Jenkins / GitLab CI）   |



------

### ✅ 四、应急演练机制（高阶面试官经常问）

> 我们会定期组织 **高可用演练 / 故障注入 / Chaos 工具演练**

| 类型          | 示例                                     |
| ------------- | ---------------------------------------- |
| 容器模拟异常  | 手动 kill pod 看 HPA / Liveness 是否拉起 |
| 节点下线演练  | 关闭 node，验证 Pod 是否调度到其他节点   |
| etcd 压力测试 | 模拟写入压力验证 etcd alert 是否生效     |
| 网络中断测试  | 使用 Chaos Mesh 注入网络延迟 / 丢包      |



------

### ✅ 五、RCA 复盘报告（建议提到）

> 每次故障后会撰写 RCA 报告（Root Cause Analysis），包含：

- 故障简述 + 时间线
- 根因分析（日志 / 配置 / 资源 / 代码）
- 临时修复 + 永久修复
- 预防机制：如加熔断 / 限流 / 告警规则
- 责任人 + 改进事项

------

### 💬 面试总结答法（可直接背诵）

> 在生产环境中我们建立了完善的应急响应机制，包括 Prometheus 告警发现、事件分级、故障应急响应、快速回滚与自动恢复
>  并在事后进行 RCA 复盘与系统优化。同时也会通过 Chaos Mesh 等方式定期进行高可用演练，确保平台在高并发或故障场景下具备自愈与稳定性。



## 事故管理怎么做的

面试中如果问你“**你们事故管理怎么做的？**”——其实是想考察你是否参与过 **实际生产事故的闭环处理流程**，有没有建立规范、有无总结、预防机制是否到位。

------

### ✅ 一、事故管理核心流程（答法模板）

你可以这样回答：

> 在我们团队中，生产事故的管理遵循 “**4阶闭环流程 + 3个制度保障**”：
>
> - 事故处理流程：**检测 → 响应 → 通报 → 复盘**
> - 制度保障机制：**事故分级机制、RCA 报告机制、SRE 值班制度**

------

### ✅ 二、生产事故处理四阶段

| 阶段   | 描述                                                      | 实践操作（示例）              |
| ------ | --------------------------------------------------------- | ----------------------------- |
| 1️⃣ 检测 | 通过 Prometheus 告警、用户反馈、日志平台监控发现故障      | Prometheus 报警触发钉钉通知   |
| 2️⃣ 响应 | 第一时间值班 SRE 介入处理，通知相关责任人                 | 启动应急预案，限流 + 服务降级 |
| 3️⃣ 通报 | 事故发生后 **10分钟内** 通报内部群，严重事件逐级汇报      | 使用模板化通知格式            |
| 4️⃣ 复盘 | 故障恢复后 **24小时内** 提交 RCA 报告，包含根因与改进措施 | 建 Jira 工单跟进改进任务      |



------

### ✅ 三、事故分级制度（建议背诵）

| 等级 | 描述                               | 响应时间                       |
| ---- | ---------------------------------- | ------------------------------ |
| P1   | 全站不可用或核心功能完全瘫痪       | 5分钟内响应，所有人介入        |
| P2   | 主要模块严重异常，但仍可用         | 15分钟响应，相关模块负责人处理 |
| P3   | 局部异常或功能性 Bug，不影响主流程 | 当日排期处理                   |



> 💡 **提示：面试时如果你能明确说出“我们按 P1~P3 等级处理事故”，说明你对团队运维规范熟悉！**

------

### ✅ 四、事故复盘制度（RCA）

> 事故发生后 24 小时内需提交 RCA 报告，并进行团队级技术复盘会议。

RCA 报告内容包括：

1. **问题描述 + 时间线**
2. **影响范围**
3. **根因分析（可引用日志 / kubectl describe 等信息）**
4. **应急处理过程**
5. **永久修复方案**
6. **预防措施（告警、测试、优化）**
7. **责任人、验收标准**

------

### ✅ 五、预防机制（经验点）

| 类型     | 做法                                                         |
| -------- | ------------------------------------------------------------ |
| 告警     | Prometheus/Alertmanager + 阈值 + 关键指标覆盖（如 QPS、延迟、错误率） |
| 回滚     | 所有服务接入 CI/CD 平台，一键回滚容灾版本                    |
| 限流     | 接入 Istio/Gateway 实现服务限流与熔断                        |
| 灰度     | 使用 Argo Rollouts 或自定义标签灰度发布                      |
| 自动恢复 | Liveness、HPA、Eviction 等自动调度机制                       |



------

### ✅ 六、补充材料（你可以主动提）

> 我们还建立了“事故通报模板”、“事故应急演练制度”、“值班轮换制度”等文档标准，提升团队协作效率。

------

### 💬 面试总结参考说法：

> 我们在生产事故管理方面形成了标准化流程，包括按 P1~P3 分级响应机制、SRE 值班制度、RCA 复盘机制，并结合 Prometheus 告警、自动化回滚、服务限流等手段快速定位与恢复
>  事故恢复后会形成 RCA 报告，并推动代码、配置、架构上的改进措施闭环处理，确保问题不二次发生。







## 华为的openstack私有云

华为的 OpenStack 私有云平台，主要是基于 OpenStack 社区版本进行深度定制和企业级增强，打造出的企业级云平台解决方案，官方称为 **FusionCompute（计算虚拟化）+ FusionStorage（分布式存储）+ FusionSphere（云操作系统）**，广泛应用于政府、金融、能源、电信等行业。

------

### ✅ 一、华为私有云的整体架构概览

华为的私有云平台核心组件主要基于 OpenStack，但围绕企业级业务场景做了大量增强：

#### 1. **底层基础设施层（IaaS）**

- 虚拟化平台：基于 KVM 的 **FusionCompute**
- 存储系统：分布式块存储 **FusionStorage**（也可接入华为 SAN/NAS）
- 网络：基于 **SDN（Agile Controller）** 构建 VXLAN/EVPN 网络
- 硬件：支持鲲鹏/鲲鹏服务器、X86、ARM 等混合环境

#### 2. **云操作系统层**

- 华为 **FusionSphere**（类似 OpenStack 控制面）
  - 提供弹性计算（ECS）、弹性云硬盘（EVS）、对象存储（OBS）、虚拟网络（VPC）等服务
  - 可与云桌面（FusionAccess）、大数据、容器（Cloud Container Engine）集成

#### 3. **平台管理与运维层**

- 云管平台：ManageOne（CMP）
  - 实现统一门户、自助服务、资源编排、自动化运维
- 安全管理：统一认证、角色权限、审计
- 运维监控：AOM、OMS 支持多维度监控和报警

------

### 🧩 二、与原生 OpenStack 的区别

| 项目         | 华为私有云                   | 原生 OpenStack          |
| ------------ | ---------------------------- | ----------------------- |
| 部署复杂度   | 可视化部署工具，交付快速     | 高度定制，部署复杂      |
| 企业特性支持 | 更好的安全、多租户、性能隔离 | 需用户自己搭建          |
| 兼容性       | 高度集成 Fusion 系列产品     | 可选组件多，自主灵活    |
| 管理界面     | ManageOne，图形化、自助化    | Horizon（功能相对简化） |
| 维护支持     | 商业支持团队，7×24 运维      | 社区自助，需技术积累    |
| 网络能力     | SDN、EVPN、VXLAN 一体化      | 需整合 Neutron 插件     |



------

### 🛠 三、常见运维工作内容（针对华为私有云）

| 运维项     | 说明                                          |
| ---------- | --------------------------------------------- |
| 资源池管理 | CPU、内存、存储、IP 资源池统一管理            |
| 虚拟网络   | 创建 VPC、子网、虚拟路由、浮动 IP             |
| 云主机运维 | 启停、重启、快照、迁移、备份                  |
| 存储管理   | 云硬盘挂载、扩容、备份、存储池维护            |
| 镜像管理   | 制作通用镜像、版本更新                        |
| 用户权限   | 租户管理、RBAC 权限设置                       |
| 自动化运维 | 利用脚本/API/ManageOne 实现定时巡检、容量分析 |
| 灾备演练   | 多活、主备切换、跨地域容灾方案测试            |



------

### 📘 四、面试常见问题参考

#### Q1：你对华为私有云的理解是什么？

**回答要点：**

> 华为私有云是以 OpenStack 为基础，通过 FusionCompute、FusionStorage、FusionSphere 构建的企业级 IaaS 平台。相比原生 OpenStack，它具备更好的稳定性、自动化部署能力、企业特性（如 HA、热迁移、计费审计、安全隔离）支持，适合政府与大型企业落地应用。

------

#### Q2：你在华为私有云运维中做过哪些工作？

**回答示例：**

> 我负责 FusionSphere 平台的日常运维工作，包括虚拟机创建与自动化部署、资源池的扩容与迁移、镜像模板管理、VPC 网络隔离、云硬盘备份与扩容等操作；通过 ManageOne 平台实现资源统计、故障告警、定时巡检等功能。同时对接了华为云 API 实现脚本化批量操作，提升运维效率。

------

### 🌐 五、常用管理入口

| 模块             | 管理地址样例                |
| ---------------- | --------------------------- |
| ManageOne 控制台 | `https://<MO-IP>/manageone` |
| FusionCompute    | `https://<FC-IP>`           |
| FusionStorage    | `https://<FS-IP>`           |
| 虚拟机控制台     | 可通过 VNC/Web Console 打开 |



------

### 🔐 六、安全运维实践建议

- 使用 AD/LDAP 做集中认证
- 强密码策略与定期轮换
- 日志审计与审计报表归档
- 云资源操作权限最小化
- 云主机入侵检测 + WAF



## 阿里云组件

在阿里云中，常用的**云计算运维、DevOps、SRE**方向的组件主要分为以下几类。下面按照类别为你详细列出：

------

### 一、**计算与容器类**

#### 1. **ECS（Elastic Compute Service）**

- 云服务器，用于部署应用、数据库等。
- 类似于 AWS 的 EC2。

#### 2. **容器服务 ACK（Alibaba Cloud Kubernetes）**

- 托管的 Kubernetes 服务，支持 DevOps 与微服务架构。
- 支持与阿里云各组件（SLB、日志、监控等）深度集成。

#### 3. **函数计算（Function Compute）**

- 无服务器计算平台，支持事件驱动架构。
- 可用于自动化脚本、CI/CD流程触发器等。

------

### 二、**网络与负载均衡**

#### 1. **SLB（Server Load Balancer）**

- 负载均衡器，支持四层/七层代理，支持HTTPS。
- 支持与ECS、ACK集成，流量转发能力强。

#### 2. **私有网络 VPC**

- 网络隔离和安全控制组件。
- 支持子网、路由表、安全组配置。

#### 3. **NAT 网关 / VPN 网关**

- 提供公网访问、跨地域网络互通等能力。

------

### 三、**存储与数据库**

#### 1. **OSS（Object Storage Service）**

- 对象存储，支持海量数据存储，适合日志、镜像等静态资源。

#### 2. **NAS / 云盘（云块存储）**

- 文件存储和块存储，适用于挂载到ECS或容器中。

#### 3. **RDS（Relational Database Service）**

- 托管的MySQL、PostgreSQL、SQL Server、MariaDB数据库。

#### 4. **Redis / MongoDB / PolarDB**

- 分布式缓存/NoSQL数据库/新型高性能数据库服务。

------

### 四、**监控与日志**

#### 1. **云监控（CloudMonitor / CMS）**

- 实时监控ECS、RDS、ACK等资源的运行状态。
- 支持自定义监控指标和报警。

#### 2. **日志服务（Log Service / SLS）**

- 集中式日志采集、分析与可视化。
- 可与Prometheus、EFK等打通。

#### 3. **可观测链路 OpenTelemetry / ARMS（应用实时监控服务）**

- 类似于 APM（如SkyWalking），用于链路追踪、慢接口分析等。

------

### 五、**安全类**

#### 1. **WAF（Web 应用防火墙）**

- 提供防护OWASP漏洞、DDoS攻击等能力。

#### 2. **安全组 / RAM（权限管理）**

- 细粒度权限控制，防止非授权访问。

#### 3. **云防火墙 / 态势感知**

- 对整个云上资源进行统一安全管理和威胁检测。

------

### 六、**DevOps与自动化**

#### 1. **云效（Alibaba Cloud DevOps）**

- 阿里云原生CI/CD平台，支持代码托管、构建、测试、部署全流程。
- 支持和ECS、ACK等资源联动，适合中大型企业持续交付体系。

#### 2. **资源编排（ROS，Resource Orchestration Service）**

- 类似 Terraform，可以用模板方式自动创建资源。

#### 3. **Terraform on Alibaba Cloud**

- 使用Terraform代码管理阿里云资源。

------

### 七、**中间件**

#### 1. **消息队列（RocketMQ、Kafka、RabbitMQ）**

- 异步通信解耦组件，适合微服务架构。

#### 2. **企业级中间件（如 MSE，微服务引擎）**

- 服务注册、治理、限流、降级等能力。

------

### 八、**AI / 大数据 / 其他常用组件**

#### 1. **MaxCompute / DataWorks / EMR**

- 大数据处理和分析组件，适用于日志分析、业务报表等。

#### 2. **容器镜像服务（ACR）**

- 阿里云的容器镜像仓库，支持 Helm Chart、私有镜像托管。

------

### ✅ 总结：CI/CD流程中最常用的阿里云组件

| 阶段     | 常用阿里云组件                       |
| -------- | ------------------------------------ |
| 代码管理 | 云效 Code 或 GitHub/GitLab（第三方） |
| 构建测试 | 云效 Pipeline + 镜像服务（ACR）      |
| 部署发布 | ACK 容器服务 + SLB + ROS             |
| 配置管理 | Terraform / ROS / 云函数             |
| 日志监控 | 云监控 + 日志服务 SLS + ARMS         |
| 安全     | 安全组 + WAF + RAM                   |











# 场景问题

## 我现在有几台机器，找不到谁去认领，现在要把机器重装一下，在这之前要进最大可能去规避风险，要对这个机器做一个断网的操作，只允许我去登录，不允许其他流量的转发，我要用那个命令，及那个规则达成需求

你的目标很明确：**在重装系统前，为了规避被他人登录或流量转发风险，需要立即断网，仅允许自己登录操作该机器**。

------

### ✅ 场景假设

你需要：

1. **阻止所有外部访问（断网）**
2. **只允许本地控制台（或 localhost）登录**
3. **阻止该主机作为转发或跳板机使用**

------

✅ 推荐操作步骤（立即生效，最大限度断网，仅本地可用）

### ✅ 第一步：禁止所有网络通信（立即断网）

```
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT DROP
```

这会：

- DROP 所有进入、转发和发出的数据包
- **立刻断网，包括你的远程连接！**

⚠️ 为了避免把你自己锁在外面，推荐如下保守版本（只允许本地登录）

### ✅ 第二步：仅允许本地回环（localhost）访问

```
# 清空原有规则
iptables -F
iptables -X

# 默认全部禁止
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT DROP

# 允许 lo 回环接口访问（本地登录和命令执行）
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT
```

这会：

- 拒绝所有外部访问
- 允许你通过本地控制台或 `localhost` 登录（如 `ssh localhost`）

------

### ✅ 第三步：禁止内核 IP 转发

```
echo 0 > /proc/sys/net/ipv4/ip_forward
sysctl -w net.ipv4.ip_forward=0
```

并修改 `/etc/sysctl.conf` 永久禁用：

```
echo "net.ipv4.ip_forward = 0" >> /etc/sysctl.conf
sysctl -p
```

------

### ✅ 第四步（可选）：关闭 SSH 或限制 SSH 只监听 127.0.0.1

如果你担心远程 SSH 被人登录：

#### 方法 1：直接停用 sshd（彻底断开远程登录）

```
systemctl stop sshd
systemctl disable sshd
```

#### 方法 2：只允许本地登录 SSH

修改配置文件 `/etc/ssh/sshd_config`：

```
ListenAddress 127.0.0.1
```

然后：

```
systemctl restart sshd
```

------

### ✅ 总结：关键命令速查表

| 目的             | 命令                                                         |
| ---------------- | ------------------------------------------------------------ |
| 清空旧防火墙规则 | `iptables -F && iptables -X`                                 |
| 禁止所有转发     | `iptables -P FORWARD DROP`                                   |
| 禁止对外通信     | `iptables -P OUTPUT DROP`                                    |
| 禁止所有输入     | `iptables -P INPUT DROP`                                     |
| 允许本地回环     | `iptables -A INPUT -i lo -j ACCEPT && iptables -A OUTPUT -o lo -j ACCEPT` |
| 禁用IP转发       | `echo 0 > /proc/sys/net/ipv4/ip_forward && sysctl -w net.ipv4.ip_forward=0` |
| 永久关闭IP转发   | `echo "net.ipv4.ip_forward = 0" >> /etc/sysctl.conf && sysctl -p` |
| 停用 SSH         | `systemctl stop sshd && systemctl disable sshd`              |
